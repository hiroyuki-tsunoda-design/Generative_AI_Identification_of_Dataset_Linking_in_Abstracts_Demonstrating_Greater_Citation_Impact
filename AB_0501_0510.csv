AB,NO
"the demand for precision predictions in the field of high energy physics has dramatically increased over recent years. experiments conducted at the lhc, as well as precision measurements at the intensity frontier such as belle ii require equally precise theoretical predictions to make full use of the acquired data. to match the experimental precision, second-, third-and, for certain quantities, even higher-order calculations in perturbative quantum field theory are required. to facilitate such calculations, computer software automating as many steps as possible is required. yet, each calculation poses different challenges and thus, a high level of configurability is required. in this context we present tapir: a tool for identification, manipulation and minimization of feynman integral families. it is designed to integrate in toolchains based on the computer algebra system form, the use of which is common practice in the field. tapir can be used to reduce the complexity of multi-loop problems with cut-filters, topology mapping, partial fraction decomposition and alike.program summaryprogram title: tapircpc library link to program files: https://doi.org/10.17632/ptc9t46xyn.1developer's repository link: https://gitlab.com /tapir-devs/tapirlicensing provisions:gplv3programming language: python 3, c++nature of problem: multi-loop computations require the automatization of a large number of different tasks related to feynman integral topologies. among them are the identification and minimization of integral topologies, partial fraction decomposition of topologies in the case of linearly dependent propagators as well as mapping scalar products of loop momenta to scalar functions.solution method: the minimization of topologies is performed by comparison of their respective nickel indices [1], even further minimization utilizes pak's algorithm [2]. to efficiently map scalar products of loop momenta to scalar functions form [3] code is generated.additional comments including restrictions and unusual features: minimization based on pak's algorithm slows down for many lines and scales. a coarser minimization using the nickel indices, however, is still possible.",AB_0051
"long non-coding rnas (lncrnas) play a key role in several biological processes and scientists are constantly trying to come up with new strategies to elucidate their functions. one common approach to characterize these sequences consists in predicting their interactions with other rna fragments. nevertheless, the high computational cost of the bioinformatics tools developed for this purpose prevents their application to large-scale datasets. this paper presents priblast, a highly efficient parallel application for comprehensive lncrna-rna interaction prediction based on the state-of-the-art riblast tool, which has been proved to show superior biological accuracy compared to other counterparts in previous experimental evaluations. benchmarking on a multicore cpu cluster shows that priblast is able to compute in a few hours analyses that would need more than three months to complete with the original riblast algorithm, always achieving the same level of prediction accuracy. furthermore, this novel application can process large input datasets that cannot be processed with the former tool. priblast is free software publicly available to download at https://github.com/udc-gac/priblast under the mit license.(c) 2022 the author(s). published by elsevier b.v. this is an open access article under the cc by license ().",AB_0051
"the manipulation of the quantum states of light in linear optical systems has multiple applications in quantum optics and quantum computation. the package qoptcraft gives a collection of methods to solve some of the most usual problems when designing quantum experiments with linear interferometers. the methods include functions that compute the quantum evolution matrix for n photons from the classical description of the system and inverse methods that, for any desired quantum evolution, will either give the complete description of the experimental system that realizes that unitary evolution or, when this is impossible, the complete description of the linear system which approximates the desired unitary with a locally minimal error. the functions in the package include implementations of different known decompositions that translate the classical scattering matrix of a linear system into a list of beam splitters and phase shifters and methods to compute the effective hamiltonian that describes the quantum evolution of states with n photons. the package is completed with routines for useful tasks like generating random linear optical systems, computing matrix logarithms, and quantum state entanglement measurement via metrics such as the schmidt rank. the routines are chosen to avoid usual numerical problems when dealing with the unitary matrices that appear in the description of linear systems.program summaryprogram title: qoptcraftcpc library link to program files: https://doi .org /10 .17632 /r24hszggf4 .1developer's repository link: https://github .tel .uva .es /juagar /qoptcraft licensing provisions: apache-2.0programming language: python 3 v3.9.5:0a7dcbd, may 3 2021 17:27:52 supplementary material:: user's manual at https://github .tel .uva .es /juagar /qoptcraft /-/blob /main /qoptcraft _v1.1 _user _guide .pdfnature of problem: the evolution of the quantum states of light in linear optical devices can be computed from the scattering matrix of the system using a few alternative points of view. apart from being able to compute the evolution through a known optical system, it is interesting to consider the less studied inverse problem of design: finding the optical system which gives or approximates a desired evolution. linear optical systems are limited and can only provide a small subset of all the physically possible quantum transformations on multiple photons. choosing the best approximation for the evolutions that cannot be achieved with linear optics is not trivial. this software deals with the analysis of the quantum evolution of multiple photons in linear optical devices and the design of optical setups that achieve or approximate a desired quantum evolution. solution method: we have automated multiple computation processes regarding quantum experiments via linear optic devices. the methods rely on the properties of the groups and algebras that describe the problem of light evolution in linear system. the library qoptcraft for python 3 includes known numerical methods for decomposing an optical system into beam splitters and phase shifters and methods to give the quantum evolution of system classically described by a scattering matrix using either the heisenberg picture evolution of the states, a description based on the permanents of certain matrices or the evolution from the effective hamiltonian of the system. it also provides methods for the design of achievable evolutions, using the adjoint representation, and for approximating quantum evolutions outside the reach of linear optics with an iterative method using toponogov's comparison theorem from differential geometry. the package is completed with useful functions that deal with systems including losses and gain, described with quasiunitary matrices, the generation of random matrices and stable implementations of the matrix logarithm.additional comments including restrictions and unusual features: the package is designed to work with intermediate scale optical systems. due to the combinatorial growth in the state space with the number of photons and modes involved, there is an upper limit on the efficiency of any classical calculation. qoptcraft serves as a design tool to explore the building blocks of photonic quantum computers, optical systems that generate useful quantum states of light for their use in metrology or other applications or the design of quantum optics experiments to probe the foundations of quantum mechanics.(c) 2022 the author(s). published by elsevier b.v. this is an open access article under the cc by-nc-nd license ().",AB_0051
"objective: single-trial event-related potentials (erps) offer fine-grained information about the trajectories of the neurocognitive processes but are highly sensitive to any artifacts in the eeg signal. the primary aim of this study was to assess the impact of ocular artifact removal on the single-trial n250 erp analysis of face learning in individual participants. methods: we present a detailed description of our research-grade eeg hardware setup and a highly reproducible code (https://osf.io/aqhmn/) for generating time series of single-trial n250 erp amplitudes and precise identification of a changepoint between face memory trace acquisition and maintenance. ocular artifacts were removed using a new semi-automatic approach with only one hyperparameter based on the correlation between eeg components from independent component analysis (ica) and the eog signal. results: results from the simulation study showed that our ocular artifact filtration decreased the average rmse by half and achieved the highest increase of snr among all the compared methods. it decreased standard deviations and improved the fit of the broken-line regression models for all participants by 25% & plusmn; 17% (min. 2%, max. 63%). conclusions and significance: ocular artifact filtration had a substantial positive impact on the regression modeling of single-trial erp amplitudes. lack of ocular artifact removal can drastically distort the conclusions about the face learning process from single-trial n250 erp experiments for individual participants. the changepoint locations changed for 13 out of 15 participants. this is the first published analysis of time series of single-trial n250 erp amplitudes in face learning.",AB_0051
"health organizations advise social distancing, wearing face mask, and avoiding touching face to prevent the spread of coronavirus. based on these protective measures, we developed a computer vision system to help prevent the transmission of covid-19. specifically, the developed system performs face mask detection, face-hand interaction detection, and measures social distance. to train and evaluate the developed system, we collected and annotated images that represent face mask usage and face-hand interaction in the real world. besides assessing the performance of the developed system on our own datasets, we also tested it on existing datasets in the literature without performing any adaptation on them. in addition, we proposed a module to track social distance between people. experimental results indicate that our datasets represent the real-world's diversity well. the proposed system achieved very high performance and generalization capacity for face mask usage detection, face-hand interaction detection, and measuring social distance in a real-world scenario on unseen data. the datasets are available at https://github.com/iremeyiokur/covid-19-preventions-control-system.",AB_0051
"this article presents subjective norms for 1031 emojis in six dimensions: visual complexity, familiarity, frequency of use, clarity, emotional valence, and emotional arousal. this is the largest normative study conducted so far that relies on subjective ratings. unlike the few existing normative studies, which mainly comprise face emojis, here we present a wide range of emoji categories. we also examine the correlations between the dimensions assessed. our results show that, in terms of their affective properties, emojis are analogous to other stimuli, such as words, showing the expected u-shaped relationship between valence and arousal. the relationship between affective properties and other dimensions (e.g., between valence and familiarity) is also similar to the relationship observed in words, in the sense that positively valenced emojis are more familiar than negative ones. these findings suggest that emojis are suitable stimuli for studying affective processing. emoji-sp will be highly valuable for researchers of various fields interested in emojis, including computer science, communication, linguistics, and psychology. the full set of norms is available at: https://osf.io/dtfjv/.",AB_0051
"in order to support the burgeoning field of research into intra- and interpersonal synchrony, we present an open-source software package: multisyncpy. multivariate synchrony goes beyond the bivariate case and can be useful for quantifying how groups, teams, and families coordinate their behaviors, or estimating the degree to which multiple modalities from an individual become synchronized. our package includes state-of-the-art multivariate methods including symbolic entropy, multidimensional recurrence quantification analysis, coherence (with an additional sum-normalized modification), the cluster-phase 'rho' metric, and a statistical test based on the kuramoto order parameter. we also include functions for two surrogation techniques to compare the observed coordination dynamics with chance levels and a windowing function to examine time-varying coordination for most of the measures. taken together, our collation and presentation of these methods make the study of interpersonal synchronization and coordination dynamics applicable to larger, more complex and often more ecologically valid study designs. in this work, we summarize the relevant theoretical background and present illustrative practical examples, lessons learned, as well as guidance for the usage of our package - using synthetic as well as empirical data. furthermore, we provide a discussion of our work and software and outline interesting further directions and perspectives. multisyncpy is freely available under the lgpl license at: https://github.com/cslab-hub/multisyncpy, and also available at the python package index.",AB_0051
"we present the regensburg breast shape model (rbsm)-a 3d statistical shape model of the female breast built from 110 breast scans acquired in a standing position, and the first publicly available. together with the model, a fully automated, pairwise surface registration pipeline used to establish dense correspondence among 3d breast scans is introduced. our method is computationally efficient and requires only four landmarks to guide the registration process. a major challenge when modeling female breasts from surface-only 3d breast scans is the non-separability of breast and thorax. in order to weaken the strong coupling between breast and surrounding areas, we propose to minimize the variance outside the breast region as much as possible. to achieve this goal, a novel concept called breast probability masks (bpms) is introduced. a bpm assigns probabilities to each point of a 3d breast scan, telling how likely it is that a particular point belongs to the breast area. during registration, we use bpms to align the template to the target as accurately as possible inside the breast region and only roughly outside. this simple yet effective strategy significantly reduces the unwanted variance outside the breast region, leading to better statistical shape models in which breast shapes are quite well decoupled from the thorax. the rbsm is thus able to produce a variety of different breast shapes as independently as possible from the shape of the thorax. our systematic experimental evaluation reveals a generalization ability of 0.17mm and a specificity of 2.8mm. to underline the expressiveness of the proposed model, we finally demonstrate in two showcase applications how the rbsm can be used for surgical outcome simulation and the prediction of a missing breast from the remaining one. our model is available at https://www.rbsm.re-mic.de/.",AB_0051
"in digital era, being stranded from very basic telecommunication protocols and internet makes vehicle rerouting-like crucial tools more difficult or even impossible, especially in times of disaster and emergency. in this study, we propose a modular rerouting framework for only one single vehicle composed of visual perception, property estimation and trajectory optimization, which enables to generate optimum paths exploiting aerial imagery. once the deep network, which is fine-tuned on newly introduced dataset herein named mavefai, processes the input, the following module estimates pose, motion direction and speed of detected vehicles. afterwards, we link the appropriate vehicles via graphs to obtain group properties that pave the way for estimating the traffic congestion level. in the end, we get the output as the optimum path from the independent trajectory optimization module to which required inputs are already sent by preceding modules. we solve the multi-objective cost function subject to velocity and congestion intervals, which comprises distance, traffic congestion level, and angle inconsistency. we employ dijkstra, a*, rrt, and rrt* to optimize the cost while vast majority of existing works focus to optimize via single method. the fine-tuned segmentation model accuracy becomes more than 98% for vehicle groups thanks to mavefai. the extensive experiments reveal that all algorithms follow the same path. however, rrt* achieves the fastest result by examining most of the possible options in less time, which also appears to be the most robust method comparing with the alternatives for route optimization. our dataset mavefai is publicly available here: https://precisioncomputing.sakarya.edu.tr.",AB_0051
"with the development of deep learning technology, deep reinforcement learning (drl) has successfully built intelligent agents in sequential decision-making problems through interaction with image-based environments. however, learning from unlimited interaction is impractical and sample inefficient because training an agent requires many trial and error and numerous samples. one response to this problem is sample-efficient drl, a research area that encourages learning effective state representations in limited interactions with image-based environments. previous methods could effectively surpass human performance by training an rl agent using self-supervised learning and data augmentation to learn good state representations from a given interaction. however, most of the existing methods only consider similarity of image observations so that they are hard to capture semantic representations. to address these challenges, we propose spatio-temporal and action-based contrastive representation (stacore) learning for sample-efficient drl. stacore performs two contrastive learning to learn proper state representations. one uses the agent's actions as pseudo labels, and the other uses spatio-temporal information. in particular, when performing the action-based contrastive learning, we propose a method that automatically selects data augmentation techniques suitable for each environment for stable model training. we train the model by simultaneously optimizing an action-based contrastive loss function and spatio-temporal contrastive loss functions in an end-to-end manner. this leads to improving sample efficiency for drl. we use 26 benchmark games in atari 2600 whose environment interaction is limited to only 100k steps. the experimental results confirm that our method is more sample efficient than existing methods. the code is available at https://github.com/dudwojae/stacore. (c) 2022 elsevier ltd. all rights reserved.",AB_0051

AB,NO
"g-quadruplexes (g4) are 3d structures that are found in both dna and rna. interest in this structure has grown over the past few years due to both its implication in diverse biological mechanisms and its potential use as a therapeutic target, to name two examples. g4s in humans have been widely studied; however, the level of their study in other species remains relatively minimal. that said, progress in this field has resulted in the prediction of g4s structures in various species, ranging from bacteria to eukaryotes. these predictions were analysed in a previous study which revealed that g4s are present in all living kingdoms. to date, eleven different databases have grouped the various g4s depending on either their structures, on the proteins that might bind them, or on their location in the various genomes. however, none of these databases contains information on their location in the transcriptome of many of the implicated species. the gaza database was designed so as to make this data available online in a user-friendly manner. through its web interface, users can query gaza to filter g4s, which, we hope, will help the research in this field. gaza is available at: https://gaia.cobius.usherbrooke.ca",AB_0011
"vision-based autonomous driving systems need to overcome many challenges at nighttime, such as complicated illumination conditions, dazzle caused by headlamps, light refraction, motion blur and many other special problems. although many research works have gradually paid attention to low-light challenges, there are still lacking natural nighttime driving datasets covering various countries and regions. thus, we propose the transnational image object detection datasets from nighttime driving (tdnd datasets), which contain natural driving images across multiple countries and regions. the tdnd datasets not only cover severe weather such as heavy rain and snow, but also retain complicated illumination conditions and other problems. these datasets consist of 115k images which are annotated in six classes. the performance of six deep-learning-based object detection methods is further compared for evaluation, which are faster r-cnn, cascade r-cnn, retinanet, yolo-v3, cornernet and fcos. the results show that the quality of the tdnd datasets is comparable to that of ms-coco. moreover, for special problems at nighttime, the state-of-the-art object detection methods are worthy of further research and optimization. the datasets can be downloaded at https://github.com/biubiu3/tdnd-dataset.",AB_0011
"dynamic texture (dt) exhibits statistical stationarity in the spatial domain and stochastic repetitiveness in the temporal dimension, indicating that different frames of dt possess a high similarity correlation that is critical prior knowledge. however, existing methods cannot effectively learn a synthesis model for high-dimensional dt from a small number of training samples. in this article, we propose a novel dt synthesis method, which makes full use of similarity as prior knowledge to address this issue. our method is based on the proposed kernel similarity embedding, which can not only mitigate the high dimensionality and small sample issues, but also has the advantage of modeling nonlinear feature relationships. specifically, we first put forward two hypotheses that are essential for the dt model to generate new frames using similarity correlations. then, we integrate kernel learning and the extreme learning machine into a unified synthesis model to learn kernel similarity embeddings for representing dts. extensive experiments on dt videos collected from the internet and two benchmark datasets, i.e., gatech graphcut textures and dyntex, demonstrate that the learned kernel similarity embeddings can provide discriminative representations for dts. further, our method can preserve the long-term temporal continuity of the synthesized dt sequences with excellent sustainability and generalization. meanwhile, it effectively generates realistic dt videos with higher speed and lower computation than the current state-of-the-art methods. the code and more synthesis videos are available at our project page https://shiming-chen.github.io/similarity-page/similarit.html.",AB_0011
"a cross domain multistream classification is a challenging problem calling for fast domain adaptations to handle different but related streams in never-ending and rapidly changing environments. notwithstanding that existing multistream classifiers assume no labeled samples in the target stream, they still incur expensive labeling costs since they require fully labeled samples of the source stream. this article aims to attack the problem of extreme label shortage in the cross domain multistream classification problems where only very few labeled samples of the source stream are provided before process runs. our solution, namely, learning streaming process from partial ground truth (leopard), is built upon a flexible deep clustering network where its hidden nodes, layers, and clusters are added and removed dynamically with respect to varying data distributions. a deep clustering strategy is underpinned by a simultaneous feature learning and clustering technique leading to clustering-friendly latent spaces. a domain adaptation strategy relies on the adversarial domain adaptation technique where a feature extractor is trained to fool a domain classifier by classifying source and target streams. our numerical study demonstrates the efficacy of leopard where it delivers improved performances compared to prominent algorithms in 15 of 24 cases. source codes of leopard are shared in https://github.com/wengweng001/leopard.git to enable further study.",AB_0011
"the multilayer one-class classification (occ) frameworks have gained great traction in research on anomaly and outlier detection. however, most multilayer occ algorithms suffer from loosely connected feature coding, affecting the ability of generated latent space to properly generate a highly discriminative representation between object classes. to alleviate this deficiency, two novel occ frameworks, namely: 1) occ structure using the subnetwork neural network (oc-snn) and 2) maximum correntropy-based oc-snn (mcoc-snn), are proposed in this article. the novelties of this article are as follows: 1) the subnetwork is used to build the discriminative latent space; 2) the proposed models are one-step learning networks, instead of stacking feature learning blocks and final classification layer to recognize the input pattern; 3) unlike existing works which utilize mean square error (mse) to learn low-dimensional features, the mcoc-snn uses maximum correntropy criterion (mcc) for discriminative feature encoding; and 4) a brand-new occ dataset, called co-mask, is built for this research. experimental results on the visual classification domain with a varying number of training samples from 6131 to 513,061 demonstrate that the proposed oc-snn and mcoc-snn achieve superior performance compared to the existing multilayer occ models. for reproducibility, the source codes are available at https://github.com/w1ae/occ.",AB_0011
"a deep clustering network (dcn) is desired for data streams because of its aptitude in extracting natural features thus bypassing the laborious feature engineering step. while automatic construction of deep networks in streaming environments remains an open issue, it is also hindered by the expensive labeling cost of data streams rendering the increasing demand for unsupervised approaches. this article presents an unsupervised approach of dcn construction on the fly via simultaneous deep learning and clustering termed autonomous dcn (adcn). it combines the feature extraction layer and autonomous fully connected layer in which both network width and depth are self-evolved from data streams based on the bias-variance decomposition of reconstruction loss. the self-clustering mechanism is performed in the deep embedding space of every fully connected layer, while the final output is inferred via the summation of cluster prediction score. furthermore, a latent-based regularization is incorporated to resolve the catastrophic forgetting issue. a rigorous numerical study has shown that adcn produces better performance compared with its counterparts while offering fully autonomous construction of adcn structure in streaming environments in the absence of any labeled samples for model updates. to support the reproducible research initiative, codes, supplementary material, and raw results of adcn are made available in https://github.com/andriash001/autonomousdcn.git",AB_0011
"interpreting a large number of neurons in deep learning is difficult. our proposed 'classifier-decoder' architecture (cladec) facilitates the understanding of the output of an arbitrary layer of neurons or subsets thereof. it uses a decoder that transforms the incomprehensible representation of the given neurons to a representation that is more similar to the domain a human is familiar with. in an image recognition problem, one can recognize what information (or concepts) a layer maintains by contrasting reconstructed images of cladec with those of a conventional auto-encoder(ae) serving as reference. an extension of cladec allows trading comprehensibility and fidelity. we evaluate our approach for image classification using convolutional neural networks. we show that reconstructed visualizations using encodings from a classifier capture more relevant classification information than conventional aes. this holds although aes contain more information on the original input. our user study highlights that even non-experts can identify a diverse set of concepts contained in images that are relevant (or irrelevant) for the classifier. we also compare against saliency based methods that focus on pixel relevance rather than concepts. we show that cladec tends to highlight more relevant input areas to classification though outcomes depend on classifier architecture. code is at https://github.com/johntailor/cladec",AB_0011
"classical federated learning approaches incur significant performance degradation in the presence of non-independent and identically distributed (non-iid) client data. a possible direction to address this issue is forming clusters of clients with roughly iid data. most solutions following this direction are iterative and relatively slow, also prone to convergence issues in discovering underlying cluster formations. we introduce federated learning with taskonomy (flt) that generalizes this direction by learning the task relatedness between clients for more efficient federated aggregation of heterogeneous data. in a one-off process, the server provides the clients with a pretrained (and fine-tunable) encoder to compress their data into a latent representation and transmit the signature of their data back to the server. the server then learns the task relatedness among clients via manifold learning and performs a generalization of federated averaging. flt can flexibly handle a generic client relatedness graph, when there are no explicit clusters of clients, as well as efficiently decompose it into (disjoint) clusters for clustered federated learning. we demonstrate that flt not only outperforms the existing state-of-the-art baselines in non-iid scenarios but also offers improved fairness across clients. our codebase can be found at: https://github.com/hjraad/flt/",AB_0011
"in this brief, we investigate the problem of incremental learning under data stream with emerging new classes (senc). in the literature, existing approaches encounter the following problems: 1) yielding high false positive for the new class; i) having long prediction time; and 3) having access to true labels for all instances, which is unrealistic and unacceptable in real-life streaming tasks. therefore, we propose the k-nearest neighbor ensemble-based method (knnens) to handle these problems. the knnens is effective to detect the new class and maintains high classification performance for known classes. it is also efficient in terms of run time and does not require true labels of new class instances for model update, which is desired in real-life streaming classification tasks. experimental results show that the knnens achieves the best performance on four benchmark datasets and three real-world data streams in terms of accuracy and f1-measure and has a relatively fast run time compared to four reference methods. codes are available at https://github.com/ntriver/knnens.",AB_0011
"recently, there has been a trend in tracking to use more refined segmentation mask instead of coarse bounding box to represent the target object. some trackers proposed segmentation branches based on the tracking framework and maintain real-time speed. however, those trackers use a simple fcns structure and lack of the edge information modeling. this makes performance quite unsatisfactory. in this paper, we propose an edge-aware segmentation network, which uses the complementarity between target information and edge information to provide a more refined representation of the target. firstly, we use the high-level features of the tracking backbone network and the correlation features of the classification branch of the tracking framework to fuse, and use the target edge and target segmentation mask for simultaneous supervision to obtain an optimized high-level feature with rough edge information and target information. secondly, we use the optimized high-level features to guide the low-level features of the tracking backbone network to generate more refined edge features. finally, we use the refined edge features to fuse with the target features of each layer to generate the final mask. our approach has achieved leading performance on recent pixel-wise object tracking benchmark vot2020 and segmentation datasets davis2016 and davis2017 while running on 47 fps. code is available at https://github.com/tjummg/eattracker.",AB_0011

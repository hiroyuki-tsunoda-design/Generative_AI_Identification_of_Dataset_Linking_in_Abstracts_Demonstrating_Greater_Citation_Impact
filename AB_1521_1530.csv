AB,NO
"precise and continuous monitoring of long-term carbon dioxide (co2) and methane (ch4) over the globe is of great importance, which can help study global warming and achieve the goal of carbon neutrality. nevertheless, the available observations of co2 and ch4 from satellites are generally sparse, and current fusion methods to reconstruct their long-term values on a global scale are few. to address this problem, we propose a novel spatiotemporally self-supervised fusion method to establish long-term daily seamless xco2 and xch4 products from 2010 to 2020 over the globe on grids of 0.25 degrees. a total of three datasets are applied in our study, including the greenhouse gases observing satellite (gosat), the orbiting carbon observatory 2 (oco-2), and cams global greenhouse gas reanalysis (cams-egg4). attributed to the significant sparsity of data from gosat and oco-2, the spatiotemporal discrete cosine transform is considered for our fusion task. validation results show that the proposed method achieves a satisfactory accuracy, with standard deviations of bias (sigma) of similar to 1:18 ppm for xco2 and 11.3 ppb for xch4 against total carbon column observing network (tccon) measurements from 2010 to 2020. meanwhile, the determination coefficients (r-2) of xco2 and xch4 reach 0.91 or 0.95 (2010-2014 or 2015-2020) and 0.9 (2010-2020), respectively, after fusion. overall, the performance of fused results distinctly exceeds that of cams-egg4, which is also superior or close to those of gosat and oco-2. in particular, our fusion method can effectively correct the large biases in cams-egg4 due to the issues from assimilation data, such as the unadjusted anthropogenic emission inventories for covid-19 lockdowns in 2020. moreover, the fused results present coincident spatial patterns with gosat and oco-2, which accurately display the long-term and seasonal changes in globally distributed xco2 and xch4. the daily global seamless gridded (0.25 degrees) xco2 and xch4 from 2010 to 2020 can be freely accessed at https://doi.org/10.5281/zenodo.7388893 (wang et al., 2022a).",AB_0153
"background: sexually transmitted infections (stis) remain a significant public health concern, particularly among young adults, and chlamydia trachomatis (ct) infections are the most common stis in young women. one of the most effective ways to prevent stis is the consistent use of condoms during sexual intercourse. there has been no economic evaluation of the interactive web-based sexual health program, smart girlfriend, within the chinese population. objective: this study aimed to evaluate the long-term cost-effectiveness of smart girlfriend in preventing stis in the chinese population. the evaluation compared the program with a control intervention that used a 1-page information sheet on condom use. methods: a decision-analytic model that included a decision tree followed by a markov structure of ct infections was developed since ct is the most prevalent sti among young women. the model represents the long-term experience of individuals who received either the intervention or the control. one-way and probabilistic sensitivity analyses were conducted. the main outcomes were the number of ct infections and the incremental cost as per quality-adjusted life year (qaly). results: a cohort of 10,000 sexually active nonpregnant young women initially entered the model in a noninfectious state (ie, well). in the base-case analysis, the implementation of the smart girlfriend program resulted in the prevention of 0.45% of ct infections, 0.3% of pelvic inflammatory disease, and 0.04% of chronic pelvic pain, leading to a gain of 70 discounted qalys and cost savings over a 4-year time horizon, compared to the control group. with more than 4548 users, the intervention would be cost-effective, and with more than 8315 users, the intervention would be cost saving. a 99% probability of being cost-effective was detected with a willingness to pay us $17,409 per qaly. conclusions: smart girlfriend is a cost-effective and possibly cost-saving program over a 4-year time horizon. this result was particularly sensitive to the number of website users; launching the website would be cost-effective if more than 4548 people used it. further work is warranted to explore if the findings could be expanded to apply to women who have sex with women and in the context of other stis. trial registration: clinicaltrial.gov nct03695679; https://clinicaltrials.gov/study/nct03695679",AB_0153
"accurate detection of apple diseases is crucial for agricultural production as it enables timely diagnosis and control, thereby reducing crop yield losses. however, detecting apple leaf spots presents significant challenges due to unconstrained environmental conditions and multi-scale variations. this paper proposes a novel deep learning-based detection algorithm to accurately detect multi-scale apple leaf spots in unconstrained environments. the proposed method consists of several steps. first, a dataset of apple leaf disease spots with high-quality labels is created under the guidance of agricultural experts. second, a bole convolution module (bcm) for reducing the interference of redundant feature information on extracting feature information of apple leaf disease images in unconstrained environments is designed. third, a cross-attention module (cam) for reducing the computational effort of the detection network in non-diseased regions to reduce the impact of background interference information on the feature representation capability of the network is proposed. fourth, to reduce the loss of surface and deep feature information of apple leaf diseases during feature fusion and communication, we employ a bidirectional transposition feature pyramid network (btfpn) to address this problem. finally, the proposed apple leaf disease detection network, which combines the bole convolution module, cross-attention module, and bidirectional transposed feature pyramid network (bctnet), achieves an accuracy of 85.23% and an average detection speed of 33 fps on the self-built dataset. the proposed method outperforms other stateof-the-art methods in terms of accuracy. from visible light images, it can detect multi-scale disease spots on apple leaf surfaces in natural environments and provide decision information to growers and pesticide spraying robots. the proposed method can replace traditional manual diagnosis methods, optimize the spraying efficiency of pesticide robots, and reduce pesticide waste in non-diseased areas. part of the dataset used in this paper can be found in the https://github.com/zhouguoxiong/bctnet.",AB_0153
"video semantic segmentation has achieved great success, which is significant for road scene understanding. however, semantic segmentation remains challenging in poor illumination and inclement weather. thermal camera, highly invariant to light and highly penetrating to rain and fog, enables semantic segmentation to work under challenging conditions. thus, this paper explores semantic segmentation in thermal videos to broaden the scope of the application of road scene understanding. we offer the first thermal video semantic segmentation dataset tvss including 1695 thermal videos with 50850 frames in road scenes. it is available at: https://xzbai.buaa.edu.cn/datasets.html. tvss is finely annotated by 17 categories at the frame rate of 1fps, with a labeled pixel density of 98.9%. existing video semantic segmentation methods rely on the amount of labels and the representation power of backbones, which cannot achieve ideal results on thermal videos. thus, we introduce a multi-granularity contrastive learning based thermal video semantic segmentation model (mgcl), which explores the abundant unlabeled frames to boost the supervised segmentation. specifically, mgcl constructs multi-granularity self-supervised signals on unlabeled thermal videos by contrastive learning, including the intra-frame context generalization loss, the intra-clip temporal consistency loss, and the inter-video category discrimination loss. in addition, a hard anchor sampling strategy is introduced to focus on hard-classify pixels for further performance improvement. extensive experiments on tvss demonstrate the superior performance of mgcl in both accuracy and efficiency. compared to the 12 state-of-the-art semantic segmentation methods, mgcl achieves 2.8% to 8.1% gains in miou performance while maintaining the inference speed.",AB_0153
"large-scale and multi-annual maps of building rooftop area (bra) are crucial for addressing policy decisions and sustainable development. in addition, as a fine-grained indicator of human activities, bra could contribute to urban planning and energy modeling to provide benefits to human well-being. however, it is still challenging to produce a large-scale bra due to the rather tiny sizes of individual buildings. from the viewpoint of classification methods, conventional approaches utilize high-resolution aerial images (metric or submetric resolution) to map bra; unfortunately, high-resolution imagery is both infrequently captured and expensive to purchase, making the bra mapping costly and inadequate over a consistent spatiotemporal scale. from the viewpoint of learning strategies, there is a nontrivial gap that persists between the limited training references and the applications over geospatial variations. despite the difficulties, existing large-scale bra datasets, such as those from microsoft or google, do not include china, and hence there are no full-coverage maps of bra in china yet. in this paper, we first propose a deep-learning method, named the spatio-temporal aware super-resolution segmentation framework (stsr-seg), to achieve robust super-resolution bra extraction from relatively low-resolution imagery over a large geographic space. then, we produce the multi-annual china building rooftop area (cbra) dataset with 2.5 m resolution from 2016-2021 sentinel-2 images. cbra is the first full-coverage and multi-annual bra dataset in china. with the designed training-sample-generation algorithms and the spatiotemporally aware learning strategies, cbra achieves good performance with a f1 score of 62.55 % (+10.61 % compared with the previous bra data in china) based on 250 000 testing samples in urban areas and a recall of 78.94 % based on 30 000 testing samples in rural areas. temporal analysis shows good performance consistency over years and good agreement with other multi-annual impervious surface area datasets. stsr-seg will enable low-cost, dynamic, and large-scale bra mapping (https://github.com/zpl99/stsr-seg, last access: 12 july 2023). cbra will foster the development of bra mapping and therefore provide basic data for sustainable research (liu et al., 2023; ).",AB_0153
"there has been steady progress in the field of deep learning-based blood vessel segmentation. however, several challenging issues still continue to limit its progress, including inadequate sample sizes, the neglect of contextual information, and the loss of microvascular details. to address these limitations, we propose a dual-path deep learning framework for blood vessel segmentation. in our framework, the fundus images are divided into concentric patches with different scales to alleviate the overfitting problem. then, a multi-scale context dense aggregation network (mcdau-net) is proposed to accurately extract the blood vessel boundaries from these patches. in mcdau-net, a cascaded dilated spatial pyramid pooling (cdspp) module is designed and incor-porated into intermediate layers of the model, enhancing the receptive field and producing feature maps enriched with contextual information. to improve segmentation performance for low-contrast vessels, we pro-pose an inceptionconv (iconv) module, which can explore deeper semantic features and suppress the propa-gation of non-vessel information. furthermore, we design a multi-scale adaptive feature aggregation (mafa) module to fuse the multi-scale feature by assigning adaptive weight coefficients to different feature maps through skip connections. finally, to explore the complementary contextual information and enhance the continuity of microvascular structures, a fusion module is designed to combine the segmentation results obtained from patches of different sizes, achieving fine microvascular segmentation performance. in order to assess the effectiveness of our approach, we conducted evaluations on three widely-used public datasets: drive, chase-db1, and stare. our findings reveal a remarkable advancement over the current state-of-the-art (sota) techniques, with the mean values of se and f1 scores being an increase of 7.9% and 4.7%, respectively. the code is available at https://github.com/bai101315/mcdau-net.",AB_0153
"detonation has promising applications in advanced propulsion systems, and numerical simulation is widely used to gain insights into the complex interaction between the hydrodynamic flow and chemical reactions involved in detonation. in this work, detonationfoam, an open-source solver for accurate and efficient simulation of compressible reactive flow and detonation are developed based on openfoam. detonationfoam can simulate compressible, multi-component, reactive flow and it can accurately evaluate the detailed transport coefficients using the mixture-averaged transport model. compared to rhocentralfoam, the improved hllc-p approximate riemann solver is used in detonationfoam and it helps to accurately resolve shock waves appearing in detonation. besides, the adaptive mesh refinement and dynamic load balancing algorithms are used in detonationfoam, which greatly improves the computational efficiency. validation tests including homogenous ignition, unsteady diffusion, shock tube problem, premixed flame, planar detonation, double mach reflection, detonation cellular structure and oblique detonation wave are conducted. these tests demonstrate that detonationfoam can be used to accurately and efficiently to simulate the compressible, multi-component reactive flow and detonation processes. program summary program title: detonationfoam cpc library link to program files: https://doi .org /10 .17632 /x45zh4nz28 .1 developer's repository link: https://github .com /jiesun -pku /detonationfoam licensing provisions: gplv3 programming language: c++ nature of problem: gaseous detonation involves different length scales and complicated chemistry. to accurately and efficiently simulate the gaseous detonation, adaptive mesh refinement needs to be conducted and detailed chemistry should be considered. besides, the severe load imbalance caused by the chemical source term evaluation may greatly reduce the computation efficiency. solution method: an open-source solver, detonationfoam is developed based on openfoam. the species equations considering detailed chemistry are solved in detonationfoam and thereby detonation in a compressible, multi-component, reactive flow can be simulated. the adaptive mesh refinement technique and the dynamic load balancing algorithm are incorporated into detonationfoam. it is demonstrated that detonationfoam can accurately and efficiently simulate gaseous detonation. & copy; 2023 elsevier b.v. all rights reserved.",AB_0153
"more recently, vision transformer (vit) has shown competitive performance with convolutional neural network (cnn) on computer vision tasks, which provided more possibilities for accurate classification of hyperspectral image (hsi). however, whether cnn or vit, they generally only focus on single type of feature, resulting in insufficient information utilization. for instance, cnn has powerful local feature extraction ability, while vit pays more attention to long-range dependencies and global features. to consider multiple types of feature information, we propose a multiple vision architectures-based hybrid network (mvahn) for hsi classification, which consists of joint cnn and transformer (jct) structure and graph convolutional module (gcm). firstly, jct successfully embeds convolution operations into vit to capture local and global features, which mainly include: 1) a spectral spatial convolution block (sscb) is proposed to unearth local spectral spatial features. 2) a convolution embedding is aggregated into self-attention to design a local-global attention (lga) mechanism, which can realize the seamless integration of cnn and vit, thereby capturing local-global combined features. secondly, a plug-and-play gcm is developed in parallel with transformer encoders to further improve the model classification ability by mining the similarity relationship between pixels in hsi. overall, an elegant integration of these seemingly distinct paradigms is realized by mvahn to capture multiple types of feature information. the overall accuracies (oas) of mvahn on pavia university, houston 2013, salinas valley, kennedy space center, indian pines and botswana datasets are 96.37%, 88.33%, 97.57%, 98.96%, 96.25% and 99.26%, respectively. compared with the state-of-the-art hybrid models, mvahn achieves competitive classification results. the source code will be available at https://github.com/zjier/mvahn.",AB_0153
"background and objective: nuclear segmentation in cervical cell images is a crucial technique for automatic cytopathology diagnosis. experimental evaluation of nuclear segmentation methods with datasets is helpful in promoting the advancement of nuclear segmentation techniques. however, public datasets are not enough for a reasonable and comprehensive evaluation because of insufficient quantity, single data source, and low segmentation difficulty.methods: therefore, we provide the largest dataset for cervical nuclear segmentation (cnseg). it contains 124,000 annotated nuclei collected from 1,530 patients under different conditions. the image styles in this dataset cover most practical application scenarios, including microbial infection, cytopathic heterogeneity, overlapping nuclei, etc. to evaluate the performance of segmentation methods from different aspects, we divided the cnseg dataset into three subsets, namely the patch segmentation dataset (patchseg) with nuclei images collected under complex conditions, the cluster segmentation dataset (clusterseg) with cluster nuclei, and the domain segmentation dataset (domainseg) with data from different domains. furthermore, we propose a postprocessing method that processes overlapping nuclei single ones.results and conclusion: experiments show that our dataset can comprehensively evaluate cervical nuclear segmentation methods from different aspects. we provide guidelines for other researchers to use the dataset. https://github .com /jingzhaohlj /al -net",AB_0153
"objective: cognitive impairment is a detrimental complication of stroke that compromises the quality of life of the patients and poses a huge burden on society. due to the lack of effective early prediction tools in clinical practice, many researchers have introduced machine learning (ml) into the prediction of post-stroke cognitive impairment (psci). however, the mathematical models for ml are diverse, and their accuracy remains highly contentious. therefore, this study aimed to examine the efficiency of ml in the prediction of psci. methods: relevant articles were retrieved from cochrane, embase, pubmed, and web of science from the inception of each database to 5 december 2022. study quality was evaluated by probast, and c-index, sensitivity, specificity, and overall accuracy of the prediction models were meta-analyzed. results: a total of 21 articles involving 7,822 stroke patients (2,876 with psci) were included. the main modeling variables comprised age, gender, education level, stroke history, stroke severity, lesion volume, lesion site, stroke subtype, white matter hyperintensity (wmh), and vascular risk factors. the prediction models used were prediction nomograms constructed based on logistic regression. the pooled c-index, sensitivity, and specificity were 0.82 (95% ci 0.77-0.87), 0.77 (95% ci 0.72-0.80), and 0.80 (95% ci 0.71-0.86) in the training set, and 0.82 (95% ci 0.77-0.87), 0.82 (95% ci 0.70-0.90), and 0.80 (95% ci 0.68-0.82) in the validation set, respectively. conclusion: ml is a potential tool for predicting psci and may be used to develop simple clinical scoring scales for subsequent clinical use. systematic review registration: https://www.crd.york.ac.uk/prospero/display_record.php? recordid=383476.",AB_0153

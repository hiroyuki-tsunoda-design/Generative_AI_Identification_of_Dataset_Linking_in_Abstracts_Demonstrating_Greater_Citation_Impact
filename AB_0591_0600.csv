AB,NO
"we present graph mapping - a simple and effective computerized test of fluid intelligence (reasoning ability). the test requires structure mapping - a key component of the reasoning process. participants are asked to map a pair of corresponding nodes across two mathematically isomorphic but visually different graphs. the test difficulty can be easily manipulated - the more complex structurally and dissimilar visually the graphs, the higher response error rate. graph mapping offers high flexibility in item generation, ranging from trivial to extremally difficult items, supporting progressive item sequences suitable for correlational studies. it also allows multiple item instances (clones) at a fixed difficulty level as well as full item randomization, both particularly suitable for within-subject experimental designs, longitudinal studies, and adaptive testing. the test has short administration times and is unfamiliar to participants, yielding practical advantages. graph mapping has excellent psychometric properties: its convergent validity and reliability is comparable to the three leading traditional fluid reasoning tests. the convenient software allows a researcher to design the optimal test variant for a given study and sample. graph mapping can be downloaded from: https://osf. io/wh7zv/.",AB_0060
"deep reinforcement learning (drl) is a promising way to achieve human-like autonomous driving. however, the low sample efficiency and difficulty of designing reward functions for drl would hinder its applications in practice. in light of this, this article proposes a novel framework to incorporate human prior knowledge in drl, in order to improve the sample efficiency and save the effort of designing sophisticated reward functions. our framework consists of three ingredients, namely, expert demonstration, policy derivation, and rl. in the expert demonstration step, a human expert demonstrates their execution of the task, and their behaviors are stored as state-action pairs. in the policy derivation step, the imitative expert policy is derived using behavioral cloning and uncertainty estimation relying on the demonstration data. in the rl step, the imitative expert policy is utilized to guide the learning of the drl agent by regularizing the kl divergence between the drl agent's policy and the imitative expert policy. to validate the proposed method in autonomous driving applications, two simulated urban driving scenarios (unprotected left turn and roundabout) are designed. the strengths of our proposed method are manifested by the training results as our method can not only achieve the best performance but also significantly improve the sample efficiency in comparison with the baseline algorithms (particularly 60% improvement compared with soft actor-critic). in testing conditions, the agent trained by our method obtains the highest success rate and shows diverse and human-like driving behaviors as demonstrated by the human expert. we also find that using the imitative expert policy trained with the ensemble method that estimates both policy and model uncertainties, as well as increasing the training sample size, can result in better training and testing performance, especially for more difficult tasks. as a result, the proposed method has shown its potential to facilitate the applications of drl-enabled human-like autonomous driving systems in practice. the code and supplementary videos are also provided. [https://mczhi.github.io/expert-prior-rl/]",AB_0060
"microalgae have received increasing attention as one of the most promising feedstocks in the development of new healthier food products and different strategies have been at-tempted to improve their growth. however, the high production costs and low pro-ductivities, commonly associated with photoautotrophic growths, are still a big challenge. in this study, a two-step optimization strategy was carried out in order to maximize the biomass production of a chlorella vulgaris strain used at industrial scale under hetero-trophic conditions. from a total of 24 independent variables, which were studied si-multaneously, 10 have presented a positive effect over xmax, while the remaining have shown to be negative. the amount of (nh4)2so4 (6.3 g l-1), mgso4middot7h2o (0.7 g l-1), and c6h12o6 (50% w/v) in the culture medium has revealed to be the only factors with a sig-nificant impact on biomass concentration, with optimum values of 25.5, 64.6, and 75 ml.l-1, respectively. the optimized medium resulted in an improvement of the xmax by 99.6% when compared to the growth medium applied at industrial scale, proving the success of this strategy. additionally, the carbohydrates production was enhanced by 48.0%.(c) 2022 the author(s). published by elsevier ltd on behalf of institution of chemical engineers. this is an open access article under the cc by-nc-nd license (http://creati-vecommons.org/licenses/by-nc-nd/4.0/).",AB_0060
"background: the de novo assembly of raw sequence data is key in metagenomic analysis. it allows recovering draft genomes from a pool of mixed raw reads, yielding longer sequences that offer contextual information and provide a more complete picture of the microbial community.findings: to better compare de novo assemblers for metagenomic analysis, lmas (last metagenomic assembler standing) was developed as a flexible platform allowing users to evaluate assembler performance given known standard communities. overall, in our test datasets, k-mer de bruijn graph assemblers outperformed the alternative approaches but came with a greater computational cost. furthermore, assemblers branded as metagenomic specific did not consistently outperform other genomic assemblers in metagenomic samples. some assemblers still in use, such as abyss, metahipmer2, minia, and velvetoptimiser, perform relatively poorly and should be used with caution when assembling complex samples. meaningful strain resolution at the single-nucleotide polymorphism level was not achieved, even by the best assemblers tested.conclusions: the choice of a de novo assembler depends on the computational resources available, the replicon of interest, and the major goals of the analysis. no single assembler appeared an ideal choice for short-read metagenomic prokaryote replicon assembly, each showing specific strengths. the choice of metagenomic assembler should be guided by user requirements and characteristics of the sample of interest, and lmas provides an interactive evaluation platform for this purpose. lmas is open source, and the workflow and its documentation are available at https://github.com/b-ummi/lmas and https://lmas.readthedocs.io/, respectively.",AB_0060
"background: d-beta-hydroxybutyrate-(r)-1,3 butanediol - a non-racemic ketone monoester for ingestion - has emerged as an effective way to achieve acute nutritional ketosis. whether white adipose tissue plays a role in effects of acute nutritional ketosis is largely unknown. objective: to investigate the effects of acute nutritional ketosis on plasma levels of asprosin and leptin and if they are affected by abdominal fat phenotypes. methods: the design was a randomised crossover trial. participants received either the d-beta-hydroxybutyrate-(r)-1,3 butanediol monoester (ke beta hb) drink or placebo drink. blood samples were collected at baseline, 30, 60, 90, 120, and 150 minutes. 3.0 tesla magnetic resonance imaging was used to measure visceral and subcutaneous fat volumes (vfv and sfv, respectively), intra-hepatic fat deposition (ihfd), and intra-pancreatic fat deposition (ipfd). results: a total of 18 adults were randomised, with no drop-outs. there were no significant differences in plasma levels of asprosin and leptin (p = 0.808 and p = 0.907, respectively) between the ke beta hb and placebo drinks. there was no effect of time, treatment, or interaction between time and treatment on asprosin and leptin. after stratification by the vfv/sfv ratio, ihfd, and ipfd, there were no differences in asprosin and leptin between the ke beta hb and placebo drinks. conclusion: plasma levels of asprosin and leptin were not significantly affected by acute nutritional ketosis. abdominal fat phenotypes did not significantly affect circulating levels of the two hormones. white adipose tissue does not appear to play a role in altering hormone levels during acute nutritional ketosis. the clinical trial registry number is nct03889210 (https://clinicaltrials.gov).",AB_0060
"sequence homology is a basic concept in protein evolution, structure and function studies. however, there are not many different tools and services for homology searches being sensitive, accurate and fast at the same time. we present a new web server for protein analysis based on comer2, a sequence alignment and homology search method that exhibits these characteristics. comer2 has been upgraded since its last publication to improve its alignment quality and ease of use. we demonstrate how the user can benefit from using it by providing examples of extensive annotation of proteins of unknown function. among the distinctive features of the web server is the user's ability to submit multiple queries with one click of a button. this and other features allow for transparently running homology searches-in a command-line, programmatic or graphical environment-across multiple databases with multiple queries. they also promote extensive simultaneous protein analysis at the sequence, structure and function levels. availability and implementation: the comer web server is available at https://bioinformatics.lt/comer.",AB_0060
"the study of the suitability of two isolation processes to produce cellulose nanofibers (cnfs) from salicornia ramosissima waste, with potential applicability as a reinforcing agent of polymeric composites was carried out. to separate the cellulose fibrils from the cell wall and obtain cnfs an alkaline treatment was applied followed by a bleaching treat-ment and, the insoluble residue was next hydrolyzed by either an acid treatment (at) or an enzyme treatment (et). sem and tem images indicated fiber exposure caused by both treatments. the diameter, length, aspect ratio, and polydispersity index, were measured for both cnfs. cnf (et) showed high zeta potential values suggesting that et produces more electrically stable and thinner nanofibers. the ftir spectra revealed that both treatments effectively removed the amorphous components allowing the cnfs isolation, and xrd patterns evidenced the increase in the degree of crystallinity of both cnfs. nonetheless, cnf(at) presented a lower mechanical resistance due to its smaller particle size, compared to the cnf(et). in summary, the (et) could successfully isolate cnfs from the salicornia waste, encouraging the use of this treatment, once when compared to (at), it does not generate toxic residues, presents mild thermal conditions, and produces cnfs with higher-value applications.(c) 2022 the author(s). published by elsevier ltd on behalf of institution of chemical engineers. this is an open access article under the cc by-nc-nd license (http://creati-vecommons.org/licenses/by-nc-nd/4.0/).",AB_0060
"we draw from the assumption that similarities between pathogens at both pathogen protein and host protein level, may provide the appropriate framework to identify and rank candidate drugs to be used against a specific pathogen. vir2drug is a drug repurposing tool that uses network -based approaches to identify and rank candidate drugs for a specific pathogen, combining information obtained from: (a) ranked pathogen -to -pathogen networks based on protein similarities between pathogens, (b) taxonomy distance between pathogens and (c) drugs targeting specific pathogen's and host proteins. the underlying pathogen networks are used to screen drugs by means of specific methodologies that account for either the host or pathogen's protein targets. vir2drug is a useful and yet informative tool for drug repurposing against known or unknown pathogens especially in periods where the emergence for repurposed drugs plays significant role in handling viral outbreaks, until reaching a vaccine. the web tool is available at: https://bioinformatics.cing.ac.cy/vir2 drug, https://vir2drug.cing-big.hpcf.cyi.ac.cy",AB_0060
"the simple python ipywidgets notebook interface to obtain the optoelectronic properties of materials (spin) is an open source graphical user interface that allows users to work with standard siesta files and perform end-to-end atomic level simulation processes. it contains the complete flow, from the construction and visualization of structures or systems until the pre-processing, execution, and post-processing of calculations such as structure optimization, electronic properties like band structure, density of states (dos), and optical properties. spin is an easy-to-use and fast-learning solution written in python and built from ipywidgets. however, the end-user can use all available features without the need for python language knowledge. program summary program title: spin cpc library link to program files: https://doi .org /10 .17632 /5w2fjk4h3y.1 developer's repository link: https://github .com /josemvergara /spin licensing provisions: mit programming language: python nature of problem: the program can be used in complete workflow in which fundamental elements in the atomic level simulation of materials are integrated. solution method: spin, is an open source graphical user interface that seeks to integrate a set of tools and packages to provide an intuitive, easy-to-use and fast-learning solution, given the possibility to make different processes such as the construction and visualization of structures or systems and the pre-processing, execution, and post-processing of calculations. spin is an ipywidgets based interface that allow users to work easily in any operating system (windows, linux and mac), because it works on jupyter notebooks. (c) 2022 elsevier b.v. all rights reserved.",AB_0060
"collaborative training of deep neural networks using edge devices has attracted substantial research interest recently. the two main architecture approaches for the training process are centrally orchestrated federated learning and fully decentralized peer-to-peer learning. in decentralized systems, edge devices, known as agents, collaborate in a peer-to-peer architecture, avoiding the need for a central system to orchestrate the process. decentralized peer-to-peer (p2p) learning techniques are well researched under the assumption of independent and identically distributed (iid) data across the agents. iid data is seldom observed in real-world distributed systems, and the training performance varies significantly with non-iid data. this paper proposes a decentralized learning variant of the p2p gossip averaging method with batch normalization (bn) adaptation for p2p architectures. it is well-known that bn layers accelerate the convergence of the non-distributed deep learning models. recent research confirms that federated learning methods benefit from using the bn method with some aggregation alterations. our work demonstrated bn effectiveness in p2p architectures by mitigating the non-iid data characteristics across decentralized agents. we also introduce a variant of the early stopping technique that, combined with bn layers, acts as a fine-tuning technique for agent models. we validated our approach by conducting numerous simulations of different model-topology-communication combinations and comparing them to other decentralized baseline approaches. the evaluations were conducted on the next word prediction task using user comments from the reddit and stackoverflow datasets representing comments from two different domains. simulations showed that our approach, on average, achieves a mean relative top accuracy increase of 16.9% in ring (19.9% for reddit, 13.9% for stackoverflow) and 29.8% in sparse (32.9% for reddit, 26.6% for stackoverflow) communication topologies compared to the best baseline approach. our code is available at https://github.com/fipu- lab/p2p_bn.",AB_0060

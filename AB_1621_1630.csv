AB,NO
"in this paper, a metaheuristic algorithm called pid-based search algorithm (psa) is proposed for global optimization. the algorithm is based on an incremental pid algorithm that converges the entire population to an optimal state by continuously adjusting the system deviations. psa is mathematically modeled and implemented to achieve optimization in a wide range of search spaces. psa is used to solve cec2017 benchmark test functions and six constrained problems. the optimization performance of psa is verified by comparing it with seven metaheuristics proposed in recent years. the kruskal-wallis, holm and friedman tests verified the superiority of psa in terms of statistical significance. the results show that psa can be better balanced exploration and exploitation with strong optimization capability. source codes of psa are publicly available at https://ww2.math works.cn/matlabcentral/fileexchange/131534-pid-based-search-algorithm.",AB_0163
"the quantification of large-scale leaf-age-dependent leaf area index has been lacking in tropical and subtropical evergreen broadleaved forests (tefs), despite the recognized importance of leaf age in influencing leaf photosynthetic capacity in this biome. here, we simplified the canopy leaves of tefs into three age cohorts (i.e., young, mature, and old, with different photosynthesis capacities; i.e., v-c,v-max) and proposed a novel neighbor-based approach to develop the first gridded dataset of a monthly leaf-age-dependent leaf area index (lai) product (referred to as lad-lai) at 0.25 degrees spatial resolution over the continental scale during 2001-2018 from satellite observations of sun-induced chlorophyll fluorescence (sif) that was reconstructed from modis and tropomi (the tropospheric monitoring instrument). the new lad-lai products show good performance in capturing the seasonality of three lai cohorts, i.e., young (lai(young); the pearson correlation coefficient of r = 0 :36), mature (lai(mature); r = 0 :77), and old (lai(old); r = 0 :59) leaves at eight camera-based observation sites (four in south america, three in subtropical asia, and one in the democratic republic of the congo(drc)) and can also represent their interannual dynamics, validated only at the barro colorado site, with r being equal to 0.54, 0.64, and 0.49 for lai(young), lai(mature), and lai(old), respectively. additionally, the abrupt drops in lai(old) are mostly consistent with the seasonal litterfall peaks at 53 in situ measurements across the whole tropical region (r = 0 :82). the lai seasonality of young and mature leaves also agrees well with the seasonal dynamics of the enhanced vegetation index (evi; r = 0 :61), which is a proxy for photosynthetically effective leaves. spatially, the gridded lad-lai data capture a dry-season green-up of canopy leaves across the wet amazonian areas, where mean annual precipitation exceeds 2000 mmyr(-1), consistent with previous satellite-based analyses. the spatial patterns clustered from the three lai cohorts also coincide with those clustered from climatic variables over the whole tef region. herein, we provide the average seasonality of three lai cohorts as the main dataset and their time series as a supplementary dataset. these lad-lai products are available at https://doi.org/10.6084/m9.figshare.21700955.v4 (yang et al., 2022).",AB_0163
"medical image segmentation is essential in medical image analysis since it can provide reliable assistance in computer-aided clinical diagnosis, treatment planning, and intervention. although deep learning algorithms based on cnns and transformers have made notable progress in medical image segmentation, it is still chal-lenging owing to the objects with complex structures, low discrimination and differences between individuals. to alleviate these issues, we propose a novel 3d medical image segmentation network based on transformers and cnns combining morphological information and reticular mechanism. firstly, the morphological constraint stream is designed to learn the prior shape information based on the cnn model and make the attention maps focus on target tasks for enhancing the interpretability. secondly, the reticular transformer is utilized to obtain multi-scale information based on the transformer, which can bind the local texture information and underlying semantic information to further acquire the feature maps with sufficient details and receptive field. the ex-periments demonstrate that our proposed method outperforms many existing segmentation models in terms of the performance in metrics dsc and hd (80.46% in dsc on the synapse dataset and 90.83% in dsc on the acdc dataset). the code will be released at https://github.com/rocklijun/mcrformer.",AB_0163
"the capability of partially penetrating vegetation canopy and efficiently collecting high-precision point clouds over large areas makes airborne laser scanning (als) a valuable tool for various geospatial applications. however, automated ground filtering (gf), one fundamental and challenging step for most als applications, has remained a widely researched yet unsolved problem for decades. the recent breakthroughs in supervised deep learning (dl) techniques, which rely on sufficient and high-quality labeled datasets, provide a new solution to better solve this problem. unfortunately, public 3d geospatial datasets are scarce, especially for those tailored for the landform-scale gf task. moreover, whether advanced deep neural networks (dnns) can be well-scaled to the problem of gf remains an open question. to comprehensively advance the development of effective dl-based gf pipelines, we first publish an ultra-large-scale gf dataset built upon open-access als point clouds of four different countries worldwide, which covers over 47 km' and nine different terrain scenes. then, multiple attractive advantages of dl techniques in gf are evaluated through extensive experimental comparisons with traditional gf methods on the presented dataset. furthermore, we reveal several issues faced by generalizing existing advanced 3d dnns into gf tasks with a series of in-depth experimental analyses. finally, some promising directions for future research are suggested in response to the identified challenges. our dataset, named opengf, is available at https://github.com/nathan-uw/opengf.",AB_0163
"single-cell rna sequencing (scrna-seq) is now a successful technique for identifying cellular heterogeneity, revealing novel cell subpopulations, and forecasting developmental trajectories. a crucial component of the processing of scrna-seq data is the precise identification of cell subpopulations. although many unsupervised clustering methods have been developed to cluster cell subpopulations, the performance of these methods is vulnerable to dropouts and high dimensionality. in addition, most existing methods are time-consuming and fail to adequately account for potential associations between cells. in the manuscript, we present an unsupervised clustering method based on an adaptive simplified graph convolution model called scasgc. the proposed method builds plausible cell graphs, aggregates neighbor information using a simplified graph convolution model, and adaptively determines the most optimal number of convolution layers for various graphs. experiments on 12 public datasets show that scasgc outperforms both classical and state-of-the-art clustering methods. in addition, in a study of mouse intestinal muscle containing 15,983 cells, we identified distinct marker genes based on the clustering results of scasgc. the source code of scasgc is available at https://github.com/zzzoctopus/scasgc.",AB_0163
"generative adversarial networks (gans) and their variants as an effective method for generating visually appealing images have shown great potential in different medical imaging applications during past decades. however, some issues remain insufficiently investigated: many models still suffer from model collapse, vanishing gradients, and convergence failure. considering the fact that medical images differ from typical rgb images in terms of complexity and dimensionality, we propose an adaptive generative adversarial network, namely medgan, to mitigate these issues. specifically, we first use wasserstein loss as a convergence metric to measure the convergence degree of the generator and the discriminator. then, we adaptively train medgan based on this metric. finally, we generate medical images based on medgan and use them to build few -shot medical data learning models for disease classification and lesion localization. on demodicosis, blister, molluscum, and parakeratosis datasets, our experimental results verify the advantages of medgan in model convergence, training speed, and visual quality of generated samples. we believe this approach can be generalized to other medical applications and contribute to radiologists' efforts for disease diagnosis. the source code can be downloaded at https://github.com/geyao-c/medgan.",AB_0163
"brain function connectivity, derived from functional magnetic resonance imaging (fmri), has enjoyed high popularity in the studies of autism spectrum disorder (asd) diagnosis. albeit rapid progress has been made, most studies still suffer from several knotty issues: (1) the hardship of modeling the sophisticated brain neuronal connectivity; (2) the mismatch of identically graph node setup to the variations of different brain regions; (3) the dimensionality explosion resulted from excessive voxels in each fmri sample; (4) the poor interpretability giving rise to unpersuasive diagnosis. to ameliorate these issues, we propose a position-aware graph-convolution-network-based model, namely plsnet, with superior accuracy and compelling built-in interpretability for asd diagnosis. specifically, a time-series encoder is designed for context-rich feature extraction, followed by a function connectivity generator to model the correlation with long range dependencies. in addition, to discriminate the brain nodes with different locations, the position embedding technique is adopted, giving a unique identity to each graph region. we then embed a rarefying method to sift the salient nodes during message diffusion, which would also benefit the reduction of the dimensionality complexity. extensive experiments conducted on autism brain imaging data exchange demonstrate that our plsnet achieves stateof-the-art performance. notably, on cc200 atlas, plsnet reaches an accuracy of 76.4% and a specificity of 78.6%, overwhelming the previous state-of-the-art with 2.5% and 6.5% under five-fold cross-validation policy. moreover, the most salient brain regions predicted by plsnet are closely consistent with the theoretical knowledge in the medical domain, providing potential biomarkers for asd clinical diagnosis. our code is available at https://github.com/codegoat24/plsnet.",AB_0163
"the automatic identification system (ais) and video cameras have been widely exploited for vessel traffic surveillance in inland waterways. the ais data could provide vessel identity and dynamic information on vessel position and movements. in contrast, the video data could describe the visual appearances of moving vessels without knowing the information on identity, position, movements, etc. to further improve vessel traffic surveillance, it becomes necessary to fuse the ais and video data to simultaneously capture the visual features, identity, and dynamic information for the vessels of interest. however, the performance of ais and video data fusion is susceptible to issues such as data spatial difference, message asynchronous transmission, visual object occlusion, etc. in this work, we propose a deep learning-based simple online and real-time vessel data fusion method (termed deepsorvf). we first extract the ais- and video-based vessel trajectories, and then propose an asynchronous trajectory matching method to fuse the ais-based vessel information with the corresponding visual targets. in addition, by combining the ais- and video-based movement features, we also present a prior knowledge-driven anti-occlusion method to yield accurate and robust vessel tracking results under occlusion conditions. to validate the efficacy of our deepsorvf, we have also constructed a new benchmark dataset (termed fvessel) for vessel detection, tracking, and data fusion. it consists of many videos and the corresponding ais data collected in various weather conditions and locations. the experimental results have demonstrated that our method is capable of guaranteeing high-reliable data fusion and anti-occlusion vessel tracking. the deepsorvf code and fvessel dataset are publicly available at https://github.com/gy65896/deepsorvf and https://github.com/gy65896/fvessel, respectively.",AB_0163
"camera-based indoor localization is a fundamental aspect of indoor navigation, virtual reality, and location based services. deep learning methods have exhibited remarkable performance with low storage requirements and high efficiency. however, existing methods mainly derive features implicitly for pose regression without considering explicit structure information from images. this paper proposes that incorporating such information can improve the localization performance of learning-based approaches. we extract structure information from rgb images in the form of depth maps and edge maps and design two modules for depth-weighted and edge-weighted feature fusion. these modules are integrated into the pose regression network to enhance pose prediction. furthermore, we employ a self-attention module for high-level feature extraction to augment the network capacity. extensive experiments are conducted on the publicly available 7scenes and 12scenes datasets, and the results demonstrate that the proposed method achieves high localization performance, with an average positional error of 0.19 m and 0.16 m, respectively. the code for this work is available at https://github.com/lqing900205/structureloc.",AB_0163
"snow is one of the toughest adverse weather conditions for object detection (od). currently, not only there is a lack of snowy od datasets to train cutting-edge detectors, but also these detectors have difficulties of learning latent information beneficial for detection in snow. to alleviate the two above problems, we first establish a real-world snowy od dataset, named rsod. besides, we develop an unsupervised training strategy with a distinctive activation function, called $peak \ act$ , to quantitatively evaluate the effect of snow on each object. peak act helps grade the images in rsod into four-difficulty levels. to our knowledge, rsod is the first quantitatively evaluated and graded real-world snowy od dataset. then, we propose a novel cross fusion (cf) block to construct a lightweight od network based on yolov5s (called cf-yolo). cf is a plug-and-play feature aggregation module, which integrates the advantages of feature pyramid network and path aggregation network in a simpler yet more flexible form. both rsod and cf lead our cf-yolo to possess an optimization ability for od in real-world snow. that is, cf-yolo can handle unfavorable detection problems of vagueness, distortion and covering of snow. experiments show that our cf-yolo achieves better detection results on rsod, compared to sotas. the code and dataset are available at https://github.com/qqding77/cf-yolo-and-rsod.",AB_0163

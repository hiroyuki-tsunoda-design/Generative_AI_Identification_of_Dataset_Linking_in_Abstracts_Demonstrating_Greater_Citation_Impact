AB,NO
"alternative polyadenylation (apa) contributes to transcriptome complexity and gene expression regulation and has been implicated in various cellular processes and diseases. single-cell rna sequencing (scrna-seq) has enabled the profiling of apa at the single-cell level; however, the spatial information of cells is not preserved in scrna-seq. alternatively, spatial transcriptomics (st) technologies provide opportunities to decipher the spatial context of the transcriptomic landscape. pioneering studies have revealed potential spatially variable genes and/or splice isoforms; however, the pattern of apa usage in spatial contexts remains unappreciated. in this study, we developed a toolkit called stapaminer for mining spatial patterns of apa from spatially barcoded st data. apa sites were identified and quantified from the st data. in particular, an imputation model based on the k-nearest neighbors algorithm was designed to recover apa signals, and then apa genes with spatial patterns of apa usage variation were identified. by analyzing well-established st data of the mouse olfactory bulb (mob), we presented a detailed view of spatial apa usage across morphological layers of the mob. we compiled a comprehensive list of genes with spatial apa dynamics and obtained several major spatial expression patterns that represent spatial apa dynamics in different morphological layers. by extending this analysis to two additional replicates of the mob st data, we observed that the spatial apa patterns of several genes were reproducible among replicates. stapaminer employs the power of st to explore the transcriptional atlas of spatial apa patterns with spatial resolution. this toolkit is available at https://github.com/bmilab/stapaminer and https://ngdc.cncb.ac.cn/biocode/tools/bt007320.",AB_0388
"adenosine-to-inosine (a-to-i) rna editing, constituting nearly 90% of all rna editing events in humans, has been reported to contribute to the tumorigenesis in diverse cancers. however, the comprehensive map for functional a-to-i rna editing events in cancers is still insufficient. to fill this gap, we systematically and intensively analyzed multiple tumorigenic mechanisms of a-to-i rna editing events in samples across 33 cancer types from the cancer genome atlas. for individual candidate among similar to 1,500,000 quantified rna editing events, we performed diverse types of downstream functional annotations. finally, we identified 24,236 potentially functional a-to-i rna editing events, including the cases in apol1, igfbp3, gria2, blcap, and mir-589-3p. these events might play crucial roles in the scenarios of tumorigenesis, due to their tumor-related editing frequencies or probable effects on altered expression profiles, protein functions, splicing patterns, and microrna regulations of tumor genes. our functional a-to-i rna editing events (https://ccsm.uth.edu/caeditome/) will help better understand the cancer pathology from the a-to-i rna editing aspect.",AB_0388
"identifying expressed somatic mutations from single-cell rna sequencing data de novo is challenging but highly valuable. we propose resa - recurrently expressed snv analysis, a computational framework to identify expressed somatic mutations from scrna-seq data. resa achieves an average precision of 0.77 on three in silico spike-in datasets. in extensive benchmarking against existing methods using 19 datasets, resa consistently outperforms them. furthermore, we applied resa to analyze intratumor mutational heterogeneity in a melanoma drug resistance dataset. by enabling high precision detection of expressed somatic mutations, resa substantially enhances the reliability of mutational analysis in scrna-seq. resa is available at https://github.com/shenlab-genomics/resa.",AB_0388
"the incidence of hepatocellular carcinoma (hcc) has been increasing in recent years. with the development of various detection technologies, machine learning is an effective method to screen disease characteristic genes. in this study, weighted gene co-expression network analysis (wgcna) and machine learning are combined to find potential biomarkers of liver cancer, which provides a new idea for future prediction, prevention, and personalized treatment. in this study, the limma software package was used. p < .05 and log2 |fold-change| > 1 is the standard screening differential genes, and then the module genes obtained by wgcna analysis are crossed to obtain the key module genes. gene ontology and kyoto gene and genome encyclopedia analysis was performed on key module genes, and 3 machine learning methods including lasso, support vector machine-recursive feature elimination, and randomforest were used to screen feature genes. finally, the validation set was used to verify the feature genes, the genemania (http://www.genemania.org) database was used to perform protein-protein interaction networks analysis on the feature genes, and the spied3 database was used to find potential small molecule drugs. in this study, 187 genes associated with hcc were screened by using the limma software package and wgcna. after that, 6 feature genes (aadat, apof, gpc3, lpa, masp1, and nat2) were selected by randomforest, absolute shrinkage and selection operator, and support vector machine-recursive feature elimination machine learning algorithms. these genes are also significantly different on the external dataset and follow the same trend as the training set. finally, our findings may provide new insights into targets for diagnosis, prevention, and treatment of hcc. aadat, apof, gpc3, lpa, masp1, and nat2 may be potential genes for the prediction, prevention, and treatment of liver cancer in the future.",AB_0388
"there are few studies on risk factors for frozen shoulder, and even fewer mendelian randomization (mr) studies on frozen shoulder. therefore, we conducted a two-sample mr study to explore whether socioeconomic status (years of schooling, average total household income before tax), obesity (body mass index and waist circumference), individual behaviors (smoking initiation, alcohol intake frequency, coffee intake, nonoily fish intake, tea intake, beef intake, bread intake, cheese intake, oily fish intake, and fresh fruit intake), and diabetes (type 1 and type 2 diabetes) are associated with frozen shoulder. the exposure datasets and the outcome dataset were extracted from the mrc integrative epidemiology unit at the university of bristol open genome-wide association studies project (https://gwas.mrcieu.ac.uk/). we conducted mr analyses using the inverse variance weighted (primary method), mr-egger, and weighted median methods and conducted heterogeneity and pleiotropy analyses. type 1 diabetes (or: 1.103; 95% ci: 1.053-1.156; p = .0000410) was associated with an increased risk of frozen shoulder. cheese intake (or: 0.490; 95% ci: 0.267-0.899; p = .0213), non-oily fish intake (or: 0.0993; 95% ci: 0.0220-0.448; p = .00267), years of schooling (or: 0.453; 95% ci: 0.349-0.588; p = .00000000277), and average total household income before tax (or: 0.434; 95% ci: 0.253-0.743; p = .00236) were discovered as protective factors. no horizontal pleiotropy was found in all analyzes we performed (p > .05). our study indicated that type 1 diabetes was a risk factor for frozen shoulder while cheese intake, non-oily fish intake, years of schooling, and average total household income before tax were considered as protective factors for frozen shoulder.",AB_0388
"the two-sided markets, such as ride-sharing companies, often involve a group of subjects who are making sequential decisions across time and/or location. with the rapid development of smart phones and internet of things, they have substantially transformed the transportation landscape of human beings. in this paper we consider large-scale fleet management in ride-sharing companies that involve multiple units in different areas receiving sequences of products (or treatments) over time. major technical challenges, such as policy evaluation, arise in those studies because: (i) spatial and temporal proximities induce interference between locations and times, and (ii) the large number of locations results in the curse of dimensionality. to address both challenges simultaneously, we introduce a multiagent reinforcement learning (marl) framework for carrying policy evaluation in these studies. we propose novel estimators for mean outcomes under different products that are consistent despite the high dimensionality of state-action space. the proposed estimator works favorably in simulation experiments. we further illustrate our method using a real dataset obtained from a two-sided marketplace company to evaluate the effects of applying different subsidizing policies. a python implementation of our proposed method is available in the supplementary material and also at https://github.com/runzhestat/causalmarl.",AB_0388
"introductiondecisions regarding the optimal timing of intervention for asymptomatic aortic stenosis (as) are controversial. the study aims to identify potential risk factors for asymptomatic patients with severe as that are associated with worse prognosis and to evaluate the benefits of early interventions for asymptomatic patients presenting with one or more additional risk factors.methods and analysisthis is a non-interventional, prospective, open-label, multicentre registry study across china. a total of 1000 patients will be enrolled and categorised as symptomatic or asymptomatic. the primary endpoint is the occurrence of all-cause mortality, stroke, acute myocardial infarction and heart failure-related hospitalisation at 1-year follow-up. in asymptomatic severe as patients presenting with one or more risk factors, the occurrence rate of the primary endpoint between those who undergo transcatheter aortic valve replacement (tavr) and those who do not will be compared. we will also compare the occurrence rate of the primary endpoint for asymptomatic severe as patients with additional risk factors who undergo tavr with those presenting with symptoms. this study is believed to provide additional evidence to help clinicians identify and refer severe as patients who are asymptomatic but present with additional risk factors for early intervention of tavr.ethics and disseminationthe study protocol has been approved by the local ethics committee of each participating site: west china hospital, sichuan university; sir run run shaw hospital, zhejiang university school of medicine; second hospital of hebei medical university; tianjin chest hospital; and first affiliated hospital of nanchang university. all participants will provide written informed consent. study results will be published through academic conferences and peer-reviewed journals.trial registrationthis study was registered at the chinese clinical trial registry (https:// www.chictr.org.cn), with the registration number chictr2200064853.",AB_0388
"low-surface-brightness galaxies (lsbgs), fainter members of the galaxy population, are thought to be numerous. however, due to their low surface brightness, the search for a wide-area sample of lsbgs is difficult, which in turn limits our ability to fully understand the formation and evolution of galaxies as well as galaxy relationships. edge-on lsbgs, due to their unique orientation, offer an excellent opportunity to study galaxy structure and galaxy components. in this work, we utilize the you only look once object detection algorithm to construct an edge-on lsbg detection model by training on 281 edge-on lsbgs in sloan digital sky survey (sdss) gri-band composite images. this model achieved a recall of 94.64% and a purity of 95.38% on the test set. we searched across 938,046 gri-band images from sdss data release 16 and found 52,293 candidate lsbgs. to enhance the purity of the candidate lsbgs and reduce contamination, we employed the deep support vector data description algorithm to identify anomalies within the candidate samples. ultimately, we compiled a catalog containing 40,759 edge-on lsbg candidates. this sample has similar characteristics to the training data set, mainly composed of blue edge-on lsbg candidates. the catalog is available online at https://github.com/worldoutside/edge-on_lsbg.",AB_0388
"backgroundprecise preoperative evaluation of lymph node metastasis (lnm) is crucial for ensuring effective treatment for rectal cancer (rc). this research aims to develop a clinical-radiomics nomogram based on deep learning techniques, preoperative magnetic resonance imaging (mri) and clinical characteristics, enabling the accurate prediction of lnm in rc.materials and methodsbetween january 2017 and may 2023, a total of 519 rectal cancer cases confirmed by pathological examination were retrospectively recruited from two tertiary hospitals. a total of 253 consecutive individuals were selected from center i to create an automated mri segmentation technique utilizing deep learning algorithms. the performance of the model was evaluated using the dice similarity coefficient (dsc), the 95th percentile hausdorff distance (hd95), and the average surface distance (asd). subsequently, two external validation cohorts were established: one comprising 178 patients from center i (evc1) and another consisting of 88 patients from center ii (evc2). the automatic segmentation provided radiomics features, which were then used to create a radscore. a predictive nomogram integrating the radscore and clinical parameters was constructed using multivariate logistic regression. receiver operating characteristic (roc) curve analysis and decision curve analysis (dca) were employed to evaluate the discrimination capabilities of the radscore, nomogram, and subjective evaluation model, respectively.resultsthe mean dsc, hd95 and asd were 0.857 +/- 0.041, 2.186 +/- 0.956, and 0.562 +/- 0.194 mm, respectively. the nomogram, which incorporates mr t-stage, cea, ca19-9, and radscore, exhibited a higher area under the roc curve (auc) compared to the radscore and subjective evaluation in the training set (0.921 vs. 0.903 vs. 0.662). similarly, in both external validation sets, the nomogram demonstrated a higher auc than the radscore and subjective evaluation (0.908 vs. 0.735 vs. 0.640, and 0.884 vs. 0.802 vs. 0.734).conclusionthe application of the deep learning method enables efficient automatic segmentation. the clinical-radiomics nomogram, utilizing preoperative mri and automatic segmentation, proves to be an accurate method for assessing lnm in rc. this approach has the potential to enhance clinical decision-making and improve patient care.research registration unique identifying number (uin)research registry, identifier 9158, https://www.researchregistry.com/browse-the-registry#home/registrationdetails/648e813efffa4e0028022796/.",AB_0388
"the progenitors for many types of supernovae (sne) are still unknown, and an approach to diagnose their physical origins is to investigate the light-curve brightness and shape of a large set of sne. however, it is often difficult to compare and contrast the existing sample studies due to differences in their approaches and assumptions, for example, in how to eliminate host galaxy extinction, and this might lead to systematic errors when comparing the results. we therefore introduce the hybrid analytic flux fitter for transients (haffet), a python-based software package that can be applied to download photometric and spectroscopic data for transients from open online sources, derive bolometric light curves, and fit them to semianalytical models for estimation of their physical parameters. in a companion study, we have investigated a large collection of sne ib and ic observed with the zwicky transient facility (ztf) with haffet, and here we detail the methodology and the software package to encourage more users. as large-scale surveys such as ztf and lsst continue to discover increasing numbers of transients, tools such as haffet will be critical for enabling rapid comparison of models against data in statistically consistent, comparable, and reproducible ways. additionally, haffet is created with a graphical user interface mode, which we hope will boost the efficiency and make the usage much easier (https://github.com/saberyoung/haffet).",AB_0388

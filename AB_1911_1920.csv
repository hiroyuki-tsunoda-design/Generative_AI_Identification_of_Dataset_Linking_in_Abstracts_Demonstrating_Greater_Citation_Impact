AB,NO
"a complete global flood event record would aid researchers to analyze the distribution of global floods and, thus, better formulate and manage disaster prevention and reduction policies. this study used gravity recovery and climate experiment (grace) terrestrial water storage and precipitation data combined with high frequency filtering, anomaly detection and flood potential index methods to successfully extract historical flood days globally between 1 april 2002 and 31 august 2016; these results were then further compared and validated with dartmouth flood observatory (dfo) data, global runoff data centre (grdc) discharge data, news reports and social media data. the results showed that grace-based flood days could cover 81 % of the flood events in the dfo database, 87 % of flood events extracted by modis and supplement many additional flood events not recorded by the dfo. moreover, the probability of detection greater than or equal to 0.5 reached 62 % among 261 river basins compared to flood events derived from the grdc discharge data. these detection capabilities and detection results are both good. finally, we provided flood day products with a 1 degrees spatial resolution covering the range between 60 degrees s and 60 degrees n from 1 april 2002 to 31 august 2016; these products can be obtained from https://doi.org/10.5281/zenodo.6831384 (zhang et al., 2022b). thus, this research contributes a data foundation for the mechanistic analysis and attribution of global flood events.",AB_0192
"wireless sensing-based human-vehicle recognition (hvr) methods have become a research hotspot due to their noninvasive, low-cost, and ubiquitous advantages. however, existing methods usually have limited applicability and low recognition performance. furthermore, the antenna deployment height and the carrier frequency of wireless signals are also key factors that affect the hvr performance, but a few works deeply explore their impact on hvr tasks. to address these issues, inspired by the powerful feature learning capability of recently merged deep learning techniques, this article proposes an attention-based convolutional neural network (cnn) model named wireless-based lightweight attention deep learning (wi-ladl) method for hvr. wi-ladl takes received signal strength (rss) as input since rss contains the useful temporal feature of the gait for hvr. wi-ladl consists of several lightweight cnn modules in series and a convolutional block attention module (cbam) to learn high-level features from rss signals. experimental results on the developed five-category rss dataset show that the proposed wi-ladl not only achieves higher accuracy but also exhibits lower computational complexity compared with state-of-the-art hvr methods. in particular, wi-ladl obtains the best performance with an average accuracy of 98.8% at the 2.4-ghz band and an antenna height of 0.8 m on hvr tasks. specifically, when classifying one-pedestrian, two-pedestrians, one-bicycle, two-bicycles, and one-car, the proposed method achieves the recognition accuracy of 97.06%, 97.14%, 100%, 100%, and 100%, respectively. to facilitate the development of wireless sensing technology, the developed new rss dataset has been publicly available at https://github.com/tz-mx/wiparam.",AB_0192
"background: we sought to assess the anxiety and depression scores of pregnant women in hong kong during the covid-19 pandemic and to evaluate the impact of demographic, economic and social factors on these scores. methods: this was part of an ongoing worldwide cross-sectional study conducted from 22 may 2020 to 28 february 2021. data were collected through an anonymous web-based survey. the severity of depression and anxiety was assessed using the patient health questionnaire-9 (phq-9) score and the general anxiety disorder-7 (gad-7) score, respectively. results: a total of 361 participants completed both the gad-7 and phq-9 questionnaires. participants with psychiatric illness reported a significant higher median gad-7 score (6.00, interquartile range [iqr] 3.00-7.75 vs. 2.00, iqr 0.00-6.00, p = 0.001), while the median phq-9 score was also higher but was not statistically significant (6.50, iqr 3.00-11.00 vs. 5.00, iqr 3.00-8.00, p = 0.066). a higher proportion of participants with psychiatric illness reported moderate-severe depression and anxiety (35.7% vs. 16.5%, p = 0.002, 17.8% vs. 3.6%, p < 0.001 respectively). multivariate regression analysis demonstrated that financial difficulty, in education and pregnancy by in-vitro fertilization were associated with a higher phq-9 score in pregnant women during the covid-19 pandemic, while underlying psychiatric illness was associated with a higher gad-7 score. support from a partner was demonstrated to be associated with a reduced level of depression and anxiety in pregnancy. conclusions: pregnant women with underlying psychiatric illness were more vulnerable during the covid-19 pandemics than the non-psychiatric counterparts. partner support is important for alleviating depression and anxiety in pregnancy during the covid-19 pandemic. clinical trial registration: the study was registered at http://www.clinicaltrials.gov, registration number nct04377412.",AB_0192
"registering point clouds of forest environments is an essential prerequisite for lidar applications in precision forestry. state-of-the-art methods for forest point cloud registration require the extraction of individual tree attributes, and they have an efficiency bottleneck when dealing with point clouds of real-world forests with dense trees. we propose an automatic, robust, and efficient method for the registration of forest point clouds. our approach first locates tree stems from raw point clouds and then matches the stems based on their relative spatial relationship to determine the registration transformation. the algorithm requires no extra individual tree attributes and has quadratic complexity to the number of trees in the environment, allowing it to align point clouds of large forest environments. extensive experiments on forest terrestrial point clouds have revealed that our method inherits the effectiveness and robustness of the stem-based registration strategy while exceedingly increasing its efficiency. besides, we introduce a new benchmark dataset that complements the very few existing open datasets for the development and evaluation of registration methods for forest point clouds. the source code of our method and the dataset are available at https://github.com/zexinyang/ globalmatch.",AB_0192
"reconstruction of anisotropic targets using sar from multiple observation aspects is an important research direction. conventionally, to obtain reconstruction of high quality using compressed sensing (cs) or back-projection (bp) methods, it is essential to acquire signals from plenty of aspects. however, limited by the flight trajectory and other factors, only few aspects are available. besides, massive signal data from abundant aspects brings huge burden in computation. thus, a new framework to generate 3d reconstruction of anisotropic targets from few aspects with low computational cost is necessary. to tackle this problem, we propose a new framework, which combines conventional cs algorithm and neural network. the cs algorithm is an imaging module to transform data from frequency domain into spatial domain with high resolution in each aspect to generate incomplete outputs. the sparse-aspects-completion network (sacnet) based on gan principle is originally introduced to predict integral structures from the incomplete results. to evaluate the effectiveness and robustness of our framework, the simulation data (civilian vehicle demo) is used to train while the measured data (gotcha) is for validating. extensive experiments are conducted under condition of {4, 6, 8,10} aspects to estimate the performance with respect to the number of aspects. the proposed framework achieves the highest iou and the lowest bce metrics compared with the conventional algorithms and the sota networks used in similar optical tasks in both simulation and measured datasets under various number of aspects, which proves the effectiveness and robustness of our framework. the source code is available at: https://gitee.com/wshongcola/sar_3d_multi_aspect.",AB_0192
"the internet of things (iot) has recently emerged as a revolutionary communication paradigm where a large number of objects and devices are closely interconnected to enable smart industrial environments. the tremendous growth of visual sensors can significantly promote the traffic situational awareness, traffic safety management, and intelligent vehicle navigation in intelligent transportation systems (itss). however, due to the absorption and scattering of light by the turbid medium in atmosphere, the visual iot inevitably suffers from imaging quality degradation, e.g., contrast reduction, color distortion, etc. this negative impact can not only reduce the imaging quality, but also bring challenges for the deployment of several high-level vision tasks (e.g., object detection, tracking, recognition, etc.) in the its. to improve imaging quality under the hazy environment, we propose a deep network-enabled three-stage dehazing network (termed tsdnet) for promoting the visual iot-driven its. in particular, the proposed tsdnet mainly contains three parts, i.e., multiscale attention module for estimating the hazy distribution in the rgb image domain, two-branch extraction module for learning the hazy features, and multifeature fusion module for integrating all characteristic information and reconstructing the haze-free image. numerous experiments have been implemented on synthetic and real-world imaging scenarios. dehazing results illustrated that our tsdnet remarkably outperformed several state-of-the-art methods in terms of both qualitative and quantitative evaluations. the high-accuracy object detection results have also demonstrated the superior dehazing performance of the tsdnet under hazy atmosphere conditions. the source code is available at https://github.com/gy65896/tsdnet.",AB_0192
"a critical component of visual simultaneous localization and mapping is loop closure detection (lcd), an operation judging whether a robot has come to a pre-visited area. concretely, given a query image (i.e., the latest view observed by the robot), it proceeds by first exploring images with similar semantic information, followed by solving the relative relationship between candidate pairs in the 3d space. in this work, a novel appearance-based lcd system is proposed. specifically, candidate frame selection is conducted via the combination of super-features and aggregated selective match kernel (asmk). we incorporate an incremental strategy into the vanilla asmk to make it applied in the lcd task. it is demonstrated that this setting is memory-wise efficient and can achieve remarkable performance. to dig up consistent geometry between image pairs during loop closure verification, we propose a simple yet surprisingly effective feature matching algorithm, termed locality preserving matching with global consensus (lpm-gc). the major objective of lpm-gc is to retain the local neighborhood information of true feature correspondences between candidate pairs, where a global constraint is further designed to effectively remove false correspondences in challenging sceneries, e.g., containing numerous repetitive structures. meanwhile, we derive a closed-form solution that enables our approach to provide reliable correspondences within only a few milliseconds. the performance of the proposed approach has been experimentally evaluated on ten publicly available and challenging datasets. results show that our method can achieve better performance over the state-of-the-art in both feature matching and lcd tasks. we have released our code of lpm-gc at https://github.com/jiayi-ma/lpm-gc.",AB_0192
"deep learning architecture with convolutional neural network achieves outstanding success in the field of computer vision. where u-net has made a great breakthrough in biomedical image segmentation and has been widely applied in a wide range of practical scenarios. however, the equal design of every downsampling layer in the encoder part and simply stacked convolutions do not allow u-net to extract sufficient information of features from different depths. the increasing complexity of medical images brings new challenges to the existing methods. in this paper, we propose a deeper and more compact split-attention u-shape network, which efficiently utilises low-level and high-level semantic information based on two frameworks: primary feature conservation and compact split-attention block. we evaluate the proposed model on cvc-clinicdb, 2018 data science bowl, isic-2018, segpc-2021 and brats-2021 datasets. as a result, our proposed model displays better performance than other state-of-the-art methods in terms of the mean intersection over union and dice coefficient. more significantly, the proposed model demonstrates excellent segmentation performance on challenging images. the code for our work and more technical details can be found at https://github.com/ xq141839/dcsau-net.",AB_0192
"transfer learning (tl) utilizes data or knowledge from one or more source domains to facilitate learning in a target domain. it is particularly useful when the target domain has very few or no labeled data, due to annotation expense, privacy concerns, etc. unfortunately, the effectiveness of tl is not always guaranteed. negative transfer (nt), i.e., leveraging source domain data/knowledge undesirably reduces learning performance in the target domain, and has been a long-standing and challenging problem in tl. various approaches have been proposed in the literature to address this issue. however, there does not exist a systematic survey. this paper fills this gap, by first introducing the definition of nt and its causes, and reviewing over fifty representative approaches for overcoming nt, which fall into three categories: domain similarity estimation, safe transfer, and nt mitigation. many areas, including computer vision, bioinformatics, natural language processing, recommender systems, and robotics, that use nt mitigation strategies to facilitate positive transfers, are also reviewed. finally, we give guidelines on nt task construction and baseline algorithms, benchmark existing tl and nt mitigation approaches on three nt-specific datasets, and point out challenges and future research directions. to ensure reproducibility, our code is publicized at https://github.com/chamwen/nt-benchmark.",AB_0192
"we propose mvil-fusion, a three-level multisensor fusion system that is able to achieve robust state estimation and globally consistent mapping in perceptually degraded environments. first, lidar depth-assisted visual-inertial odometry (vio) with lidar odometry (lo) synchronous prediction and distortion correction functions is proposed as the frontend of our system. second, a novel double-sliding-window-based optimization of midend joints of lidar scan-to-scan translation constraints (vio status detection function) and scan-to-map rotation constraints (local mapping function) is used to enhance the accuracy and robustness of the state estimation. in the backend, loop closures of local-map-based keyframes are identified with altitude verification, and the global map is generated by incremental smoothing of a pose-only factor graph with altitude prior. the performance of our system is verified on both a public dataset and several self-collected sequences in challenging environments. to benefit the robotics community, our implementation is available at https://github.com/stan994265/mvil-fusion.",AB_0192

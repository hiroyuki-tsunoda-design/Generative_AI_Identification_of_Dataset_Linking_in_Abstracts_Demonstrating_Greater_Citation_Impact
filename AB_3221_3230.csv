AB,NO
"deep neural network (dnn) based multivariate time series (mts) forecasting has been widely studied in many domains. the approach has also been successfully applied to pro-duct sales forecasting, which is invaluable in the strategic development of enterprises. however, one key challenge is to efficiently combine all influential factors into a unified framework by considering their long short-term correlations. this is particularly challeng-ing for real time sales predictions with many important features unknown from the per-spective of future vision, because of the complex and dynamic changing environment of sales time series. besides, dnn based methods could not effectively capture stable linear correlations between multivariate sales time series. to address these challenges, a novel stage future-vision-based multiple long short-term model with prior knowledge (slst-pknet) is proposed. the model constructs sub-models according to the types of different influential factors, and a stage future vision mechanism is used to model dependent corre-lations between future influential factors and product sales by combining a two-layer con-volutional neural network (tlcnn) and a two-stage lstm (tslstm) into a unified framework. the combination of tlcnn and tslstm is the basic component for long short-term modeling, and is an effective solution for capturing dynamic patterns by fusing the outputs from different layers and stages. a dynamic co-integration mechanism (dci) is introduced to capture strong correlations between time series, which dnn is not good at. in order to further improve the capability of the model to capture long short-term patterns from complex environment, domain prior knowledge (pk) is integrated as supervision information. extensive experiments are conducted on two sales datasets: galanz and cainiao. slst-pknet achieves significant performance improvements over 11 state-of-the-art baselines. the proposed model is also evaluated on two new datasets: traffic and exchange-rate, to further verify its generalization capability. the data and code could be visited at: https://github.com/lixt47/slst-pknet.(c) 2023 elsevier inc. all rights reserved.",AB_0323
"during each cell division, tens of thousands of dna replication origins are co-ordinately activated to ensure the complete duplication of the human genome. however, replication fork progression can be challenged by many factors, including co-directional and head-on transcription-replication conflicts (trc). head-on trcs are more dangerous for genome in-tegrity. to study the direction of replication fork movement and trcs, we developed a bioinformatics toolkit called okseqhmm (https://github.com/cl-chen-lab/ok-seq, https://doi.org/10.5281/zenodo. 7428883). then, we used okseqhmm to analyse a large number of datasets obtained by okazaki fragment sequencing to directly measure the genome-wide replication fork directionality (rfd) and to accurately predict replication initiation and termination at a fine resolution in organisms including yeast, mouse and human. we also successfully applied our analysis to other genome-wide sequencing techniques that also contain rfd information (e.g. es-pan, trael-seq). our toolkit can be used to predict replication initiation and fork progression direction genome-wide in a wide range of cell models and growth conditions. comparing the replication and transcription directions allows identifying loci at risk of trcs, particularly head-on trcs, and investigating their role in genome instability by checking dna damage data, which is of prime importance for human health.",AB_0323
"recent multimodal sentiment analysis works focus on establishing sophisticated fusion strategies for better performance. however, a major limitation of these works is that they ignore effective modality representation learning before fusion. in this work, we propose a novel text-audio sentiment analysis framework, named stylebert, to enhance the emotional information of unimodal representations by learning distinct modality styles, such that the model already obtains an effective unimodal representation before fusion, which mitigates the reliance on fusion. in particular, we propose a bi-directional style enhancement module, which learns one contextualized style representation and two differentiated style representations for each modality, where the relevant semantic information across modalities and the discriminative characteristics of each modality will be captured. furthermore, to learn fine-grained acoustic representation, we only use the directly available log-mel spectrograms as audio modality inputs and encode it with a multi-head self-attention mechanism. comprehensive ex-perimental results on three widely-used benchmark datasets demonstrate that the proposed stylebert is an effective multimodal framework and significantly outperforms the state-of-the-art multimodal baselines. our code is available at https://github.com/lsq960124/stylebert.(c) 2022 elsevier ltd. all rights reserved.",AB_0323
"recent years have seen the resurgence of self-supervised learning in visual representation thanks to contrastive learning and masked image modeling. the existing self-supervised methods for skeleton-based action recognition typically learn feature invariance of the data only through contrastive learning. in this paper, we propose a contrast learning method combined with a temporal-masking mechanism of skeleton sequences to encourage the network able to learn action representations other than feature invariance, e.g., occlusion invariance, by implicitly reconstructing the masked sequences. however, the direct masking mechanism destroys the feature consistency of the samples, for which we propose supervised positive sample mining and self-attention module for embeddings to improve the generalization of the model. first of all, supervised contrastive learning can improve the robustness of models using prior knowledge of labels. secondly, to avoid excessive masking mechanism that hinders the model from learning the correct occlusion invariance, a self-attention mechanism is necessary, which further discriminate the distance for each action class in the feature space. the results of various experimental protocols on ntu 60, ntu 120, pku-mmd datasets demonstrate the advantages of our method and that our method outperforms the existing state-of-the-art contrastive methods. code is available at https://github.com/zzfcv/sasoiclr.",AB_0323
"in the era of artificial intelligence, the development of an efficient bearing, fault diagnosis method is of vital importance to ensure smooth production operations and avoid major economic losses. to this end, this paper proposes a bearing fault diagnosis method based on biphasic currents. the method first performs wavelet denoising on the biphasic current signal, then extracts its features by simple vector representation and algebraic operations, and finally, combines the cbar model of convolutional block attention module (cbam) and residual network (resnet) for bearing fault diagnosis. the experimental results show that the highest accuracy rate reaches 100% in both single-point fault and single-point mixed with multiple faults conditions on the open source current bearing fault diagnosis dataset, respectively. compared with other methods, the method proposed in this paper has the advantage of simple data processing, concise model structure, and high-fault diagnosis accuracy, which provides an effective way for dual-phase current-based bearing fault diagnosis. it is worth emphasizing that based on wavelet denoising, this paper uses the simplest vector representation and algebraic operations to preprocess the signal (wp), making the method more efficient and easy to implement. (some experiment-related code is posted on the code open source repository website. https://github.com/ltbig/lt_bearing_fault)",AB_0323
"singer recognition plays a vital role in music information retrieval systems. most songs in the singer recognition system are mixed audios of music and voice. in contrast, there is a lack of labeled a cappella solo singing data suitable for singer recognition. text-independent singer recognition systems successfully encode audio features such as voice pitch, intensity, and timbre to achieve good performance. most such systems are trained and evaluated using data from music with accompaniment. however, due to the influence of background music, the performance of the singer recognition model was limited. contrarily, a powerful singer identification system can be trained and evaluated using a cappella solo singing voice with a clear and broad range of qualities. there needs to be labeled clear singing data suitable for singer recognition research. to address this issue, we present vocal92, a multivariate a cappella solo singing and speech audio dataset spanning around 146.73 hours sourced from volunteers. furthermore, we use three models to construct the singer recognition baseline system. in experiments, the singer recognition model developed by a cappella solo singing data performs well in both single-mode and cross-modal verification data, significantly improving related works. the dataset is accessible to everyone at https://pan.baidu.com/s/1pn62dhfal2ooz_5jqggbdq with jnz5 as the validation code. for non-commercial use, the dataset is available free of charge at the ieee dataport (https://ieee-dataport.org/documents/vocal92-multimodal-audio-dataset-cappella-solo-singing-and-speech).",AB_0323
"document-level relation extraction (re) task aims to predict predefined relation types of every entity pair in a given document. compared with the sentence-level counterpart, document-level relation extraction task requires reasoning in a more complex environment, where exist much longer text and much larger amount of entities, making it a more challenging task. however, previous methods suffers from over-smoothing problem when the count of gnn layers is high enough, leading high frequency signals on graph could not pass through filter, and then resulting in an insufficient approximation of the real function and finally causing a defective performance in tasks. to solve this problem, we propose a novel model, called doreber, for document-level re task, which can obtain a higher quality of graph representation. specifically, doreber performs estimation of filter over the normalized laplacian spectrum of a graph by leveraging an order-k bernstein polynomial approximation, and designs its spectral property by setting the coefficients of the bernstein basis. therefore, doreber can alleviate the over-smoothing problem to enhance learning ability of model. in addition, doreber has a higher interpretability for learned parameters of graph filter. we evaluate doreber on the docred public document-level re dataset. online experimental results demonstrate that doreber achieves significant performance improvements (2.72 and 2.76 higher on ign f-1 and f-1 respectively), over the previous state-of-the-art on sequence-based method baseline. doreber reveals the potential of bernnet method in document-level relation extraction tasks and sheds light on a path to learn potential representation in high-dimensional data.the source code of this paper can be obtained from https://github.com/factor77/doreber/.",AB_0323
"identifying defects at different scales is a challenge in industrial defect detection. to solve this problem, many multi-scale feature fusion networks have been proposed to improve multi-scale target detection accuracy by fusing fine-grained information from shallow networks and semantic information from deep networks. this approach requires the introduction of extraa parameters. thinking from another perspective, can the accuracy of multi-scale target detection be improved by fusing the feature information under different receptive fields? for this purpose, we designed a three-layer network structure called trident-lk net. our model uses convolutional kernels of different sizes (31, 25, 1) in the feature extraction phase and establishes cross-fusion connections. this omits the feature fusion part and greatly reduces the network parameters while obtaining a good detection accuracy. finally we perform experiments on the neu-det dataset and the gc10 dataset to verify the feasibility of our idea. while keeping the number of parameters to a minimum, our model achieves competitive detection results on the neu-det dataset (76.9% map) and optimal on the gc10 dataset (63.55% map). our code will be publicly available at https://github.com/syyang2022/trident-lk-net.",AB_0323
"infrared small target tracking plays an important role in military reconnaissance, early warning, video surveillance, and civil applications. for tracking small infrared targets in this paper, a one-stream deep learning model is utilized. in order to integrate the processes of feature extraction and feature fusion, the model uses transformer as the framework's major component and creates a bidirectional information flow between the template and the search picture pairs in the feature extraction stage. use the head of the model to get the target position. finally, post-processing of the target area, including tracking success, saves the coordinate information of the target frame; tracking failure, near, in the middle, and far from the target box, searches for the real target. it helps to solve the situation where the target moves fast and encounters a complex background to achieve better tracking results. it is tested on an infrared small target data set, and the results show that the method in this paper reaches 80.50% average tracking accuracy. the image sequences in the data set include sky, sea, and buildings. tracking video and original images are shown at https://github.com/ahut507lab/infrared-dim-small-target-tracking.",AB_0323
"the main objective of scene text recognition is to recognize text in complex images and convert it into editable text. however, scene text recognition research has long been focused on english, and there is a lack of research on other small languages, such as uyghur language. this paper conducts a series of studies on uyghur text recognition in natural scenes, with the following main contributions: 1) to address the lack of uyghur scene text recognition datasets, we established the synthetic uyghur scene text dataset sust and the real uyghur scene text dataset rust, and we augmented rust with str-aug; 2) the contemporary existing str models are selected to conduct experiments on the dataset proposed in this paper, through which we search for the model structure suitable for uyghur scene text recognition; 3) according to the characteristics of uyghur text, this paper designs a lightweight uyghur text recognition model named lustr, which takes into account both lightweight and accuracy, and achieves good performance in the uyghur scene text recognition dataset proposed in this paper. the sust and rust are now publicly available at https://github.com/kongfnajie/sust-and-rust-datasets-for-uyghur-str.",AB_0323

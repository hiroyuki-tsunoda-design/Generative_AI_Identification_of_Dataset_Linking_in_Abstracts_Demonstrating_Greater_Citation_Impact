AB,NO
"images captured in low-light environments often suffer from complex degradation. simply adjusting light would inevitably result in burst of hidden noise and color distortion. to seek results with satisfied lighting, cleanliness, and realism from degraded inputs, this paper presents a novel framework inspired by the divide-and-rule principle, greatly alleviating the degradation entanglement. assuming that an image can be decomposed into texture (with possible noise) and color components, one can specifically execute noise removal and color correction along with light adjustment. for this purpose, we propose to convert an image from the rgb colorspace into a luminance-chrominance one. an adjustable noise suppression network is designed to eliminate noise in the brightened luminance, having the illumination map estimated to indicate noise amplification levels. the enhanced luminance further serves as guidance for the chrominance mapper to generate realistic colors. extensive experiments are conducted to reveal the effectiveness of our design, and demonstrate its superiority over state-of-the-art alternatives both quantitatively and qualitatively on several benchmark datasets. our code has been made publicly available at https://github. com/m ngcv/bread.",AB_0040
"as a future-proof technology, high dynamic range (hdr) has the superiority in scene reappearance. tone mapping operator (tmo) renders the dynamic effect of hdr images in a standard dynamic range (sdr) display at the expense of some insignificant information. however, it is difficult for existing tmos to con-sistently achieve high-quality conversion of all hdr images, and the loss of converted images is inevitable. therefore, accurate prediction of tone-mapped image (tmi) quality is of considerable significance. in this paper, we propose the reappearance effect of the tmis index (reti). according to the characteristics of primeval hdr images, the quality of tmis is considered from three important elements: authenticity, the preservation of energy and information, and scene expressiveness. the feature vectors originated from three elements are combined with subjective quality to train prediction model. experiments are executed on tow mainstream tmi quality assessment databases and the results show that the proposed method has a good prediction ability and generalization ability in comparison to some state-of-the-art methods. our matlab source code will be released at https://github.com/niannianyouyu/reti .(c) 2022 elsevier b.v. all rights reserved.",AB_0040
"pollen identification is a sub-discipline of palynology, which has broad applications in several fields such as allergy control, paleoclimate reconstruction, criminal investigation, and petroleum exploration. among these, pollen allergy is a common and frequent disease worldwide. accurate and rapid identification of pollen species under the electron microscope help medical staff in pollen forecast and interrupt the natural course of pollen allergy. the current pollen species identification needs to rely on professional researchers to identify pollen particles in pictures manually, and this time-consuming and laborious way cannot meet the requirements of pollen forecasting. recently, the self-attention based transformer has attracted considerable attention in vision tasks, such as image classification. however, pure self-attention lacks local operations on pixels and requires large-scale dataset pretraining to achieve comparable performance to convolutional neural networks (cnn). in this study, we propose a new vision transformer pipeline for image classification. first, we design a featuremap-to-token (f2t) module to perform token embedding on the input image. a global self-attention operation is performed on the basis of tokens with local information, and the hierarchical design of cnn is applied to the vision transformer, combining local and global strengths in multiscale spaces. second, we use a distillation strategy to learn the feature representation in the output space of the teacher network to further learn the inductive bias in the cnn to improve the recognition accuracy. experiments demonstrate that the proposed model achieves cnn-equivalent performance under the same conditions after being trained from scratch on the electron-microscopic pollen dataset. it also requires less model parameters and training time. code for the model is available at https://github.com/dkbshuai/pytorchour-s.",AB_0040
"pedestrian trajectory prediction is a key technology in many real applications such as video surveillance, social robot navigation, and autonomous driving, and significant progress has been made in this research topic. however, there remain two limitations of previous studies. first, the losses of the last time steps are heavier weighted than that of the beginning time steps in the objective function at the learning stage, causing the prediction errors generated at the beginning to accumulate to large errors at the last time steps at the inference stage. second, the prediction results of multiple pedestrians in the prediction horizon might be socially incompatible with the interactions modeled by past trajectories. to overcome these limitations, this work proposes a novel trajectory prediction method called csr, which consists of a cascaded conditional variational autoencoder (cvae) module and a socially-aware regression module. the cvae module estimates the future trajectories in a cascaded sequential manner. specifically, each cvae concatenates the past trajectories and the predicted location points so far as the input and predicts the adjacent location at the following time step. the socially-aware regression module generates offsets from the estimated future trajectories to produce the corrected predictions, which are more reasonable and accurate than the estimated trajectories. experiments results demonstrate that the proposed method exhibits significant improvements over state-of-the-art methods on the stanford drone dataset (sdd) and the eth/ucy dataset of approximately 38.0% and 22.2%, respectively. the code is available at https://github.com/zhouhao94/csr . (c) 2022 elsevier ltd. all rights reserved.",AB_0040
"this paper proposes a novel swarm intelligence-based metaheuristic called as sea-horse optimizer (sho), which is inspired by the movement, predation and breeding behaviors of sea horses in nature. in the first two stages, sho mimics different movements patterns and the probabilistic predation mechanism of sea horses, respectively. in detail, the movement modes of a sea horse are divided into floating spirally affected by the action of marine vortices or drifting along the current waves. for the predation strategy, it simulates the success or failure of the sea horse for capturing preys with a certain probability. furthermore, due to the unique characteristic of the male pregnancy, in the third stage, the proposed algorithm is designed to breed offspring while maintaining the positive information of the male parent, which is conducive to increase the population diversity. these three intelligent behaviors are mathematically expressed and constructed to balance the local exploitation and global exploration of sho. the performance of sho is evaluated on 23 well-known functions and cec2014 benchmark functions compared with six state-of-the-art metahewistic algorithms. finally, five real-world engineering problems are utilized to test the effectiveness of sho. the experimental results demonstrate that sho is a high-performance optimizer and positive adaptability to deal with constraint problems. sho source code is available from: https://www.mathworks.com/matlabcentral/fileexchange/115945-sea-horse-optimizer",AB_0040
"triplet loss, one of the deep metric learning (dml) methods, is to learn the embeddings where exam-ples from the same class are closer than examples from different classes. motivated by dml, we propose an effective bp-triplet loss for unsupervised domain adaption (uda) from the perspective of bayesian learning and we name the model as bp-triplet net . in previous metric learning based methods for uda, sample pairs across domains are treated equally, which is not appropriate due to the domain bias. in our work, considering the different importance of pair-wise samples for both feature learning and domain alignment, we deduce our bp-triplet loss for effective uda from the perspective of bayesian learning. our bp-triplet loss adjusts the weights of pair-wise samples in intra-domain and inter-domain. especially, it can self attend to the hard pairs (including hard positive pair and hard negative pair). together with the commonly used adversarial loss for domain alignment, the quality of target pseudo labels is progressively improved. our method achieved low joint error of the ideal source and target hypothesis. the expected target error can then be upper bounded following ben-david's theorem. comprehensive evaluations on four benchmark datasets demonstrate the effectiveness of the proposed approach for uda. code is avail-able at https://github.com/wangshanshanahu/bp-triplet -net .(c) 2022 elsevier ltd. all rights reserved.",AB_0040
"knowledge distillation (kd) is a feasible and effective way to obtain small networks with outstanding properties that can be deployed on hardware-constrained devices. earlier kd methods were primarily implemented offline and used single information contained in logits or features as the source of kd, resulting in the limited impact of kd on the network. and the online distillation structure also lacks flexibility. to address those issues, we propose embedded mutual learning (eml), a novel online distillation method. by embedding an ensemble branch and an adaptive fusion branch between two parallel peer networks, eml can use the ensemble information and overall feature representations of all peer networks and the logits to complete online kd. diverse knowledge helps fully mine the potential of the networks during online distillation. through extensive experiments conducted on cifar-10, cifar-100, and imagenet, we demonstrate that the eml is superior to the state-of-the-art online kd methods on image classification task. meanwhile, we provide insights on why our eml method is effective from different perspectives. in particular, the embedded implementation makes eml highly flexible. the eml can be widely used in different network combinations composed of heterogeneous or homogeneous networks. the implementation code of our eml model is obtainable from https://github.com/lcxlcx/eml.",AB_0040
"with the birth of the metaverse, 3d models have received extensive attention, and the security of in-formation transmission continues to be an important issue. in this paper, we propose a 3d model en-cryption method based on a 2d chaotic system constructed via the coupling of the logistic map and infinite collapse (2d-laic) and on semi-tensor product (stp) theory. in terms of lyapunov exponents, nist test results, bifurcation diagrams, etc., 2d-laic exhibits better dynamical behavior than classical chaotic systems. 2d-laic can generate an unpredictable keystream, which is highly suitable for cryptog-raphy. therefore, we propose a new 3d model encryption algorithm based on 2d-laic, named 3dme-sc. for a 3d model of the floating-point data type, xor and stp processing are applied to the integer part and fractional part, respectively, of the model to obtain a 3d ciphertext model. the keystream required for xor and stp processing is generated by 2d-laic. the results of a detailed security analysis and a comparative experimental analysis show that 3dme-sc exhibits good performance and effectiveness. (code: https://github.com/gao5211996/3d-model-encryption)(c) 2022 elsevier b.v. all rights reserved.",AB_0040
"graph neural networks (gnns) rely heavily on architecture design and artificial hyperparameters, often resulting in expensive manual effort and poor performance. recently, automated machine learning (automl) on graphs is a promising approach for automated neural network design that is gaining attention from the research community. the existing automl methods for gnns usually preset the number of layers to a small, fixed number, e.g., no more than three layers, possibly due to the oversmoothing problem. however, it is well known that deeper network models facilitate the extraction of high-level information representations. to this end, using the genetic algorithm (ga) as a framework, in this paper we propose a gnn search method (called gcn-ga) that dynamically searches the depth of the model to efficiently handle the node classification tasks. first, a variable-length encoding strategy is proposed to use the constituent units of four graph convolutional network (gcn) structures with different topologies as building blocks for representing the network architecture. second, considering that the search method of searching network architectures with fixed hyperparameters and then searching hyperparameters independently may result in the obtained network models be not optimal, gcn-ga represents hyperparameters in the form of fixed-length encoding. they form a hybrid encoding strategy for representing the network architecture and hyperparameters. then, the gcn-ga simultaneously searches both the network architecture and hyperparameters during the evolution. in addition, for the variable-length encoding, an improved two-point crossover operator, and three types of variation operators are designed for the evolutionary process. finally, experiments are conducted on three widely used node classification datasets, namely, cora, citeseer, and pubmed, in the semi-supervised and supervised tasks. the experimental results show that gcn-ga achieves more effective classification accuracy in most cases compared with the state-of-the-art hand-designed gnns and the automl methods. the code will be available at https://github.com/chnyliu/gcn-ga.",AB_0040
"accurately and automatically segmenting teeth from cone-beam computed tomography (cbct) images plays an essential role in dental disease diagnosis and treatment. this paper presents an automatic tooth segmentation model that combines deep learning methods and level-set approaches. the proposed model uses a deep learning method to detect each tooth's location and size and generates prior ellipses from those detected boundary boxes. calculating each point's signed distance to the prior edge and using them as prior weights, the restriction term can constrain the evolution of level set functions according to the distance to the prior ellipses. then, we use the curvature direction to find out joint points of teeth and employ a variational model to separate them to get individual results. by quantitative evaluation, we show that the proposed model can accurately segment teeth. the performance is more accurate and stable than those of classical level-set models and deep-learning models. for example, the dice coefficient is increased by 7% than that of the u-net model. besides, we will release the code on https://github.com/ ruicx/individual- tooth- segmentation- with- rectangle-labels .(c) 2022 elsevier ltd. all rights reserved.",AB_0040

AB,NO
"how to effectively exchange and aggregate the information of multiple modalities ( e.g. rgb image and depth map) is a big challenge in the rgb-d salient object detection community. to address this problem, in this paper, we propose a cross-modal hierarchical interaction network ( hinet ), which boosts the salient object detection by excavating the cross-modal feature interaction and progressively multi-level feature fusion. to achieve it, we design two modules: cross-modal information exchange (cie) module and multi-level information progressively guided fusion (pgf) module. specifically, the cie module is proposed to exchange the cross-modal features for learning the shared representations, as well as the beneficial feedback to facilitate the discriminative feature learning of different modalities. besides, the pgf module is designed to aggregate the hierarchical features progressively with the reverse guidance mechanism, which employs the high-level feature fusion to guide the low-level feature fusion and thus improve the saliency detection performance. extensive experiments show that our proposed model significantly outperforms the existing nine state-of-the-art models on five challenging benchmark datasets. codes and results are available at: https://github.com/ranwanwu/hinet.(c) 2022 elsevier ltd. all rights reserved.",AB_0037
"real-time semantic segmentation has attracted wide attention in the computer vision field, and its per-formance depends on both rich semantic information and high-resolution information. most networks fastly reduce image resolution or prune feature channels in the coding stage to improve the computing speed and concatenate the shallow feature to the deep feature in the decoding stage for filling in the high -resolution details. here, we propose a new real-time semantic image segmentation method called guided down-sampling network. the guided down-sampling decomposes the original image into a group of compressed images that replace the original image as the input of the encoding layers. this operation reduces the size of the feature map and meanwhile retains the most spatial information of the original image. furthermore, a two-branch sub-network is designed to extract semantic information and restore high-resolution image details from compressed images for better supervising feature learning. our net-work is tested on the cityscapes dataset on a single nvidia geforce gtx 1080ti gpu, and the competitive results of 113 fps and 75.6% miou have been achieved. the code is available at (https://github.com/ ldrunning/segmentation). (c) 2022 elsevier b.v. all rights reserved.",AB_0037
"transformer is successfully applied in many tasks but is not sensible to directly embed in the portrait matting. such an operation can effectively consider global features ignoring local features, which leads to the difficulty of identifying the complete and edge-refined portraits. what is more, the existing supervised architectures are feeble against the unlabeled images. to achieve the effective excavation of both local and global features, we design a semi-supervised network that leverages transformer to capture the global features. the arduous task of compensating more local features is left to the portrait detailed decoding module (pddm) that we designed. in addition, to provide the possibility of improving effectiveness when faced with unlabeled images, we design an intelligent pseudo-label generation strategy to embed in our semi-supervised network. this strategy can generate more detailed pseudo-labels than predicted results through redundant foreground filtering and edge adjustment. compared to existing portrait matting methods, our network successfully achieves performance improvements with a small number of datasets and has the ability to train on unlabeled datasets. the training models and the code will be released at https://github .com /xinyuezhangqdu /sspmtransformer/.(c) 2022 elsevier inc. all rights reserved.",AB_0037
"machine learning (ml) has been recently introduced to solving optimization problems, especially for combinatorial optimization (co) tasks. in this paper, we survey the trend of leveraging ml to solve the mixed-integer programming problem (mip). theoretically, mip is an np-hard problem, and most co problems can be formulated as mip. like other co problems, the human-designed heuristic algorithms for mip rely on good initial solutions and cost a lot of computational resources. therefore, researchers consider applying machine learning methods to solve mip since ml-enhanced approaches can provide the solution based on the typical patterns from the training data. specifically, we first introduce the for-mulation and preliminaries of mip and representative traditional solvers. then, we show the integration of machine learning and mip with detailed discussions on related learning-based methods, which can be further classified into exact and heuristic algorithms. finally, we propose the outlook for learning-based mip solvers, the direction toward more combinatorial optimization problems beyond mip, and the mutual embrace of traditional solvers and ml components. we maintain a list of papers that utilize machine learning technologies to solve combinatorial optimization problems, which is available at https://github.com/thinklab-sjtu/awesome-ml4co. (c) 2022 elsevier b.v. all rights reserved.",AB_0037
"unsupervised feature selection (ufs), which selects the most important feature subset and eliminates the unnecessary information for the upcoming data analysis, is a significant problem in machine learning and has been explored for years. most ufs methods map features into a pseudo label space by multiply-ing a projection matrix constrained with sparsity to learn the mapping from the features to the labels. however, the mapping relationship is usually not linear, and linear regression may result in a subop-timal selection. to address this issue, we propose a novel ufs method, called neural networks embed-ded self-expression (nnse). nnse replaces the linear regression of traditional spectral analysis methods with neural networks to learn the pseudo label space. besides, we embed neural networks into the self-expression model to improve the representative ability by preserving the local structure with an adap-tive graph regularization module. then we propose an efficient alternative iterative algorithm to solve the proposed model. experimental results on 8 public datasets show nnse outperforms the other state-of-the-art methods. moreover, experimental results are also presented to show the convergence of the proposed method. the source code is available at: https://github.com/misteru/nnse .(c) 2022 elsevier ltd. all rights reserved.",AB_0037
"the clustering of large numbers of heterogeneous features is a hot topic in multi-view communities. most existing multi-view clustering (mvc) methods employ matrix factorization or anchor strategies to handle large-scale datasets. the former operates on the original data and is, therefore, sensitive to noise and feature redundancy, which is reflected in the final clustering performance. the latter requires post -processing steps to generate the clustering results, which may be suboptimal owing to the isolation steps. to address the above problems, we propose one-stage multi-view subspace clustering with dictionary learning (osmvsc). specifically, we integrate dictionary learning, representation coefficient matrix learning, and matrix factorization as a unified learning framework, which directly learns the dictionary and representation coefficient matrix to encode the original multi-view data, and obtains the clustering results with linear time complexity without any postprocessing step. by manipulating the class centroid with the nuclear norm, a more compact and discriminative class centroid representation can be obtained to further improve clustering performance. an effective optimization algorithm with guaranteed convergence is designed to solve the proposed method. substantial experiments on various real-world multi-view datasets demonstrate the effectiveness and superiority of the proposed method. the source code is available at https://github.com/justcallmewilliam/osmvsc.(c) 2022 elsevier b.v. all rights reserved.",AB_0037
"we study the problem of talking head animation from a single image where a target anime talking head is generated to mimic the change of facial expression and head movement of source anime characters. most existing methods focus on generating talking heads from real humans. however, few effort s have been made to create anime talking head. compared with human head generation, the key challenges of anime head generation are: how to align the pose and facial expression of the target head with that of the source head without explicit facial landmarks. to address this, we propose cptnetv2, a cascaded pose transform network that unifies face pose transformation and head pose transformation. at the core of cptnetv2 is the implicit encoding of facial changes and head movement by a pose vector. given the pose vector, we introduce a mask generator to animate facial expression (e.g., close eyes and open mouth) and a grid generator to simulate head movement, followed by a fusion module to generate talk-ing heads. to tackle large displacement and improve the quality of generation, we further design a details inpainting module with pose vector decomposition to reduce the receptive field of network required for pose transformation. in particular, we collect an anime talking head dataset anihead-2k that includes around 20 0 0 anime characters with different face/head poses. extensive experiments on anihead-2k demonstrate that cptnetv2 can achieve arbitrary pose transformation conditioned on the target pose vector and outperforms other state-of-the-art methods. we also verify the effectiveness of each module through ablative studies. additional results show that cptnetv2 has good generalization and is applica-ble to generate anime talking head even based on human videos. the dataset will be made available at: https://github.com/zhangjiale487/anihead-2k .(c) 2022 elsevier ltd. all rights reserved.",AB_0037
"recent years have witnessed significant advances in ai-based face manipulation techniques, known as deepfakes, which has brought severe threats to society. hence, an emerging and increasingly important research topic is how to detect deepfake videos. in this paper, we propose a new deepfake detection method based on bi-granularity artifacts (big-arts). we observe that the most of deepfake video gen-eration can commonly introduce bi-granularity artifacts: the intrinsic-granularity artifacts and extrinsic-granularity artifacts. specifically, the intrinsic-granularity artifacts are caused by a common series of op-erations in model generation such as up-convolution or up-sampling, while the extrinsic-granularity ar-tifacts are introduced by a common step in post-processing that blends the synthesized face to original video. to this end, we formulate deepfake detection as multi-task learning problem, to simultaneously predict the intrinsic and extrinsic artifacts. benefiting from the guidance of detecting bi-granularity arti-facts, our method is notably boosted in both within-datasets and cross-datasets scenarios. extensive ex-periments are conducted on several deepfake datasets, which corroborates the superiority of our method. our method has been contributed as a part of the solution to achieve the top-1 rank in dfgc competition ( https://competitions.codalab.org/competitions/29583 ).(c) 2022 elsevier ltd. all rights reserved.",AB_0037
"for fake face image detection, most existing detectors exploit local artifacts, ignoring the mining of structured forgery clues existed in global images, which greatly constrains detection performance. in this work, we verify the importance of structured forgery clues for fake face image detection, and present a new data augmentation framework called mining structured features (msf) to promote the convolutional neural network (cnn) based detector. specifically, msf generates a position-sensitive artifact map, which is exploited to divide a candidate face image into strong correlation (sc) and weak correlation (wc) regions. by dynamically erasing some positions in sc and wc regions during the training process, msf can promote the robustness of the detector to the above regions. in essence, msf expands the attention range of the detector and fully mines the structured features from global images. msf plays an auxiliary role, which can be seamlessly integrated into existing cnn-based detectors for end-to-end training. extensive experimental results on four public datasets including hffd, ff++, dfdc and celeb-df show that the detectors trained with the guidance of msf can mine more useful clues distributed in fake face images to improve detection accuracies, achieving better results than state-of-the-art works. our code will be available at https://github.com/ericgzq/msf.",AB_0037
"as one novel meta-heuristic algorithm, african vultures optimization algorithm (avoa) has been proved to be efficient in solving continuous optimization problems. however, many real-world optimization problems are in the discrete form, and the continuous characteristics of avoa make it unsuitable for solving discrete optimization problems. therefore, this article proposes binary african vultures optimization algorithm (bavoa) to solve various optimization problems, especially discrete optimization problems. in bavoa, the x-shaped transfer function is firstly adopted to convert the continuous search space into the binary search space, and then the opposition-based learning strategy and the improved multi-elite strategy are utilized to enhance the optimization ability of bavoa. moreover, the performance of bavoa is evaluated by twenty-three benchmark functions with the relevant wilcoxon rank sum tests, and the effectiveness of bavoa is demonstrated by four engineering design problems and one combinational optimization problem. the results demonstrate that bavoa outperforms eight well-known algorithms in addressing various optimization problems. source codes of bavoa are publicly available at: https://www.mathworks.com/matlabcentral/fileexchange/115350-binary-african-vultures-optimization-algorithm",AB_0037

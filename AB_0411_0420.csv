AB,NO
"semi-supervised fine-grained recognition is a challenging task due to the difficulty of data imbalance, high inter-class similarity and domain mismatch. recently, this field has witnessed giant leap and many methods have gained great performance. we discover that these existing semi-supervised learning (ssl) methods achieve satisfactory performance owe to the exploration of unlabeled data. however, on the realistic large-scale datasets, due to the abovementioned challenges, the improvement of the quality of pseudo-labels requires further research. in this work, we propose bilateral-branch self-training framework (bistf), a simple yet effective framework to improve existing semi-supervised learning methods on class-imbalanced and domain-shifted fine-grained data. by adjusting stochastic epoch update frequency, bistf iteratively retrains a baseline ssl model with a labeled set expanded by selectively adding pseudo-labeled samples from an unlabeled set, where the distribution of pseudo-labeled samples is the same as the labeled data. we show that bistf outperforms the existing state-of-the-art ssl algorithm on semi-inat dataset. our code is available at https://github.com/howiechangehn/bistf.",AB_0042
"correctly identifying sleep stages is essential for assessing sleep quality and treating sleep disorders. however, the current sleep staging methods have the following problems: (1) manual or semi-automatic extraction of features requires professional knowledge, which is time-consuming and laborious. (2) due to the similarity of stage features, it is necessary to strengthen the learning of features. (3) acquisition of a variety of data has high requirements on equipment. therefore, this paper proposes a novel feature relearning method for automatic sleep staging based on single-channel electroencephalography (eeg) to solve these three problems. specifically, we design a bottom-up and top-down network and use the attention mechanism to learn eeg information fully. the cascading step with an imbalanced strategy is used to further improve the overall classification performance and realize automatic sleep classification. the experimental results on the public dataset sleep-edf show that the proposed method is advanced. the results show that the proposed method outperforms the state-of-the-art methods. the code and supplementary materials are available at github: https://github.com/raintyj/a-novel-feature-relearning-method.",AB_0042
"the research in pedestrian detection has made remarkable progress in recent years. however, robust pedestrian detection in crowded scenes remains a considerable challenge. many methods resort to additional annotations (visible body or head) of a dataset or develop attention mechanisms to alleviate the difficulties posed by occlusions. however, these methods rarely use contextual information to strengthen the features extracted by a backbone network. the main aim of this paper is to extract more effective and discriminative features of pedestrians for robust pedestrian detection with heavy occlusions. to this end, we propose a global context-aware module to exploit contextual information for pedestrian detection. fusing global context with the information derived from the visible part of occluded pedestrians enhances feature representations. the experimental results obtained on two challenging benchmarks, crowdhuman and citypersons, demonstrate the effectiveness and merits of the proposed method. code and models are available at: https://github.com/flyingzstar/crowded pedestrian detection.",AB_0042
"automatic violence detection in video is a meaningful yet challenging task. violent actions can be characterized both by intense sequential frames and by continuous spatial moves, imposing more complexity than other human actions. however, most existing approaches focus on general spatiotemporal features with local convolution and ignore the full temporal inference based on violence characteristics. to this end, we propose a novel full temporal cross fusion network (ftcf net) to investigate an effective inference way for violence detection. specifically, we design two essential components in each ftcf block: a spatial processor and a temporal processor by neural networks. the former is to capture the local structural features of each frame by a 3d cnn with a (3x3x1) filter to infer the continuous spatial moves, while the latter is to perform the cross-frame feature interaction step by step for each channel by a group of processing units to infer the intense and wide variation of violence in full temporal. the two branches are fused at the end of each ftcf block in the ftcf net efficiently. we conduct extensive experiments on four benchmark datasets: hockey fight, movie fight, violent flow, and real-life violence situations, and the experimental results show that ftcf net outperforms 20 comparison methods in terms of predictive accuracy. the accuracy goes up to 99.5%, 100.0%, 98.0% and 98.5% in the four datasets respectively, validating the effectiveness of our proposed approach for violence detection. moreover, the approach proposed in this paper obtains relative steady prediction performance superior to existing methods under different scale of training sets. we hope this work to be a baseline of violence detection, and the whole original codes and pre-trained weights are publicly available at https://github.com/tan-openlab/ftcf-net.",AB_0042
"marine target detection is a challenging task because degraded underwater images cause unclear targets. furthermore, marine targets are small in size and tend to live together. the popular object detection methods perform poorly in marine target detection. thus, this paper proposes a novel multiple attentional path aggregation network named apan to improve performance on marine object detection. firstly, we design a path aggregation network structure which brings features from backbone network to bottom-up path augmentation. each feature map is enhanced by the lower layer through the bottom-up downsampling pathway and incorporates the features from top-down upsampling layers. specifically, the last layer fuses feature map from backbone network which enhances the semantic features and improve the ability of feature extraction. then, a multi-attention which combines coordinate competing attention and spatial supplement attention applies to proposed path aggregation network. multi-attention can further improve the accuracy of multiple marine object detection. finally, a double transmission underwater image enhancement algorithm is proposed to enhance the underwater image datasets. the experiments show our method achieves 79.6% map in underwater image datasets and 79.03% map in enhanced underwater image datasets. meanwhile, our method achieves 81.5% map in pascal voc datasets. in addition, we also applly the method to the underwater robot. the experiments show our method achieves good performance compared with popular object detection methods. the source code is publicly available at https://github.com/yhf2022/apan.",AB_0042
"crowd counting is one of the most fundamental tasks in the field of computer vision and dictionary learning has been successfully applied to the task. however, many traditional dictionary learning-based algorithms for crowd counting often show remarkably large prediction biases on real dynamic monitoring scenes where the feature distribution of the same count is of huge divergence. meanwhile, these methods also clumsy at revealing salient feature changes between two video frames with the same crowd count. to overcome or alleviate these issues, in this paper we treat crowd counting as a particular classification problem and propose a novel dictionary learning algorithm called salient double-reconstruction based discriminative projective dictionary learning (sdr-dpl) for crowd counting. specifically, the proposed sdr-dpl develops a novel reconstruction strategy which jointly considers reducing the feature distribution gap and incorporating salient feature mappings into the reconstruction term. this strategy benefits to make the learned dictionaries better adapt to large variations in monitoring crowd scenes and enables to achieve more accurate prediction on the number of pedestrians in both indoor and outdoor scenes. moreover, we adopt an efficient linear coding technique to represent the crowd features regarding the learned synthesis dictionary, with which the optimization procedure breaks through the computational bottleneck that traditional sparse coding-based methods have to face with. extensive evaluation experiments on five benchmark datasets validate the impressive performance of the proposed sdr-dpl compared with other state-of-the-art competitors. the source code has been available at https://github.com/evelhz/sdr-dpl.",AB_0042
"as a discriminative biometric modality, palmprint accommodates two attributes of soft biometrics, namely chirality and gender. our study reveals that the false matching of a pair of palmprint templates from two identities could be possible if their representations are mirror-insensitive or gender-insensitive, despite the palmprint images have significant distinctive appearances. this could seriously impair the accuracy performance of the palmprint recognition systems. as a remedy, the useful knowledge learned from the classification of soft palmprint attributes, namely chirality and gender, is transferred to palmprint recognition, which improves the accuracy of palmprint-based identity recognition. to be specific, this paper pre-trains a shared-weight multi-task network with soft palmprint attributes under transfer learning paradigm. the pre-trained network is then transferred to the down-stream identity recognition task. several shared-weight architectures are explored and examined to determine the suitable model. extensive experiments demonstrate that the proposed method can effectively avoid the false matching between the templates of different chiralities / genders. the proposed method can be applied to other biometric modalities, where their associated soft biometrics can be exploited for performance gain. the related codes will be released as soon as possible if the paper is accepted. the link is https://github.com/1119231393/multitask-pre-training-with-soft-biometrics-for-transfer-learning-palmprint-recognition.",AB_0042
"gait recognition aims to identify people by the way they walk. currently available gait recognition datasets mainly contain single-person gait data in relatively simple walking conditions, which limits research of robust gait recognition methods. in this paper, og rgb+d dataset is presented to cope with this crucial limitation of other gait datasets. it includes the common walking conditions under occlusion in daily life, that is, those daily walking conditions in which people's normal walking patterns are occluded, including self-occlusion caused by views, occlusion caused by clothing or objects, and mutual occlusion between people. the dataset provides multi-modal data to support different types of methods, collected by multiple azure kinect dk sensors using synchronous data acquisition system (multi-kinect sdas). moreover, we propose a model-based gait recognition method skeletongait for gait recognition in walking conditions under occlusion, which learns discriminative gait features from human dual skeleton model composed of skeleton and anthropometric features through a siamese spatio-temporal graph convolutional network (siamese st-gcn). the experimental results show that skeletongait surpasses state-of-the-art methods in the case of severe occlusion. we believe that the introduction of our dataset will enable the community to apply, adapt, and develop various robust gait recognition methods. the dataset will be available at https://github.com/cvnxe/og-rgb-d-gait-dataset.",AB_0042
"generalized normal distribution optimization (gndo) inspired by the theory of normal distribution is a recently developed metaheuristic method for global optimization problems. this work presents a novel variant of gndo, which is called elite-driven generalized normal distribution optimization (edgndo). edgndo enhances the global search ability of gndo by the designed search mechanism consisting of three local search operators and three global search operators that are based on two built archives used to save elite individuals. note that, edgndo only needs population size and termination criteria for optimization, which can distinguish it over the most reported metaheuristic methods. the performance of edgndo is investigated by the well-known cec 2017 test suite including three unimodal functions and 27 multimodal functions. experimental results demenstrate that edgndo is obviously better than gndo and the other five powerful algorithms in terms of solution quality and computational efficiency. in addition, edgndo is also used for solving four challenging constrained engineering design problems. experimental results support the superiority of edgndo in solving the four problems. the superiority of edgndo in solving complex optimization problems is proven. the source code can be loaded from https://github.com/jsuzyy/edgndo.",AB_0042
"image segmentation lays the foundation for many high-stakes vision applications such as autonomous driving and medical image analysis. it is, therefore, of great importance to not only improve the accuracy of segmentation models on well-established benchmarks, but also enhance their robustness in the real world so as to avoid sparse but fatal failures. in this paper, instead of chasing state-of-the-art performance on existing benchmarks, we turn our attention to a new challenging problem: how to efficiently expose failures of top-performing segmentation models in the real world and how to leverage such counterexamples to rectify the models. to achieve this with minimal human labelling effort, we first automatically sample a small set of images that are likely to falsify the target model from a large corpus of web images via the maximum discrepancy competition principle. we then propose a weakly labelling strategy to further reduce the number of false positives, before time-consuming pixel-level labelling by humans. finally, we fine-tune the model to harness the identified failures, and repeat the whole process, resulting in an efficient and progressive framework for troubleshooting segmentation models. we demonstrate the feasibility of our framework using the semantic segmentation task in pascal voc, and find that the fine-tuned model exhibits significantly improved generalization when applied to real-world images with greater content diversity. the code is available at https://github.com/vita-group/troubleshooting_image_segmentation.",AB_0042

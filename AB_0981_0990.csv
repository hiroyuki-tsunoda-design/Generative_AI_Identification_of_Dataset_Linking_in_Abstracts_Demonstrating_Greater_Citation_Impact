AB,NO
"background: compared with chest x-ray (cxr) imaging, which is a single image projected from the front of the patient, chest digital tomosynthesis (cdts) imaging can be more advantageous for lung lesion de-tection because it acquires multiple images projected from multiple angles of the patient. various clinical comparative analysis and verification studies have been reported to demonstrate this, but there is no ar-tificial intelligence (ai)-based comparative analysis studies. existing ai-based computer-aided detection (cad) systems for lung lesion diagnosis have been developed mainly based on cxr images; however, cad-based on cdts, which uses multi-angle images of patients in various directions, has not been pro-posed and verified for its usefulness compared to cxr-based counterparts. background and objective: this study develops and tests a cdts-based ai cad system to detect lung lesions to demonstrate performance improvements compared to cxr-based ai cad. methods: we used multiple (e.g., five) projection images as input for the cdts-based ai model and a single-projection image as input for the cxr-based ai model to compare and evaluate the perfor-mance between models. multiple/single projection input images were obtained by virtual projection on the three-dimensional (3d) stack of computed tomography (ct) slices of each patient's lungs from which the bed area was removed. these multiple images result from shooting from the front and left and right 30/60 degrees. the projected image captured from the front was used as the input for the cxr-based ai model. the cdts-based ai model used all five projected images. the proposed cdts-based ai model consisted of five ai models that received images in each of the five directions, and obtained the final prediction result through an ensemble of five models. each model used wideresnet-50. to train and evaluate cxr-and cdts-based ai models, 500 healthy data, 206 tuberculosis data, and 242 pneumonia data were used, and three three-fold cross-validation was applied. results: the proposed cdts-based ai cad system yielded sensitivities of 0.782 and 0.785 and accu-racies of 0.895 and 0.837 for the (binary classification) performance of detecting tuberculosis and pneu-monia, respectively, against normal subjects. these results show higher performance than the sensitivity of 0.728 and 0.698 and accuracies of 0.874 and 0.826 for detecting tuberculosis and pneumonia through the cxr-based ai cad, which only uses a single projection image in the frontal direction. we found that cdts-based ai cad improved the sensitivity of tuberculosis and pneumonia by 5.4% and 8.7% respectively, compared to cxr-based ai cad without loss of accuracy. conclusions: this study comparatively proves that cdts-based ai cad technology can improve perfor-mance more than cxr. these results suggest that we can enhance the clinical application of cdts. our code is available at https://github.com/kskim- phd/cdts-cad- p .& copy; 2023 the authors. published by elsevier b.v. this is an open access article under the cc by-nc-nd license (  )",AB_0099
"cross-lingual knowledge graphs-based question answering (clkgqa) requires the question answering (qa) system to combine the knowledge graphs (kgs) in different languages to obtain answers to input questions. in previous works, the common idea is to merge cross-lingual knowledge graphs (clkgs) into a single kg through aligned entity pairs and then treat it as a traditional kg-based qa. however, as demonstrated by tan et al. (2023), existing entity alignment (ea) models cannot generate highly accurate aligned entity pairs for clkgs. therefore, two issues need to be addressed in the clkgqa task: (1) remove the dependency of the qa model on the fused kg; (2) improve the performance of the ea model in obtaining aligned entity pairs from locally isomorphic clkgs. to solve the above two issues, this paper presents cross-lingual reasoning network (clrn), a novel multi-hop qa model that allows switching knowledge graphs at any stage of the multi-hop reasoning. furthermore, we establish an iterative framework that combines clrn and ea model, in which clrn is used for extracting potential alignment triple pairs from clkgs during the qa process. the extracted triple pairs provide pseudo-aligned entities, and the additional aligned entity pairs are used to mine missing relations between entities in clkgs. these pseudo-aligned entity pairs and relations improve the performance of the ea model, resulting in higher accuracy in qa. extensive experiments demonstrate the effectiveness of the proposed model, which outperforms the baseline approaches. through iterative enhancement, the performance of the ea model has also been improved by > 1.0 % in hit@1 and hit@10, and the improvement is statistically significant in the confidence interval of ������ < 0.01. moreover, our work discusses the correlation between qa and ea from the side of qa, which has reference value for the follow-up exploration of related communities. we have open-sourced our dataset and code, which is available at the url https://github.com/tan92hl/cross-lingual-reasoning-network-for-clkgqa.",AB_0099
"fire disasters are considered to be among the most harmful hazards, causing fatalities, ecological and economic chaos, property damage, and they can even impact climate change. early fire detection is necessary to overcome these losses and disruption. fire detection using vision sensors is a promising research area that has gained significant attention from computer vision experts. traditionally, low-level colour features were used for fire detection but they have now been superseded by effective deep learning models that achieve higher accuracy. however, these models also suffer from a higher false alarm rate, due to the fact that they treat fire detection as a classification task where the entire image is classified into a single class and the region of the proposal stage is ignored. furthermore, the time complexity and model size limit these models from real-world implementation. to overcome these challenges, we propose a modified yolov5s model that integrates a stem module in the backbone, replaces larger kernels with smaller ones in the spp (neck), and adds the p6 module into the head. this model achieves promising results with lower complexity and smaller model size, and is able to detect both small and large fire regions in images. moreover, we contribute a medium-scale fire dataset that consists of three classes (i.e. vehicle fire, building fire, and indoor electric fire), with manual annotation according to the object detection model, where the dataset is publicly available for the research purposes. finally, for fair evaluation, we re-implement 12 different state-of-the-art object detection models, including the proposed model, and trained them over a self-created dataset. we found that the proposed model achieved better detection performance and applicable in real-world scenario. our codes and dataset is publicly available at https://github.com/hikmat-yar/modified-yolov5-code.",AB_0099
"colorectal cancer is the third most common type of cancer diagnosed annually, and the second leading cause of death due to cancer. early diagnosis of this ailment is vital for preventing the tumours to spread and plan treatment to possibly eradicate the disease. however, population-wide screening is stunted by the requirement of medical professionals to analyse histological slides manually. thus, an automated computer-aided detection (cad) framework based on deep learning is proposed in this research that uses histological slide images for predictions. ensemble learning is a popular strategy for fusing the salient properties of several models to make the final predictions. however, such frameworks are computationally costly since it requires the training of multiple base learners. instead, in this study, we adopt a snapshot ensemble method, wherein, instead of the traditional method of fusing decision scores from the snapshots of a convolutional neural network (cnn) model, we extract deep features from the penultimate layer of the cnn model. since the deep features are extracted from the same cnn model but for different learning environments, there may be redundancy in the feature set. to alleviate this, the features are fed into particle swarm optimization, a popular metaheuristic, for dimensionality reduction of the feature space and better classification. upon evaluation on a publicly available colorectal cancer histology dataset using a five-fold cross-validation scheme, the proposed method obtains a highest accuracy of 97.60% and f1-score of 97.61%, outperforming existing state-of-the-art methods on the same dataset. further, qualitative investigation of class activation maps provide visual explainability to medical practitioners, as well as justifies the use of the cad framework in screening of colorectal histology. our source codes are publicly accessible at: https://github.com/soumitri2001/snapensemfs.",AB_0099
"the accurate segmentation of carotid plaques in ultrasound videos will provide evidence for clinicians to evaluate the properties of plaques and treat patients effectively. however, the confusing background, blurry boundaries and plaque movement in ultrasound videos make accurate plaque segmentation challenging. to address the above challenges, we propose the refined feature-based multi-frame and multi-scale fusing gate network (rmfg_net), which captures spatial and temporal features in consecutive video frames for high-quality segmentation results and no manual annotation of the first frame. a spatial-temporal feature filter is proposed to suppress the noise of low-level cnn features and promote the detailed target area. to obtain a more accurate plaque position, we propose a transformer-based cross-scale spatial location algorithm, which models the relationship between adjacent layers of consecutive video frames to achieve stable positioning. to make full use of more detailed and semantic information, multi-layer gated computing is applied to fuse features of different layers, ensuring sufficient useful feature map aggregation for segmentation. experiments on two clinical datasets demonstrate that the proposed method outperforms other state-of-the-art methods under different evaluation metrics, and it processes images with a speed of 68 frames per second which is suitable for real-time segmentation. a large number of ablation experiments were conducted to demonstrate the effectiveness of each component and experimental setting, as well as the potential of the proposed method in ultrasound video plaque segmentation tasks. the codes can be publicly available from https://github.com/xifenghuu/rmfg_net.git.",AB_0099
"background: in the field of neuroscience, neural modules and circuits that control biological functions have been found throughout entire neural networks. correlations in neural activity can be used to identify such neural modules. recent technological advances enable us to measure whole-brain neural activity with single-cell resolution in several species including caenorhabditis elegans. because current neural activity data in c. elegans contain many missing data points, it is necessary to merge results from as many animals as possible to obtain more reliable functional modules.results: in this work, we developed a new time-series clustering method, wormtensor, to identify functional modules using whole-brain activity data from c. elegans. wormtensor uses a distance measure, modified shape-based distance to account for the lags and the mutual inhibition of cell-cell interactions and applies the tensor decomposition algorithm multi-view clustering based on matrix integration using the higher orthogonal iteration of tensors (hooi) algorithm (mc-mi-hooi), which can estimate both the weight to account for the reliability of data from each animal and the clusters that are common across animals.conclusion: we applied the method to 24 individual c. elegans and successfully found some known functional modules. compared with a widely used consensus clustering method to aggregate multiple clustering results, wormtensor showed higher silhouette coefficients. our simulation also showed that wormtensor is robust to contamination from noisy data. wormtensor is freely available as an r/cran package https://cran.r-project.org/web/packages/wormtensor.",AB_0099
"background: maintaining engagement and support for patients with chronic diseases is challenging. sms text messaging programs have complemented patient care in a variety of situations. however, such programs have not been widely translated into routine care. objective: we aimed to examine the implementation and utility of a customized sms text message-based support program for patients with type 2 diabetes (t2d), coronary heart disease, or both within a chronic disease integrated care program. methods: we conducted a 6-month pragmatic parallel-group, single-blind randomized controlled trial that recruited people with t2d or coronary heart disease. intervention participants received 4 semipersonalized sms text messages per week providing self-management support to supplement standard care. preprogrammed algorithms customized content based on participant characteristics, and the messages were sent at random times of the day and in random order by a fully automated sms text messaging engine. control participants received standard care and only administrative sms text messages. the primary outcome was systolic blood pressure. evaluations were conducted face to face whenever possible by researchers blinded to randomization. participants with t2d were evaluated for glycated hemoglobin level. participant-reported experience measures were evaluated using questionnaires and focus groups and summarized using proportions and thematic analysis. results: a total of 902 participants were randomized (n=448, 49.7% to the intervention group and n=454, 50.3% to the control group). primary outcome data were available for 89.5% (807/902) of the participants. at 6 months, there was no difference in systolic blood pressure between the intervention and control arms (adjusted mean difference=0.9 mm hg, 95% ci -1.1 to 2.1; p=.38). of 642 participants with t2d, there was no difference in glycated hemoglobin (adjusted mean difference=0.1%, 95% ci -0.1% to 0.3%; p=.35). self-reported medication adherence was better in the intervention group (relative risk=0.82, 95% ci 0.68-1.00; p=.045). participants reported that the sms text messages were useful (298/344, 86.6%) and easily understood (336/344, 97.7%) and motivated change (217/344, 63.1%). the lack of bidirectional messaging was identified as a barrier. conclusions: the intervention did not improve blood pressure in this cohort, possibly because of high clinician commitment to improved routine patient care as part of the chronic disease management program as well as favorable baseline metrics. there was high program engagement, acceptability, and perceived value. feasibility as part of an integrated care program was demonstrated. sms text messaging programs may supplement chronic disease management and support self-care. trial registration: australian new zealand clinical trials registry actrn12616001689460; https://anzctr.org.au/trial/registration/trialreview.aspx?id=371769&isreview=true international registered report identifier (irrid): rr2-10.1136/bmjopen-2018-025923",AB_0099
"specific emitter identification (sei) plays an increasingly crucial and potential role in both military and civilian scenarios. it refers to a process to discriminate individual emitters from each other by analyzing extracted characteristics from given radio signals. deep learning (dl) and deep neural networks (dnns) can learn the hidden features of data and build the classifier automatically for decision making, which have been widely used in the sei research. considering the insufficiently labeled training samples and large-unlabeled training samples, the semi-supervised learning-based sei (ss-sei) methods have been proposed. however, there are few ss-sei methods focusing on extracting the discriminative and generalized semantic features of radio signals. in this article, we propose an ss-sei method using metric-adversarial training (mat). specifically, pseudo labels are innovatively introduced into metric learning to enable semi-supervised metric learning (ssml), and an objective function alternatively regularized by ssml and virtual adversarial training (vat) is designed to extract discriminative and generalized semantic features of radio signals. the proposed mat-based ss-sei method is evaluated on an open-source large-scale real-world automatic-dependent surveillance-broadcast (ads-b) data set and wi-fi data set and is compared with the state-of-the-art methods. the simulation results show that the proposed method achieves better identification performance than existing state-of-the-art methods. specifically, when the ratio of the number of labeled training samples to the number of all training samples is 10%, the identification accuracy is 84.80% under the ads-b data set and 80.70% under the wi-fi data set. our code can be downloaded from https://github.com/lovelymimola/mat-based-ss-sei.",AB_0099
"we present a deep learning model based on an autoencoder for the reconstruction of cranial and facial defects using the medical open network for artificial intelligence (monai) framework, which has been pre-trained on the mug500+ and skullfix dataset. the implementation follows the monai contribution guidelines, hence, it can be easily tried out and used, and extended by monai users. the primary goal of this paper lies in the investigation of open-sourcing codes and pre-trained deep learning models under the monai framework. the pre-trained models generated in this work deliver reasonable results on the cranial and facial reconstruction task and provide an ideal starting-point for other researchers interested in further investigating the topic. we released the codes and the pre-trained model at the official monai 'research contributions' github repository: https://github.com/project-monai/research-contributions/tree/master/skullrec. this contribution has two novelties: 1. pre-training an autoencoder on the mug500+ and skullfix dataset for cranial and facial reconstruction using monai, and open -sourcing the codes and weights for other monai users; 2. demonstrating that existing monai tutorials can be easily adapted to new use cases, such as skull (cranial and facial) reconstruction.& copy; 2023 the author(s). published by elsevier b.v. this is an open access article under the cc by license ().",AB_0099
"with a higher demand for lithium (li), a better understanding of its concentration and spatial distribution is important to delineate potential anomalous areas. this study uses a digital soil mapping framework to combine data from recent geochemical surveys and environmental covariates that affect soil formation to predict and map aqua-regia-extractable li content across the 7.6x10(6) km(2) area of australia. catchment outlet sediment samples (i.e. soils formed on alluvial parent material) were collected by the national geochemical survey of australia at 1315 sites, with both top (0-10 cm depth) and bottom (on average similar to 60-80 cm depth) catchment outlet sediments sampled. we developed 50 bootstrap models using a cubist regression tree algorithm for each depth. the spatial prediction models were validated on an independent northern australia geochemical survey dataset, showing a good prediction with a root mean square error of 3.32 mgkg(-1) (which is 44.2 % of the interquartile range) for the top depth. the model for the bottom depth has yet to be validated. the variables of importance for the models indicated that the first three landsat 30+ barest earth bands (red, green, blue) and gamma radiometric dose have a strong impact on the development of regression-based li prediction. the bootstrapped models were then used to generate digital soil li prediction maps for both depths, which could identify and delineate areas with anomalously high li concentrations in the regolith. the predicted maps show high li concentration around existing mines and other potentially anomalous li areas that have yet to be verified. the same mapping principles can potentially be applied to other elements. the li geochemical data for calibration and validation are available from de caritat and cooper (2011b; ) and main et al. (2019; ), respectively. the covariate data used for this study were sourced from the terrestrial ecosystem research network (tern) infrastructure, which is enabled by the australian government's national collaborative research infrastructure strategy (ncris; https://esoil.io/ternlandscapes/public/products/tern/covariates/mosaics/90m/, last access: 6 december 2022; tern, 2019). the final predictive map is available at (ng et al., 2023).",AB_0099

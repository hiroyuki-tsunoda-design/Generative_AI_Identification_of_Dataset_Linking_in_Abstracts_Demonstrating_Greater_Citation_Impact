AB,NO
"a high-quality genome variation database derived from a large-scale population is one of the most important infrastructures for genomics, clinical and translational medicine research. here, we developed the chinese millionome database (cmdb), a database that contains 9.04 million single nucleotide variants (snv) with allele frequency information derived from low-coverage (0.06x-0.1x) whole-genome sequencing (wgs) data of 141 431 unrelated healthy chinese individuals. these individuals were recruited from 31 out of the 34 administrative divisions in china, covering han and 36 other ethnic minorities. cmdb, housing the wgs data of a multi-ethnic chinese population featuring wide geographical distribution, has become the most representative and comprehensive chinese population genome database to date. researchers can quickly search for variant, gene or genomic regions to obtain the variant information, including mutation basic information, allele frequency, genic annotation and overview of frequencies in global populations. furthermore, the cmdb also provides information on the association of the variants with a range of phenotypes, including height, bmi, maternal age and twin pregnancy. based on these data, researchers can conduct meta-analysis of related phenotypes. cmdb is freely available at https://db.cngb.org/cmdb/.",AB_0035
"for conventional image reconstruction based on dictionary learning in low-dose computed tomography (ct) imaging, all image blocks are represented by the same dictionary, thus limiting the reconstructed image quality. to improve the outcome, a low-dose ct iterative reconstruction algorithm based on image block classification and dictionary learning is proposed. first, each image block is classified as a smooth block or a detail block according to the local image variance. the detail block is subsequently divided into irregular blocks and edge blocks with different angles according to the pointing angle obtained from its gradient field information. then, the conventional k-singular value decomposition algorithm is applied to train dictionaries for different types of image blocks, and orthogonal matching pursuit determines the sparse coefficients during training. further, a variety of dictionary learning algorithms are used in penalty-weighted least-squares reconstruction as regular terms. finally, the relaxed linearized augmented lagrangian method with ordered subsets is used to solve the objective function. experimental results show that the proposed algorithm suppresses noise and sharpens edges in reconstructed ct images. the code of the proposed algorithm is available at https://github.com/liuyi827728/pwls_bcdl.",AB_0035
"multi-view clustering based on graph learning has attracted extensive attention due to its simplicity and efficiency in recent years. however, there are still some issues in most of the existing graph-based multi-view clustering methods. first, most of those methods require post-processing such as k-means or spec-tral rotation to get the final discrete clustering result. second, graph-based clustering methods perform clustering on a fixed input similarity graph, which could induce bad clustering results if the initial graph is with low quality. third, these methods have high computation cost, which hinders them for dealing with large-scale data. in order to solve these problems, we propose a multi-view spectral clustering method via joint adaptive graph learning and matrix factorization (aglmf). in this method, to reduce computational cost, we adopt the anchor-based strategy to construct the input similarity graphs. then, we use the l1-norm to learn a high quality similarity graph adaptively from original similarity graphs which can make the final graph more robust than original ones. in addition, aglmf uses symmetric non-negative matrix factorization to learn the final clustering indicators which can show the final consis-tent clustering result directly. finally, experimental results on multiple multi-view datasets validate the effectiveness of the proposed algorithm when compared with previous multi-view spectral clustering algorithms. the demo code of this work is publicly available at https://github.com/theywq/aglmf.git.(c) 2022 published by elsevier b.v.",AB_0035
"zero-shot learning (zsl) aims to learn models that can recognize unseen image semantics based on the training of data with seen semantics. recent studies either leverage the global image features or mine discriminative local patch features to associate the extracted visual features to the semantic attributes. however, due to the lack of the necessary top-down guidance and semantic alignment for ensuring the model attend to the real attribute-correlation regions, these methods still encounter a significant se-mantic gap between the visual modality and the attribute modality, which makes their prediction on unseen semantics unreliable. to solve this problem, this paper establishes a novel transformer encoder -decoder model, called hybrid routing transformer (hrt). in hrt encoder, we embed an active attention, which is constructed by both the bottom-up and the top-down dynamic routing pathways to generate the attribute-aligned visual feature. while in hrt decoder, we use static routing to calculate the correlation among the attribute-aligned visual features, the corresponding attribute semantics, and the class attribute vectors to generate the final class label predictions. this design makes the presented transformer model a hybrid of 1) top-down and bottom-up attention pathways and 2) dynamic and static routing pathways. comprehensive experiments on three widely-used benchmark datasets, namely cub, sun, and awa2, are conducted. the obtained experimental results demonstrate the effectiveness of the proposed method. our code is released in https://github.com/koriyn/hrt . (c) 2022 elsevier ltd. all rights reserved.",AB_0035
"to enhance the recommendation performance, session-based recommendations typically model based on graph neural networks (gnn). these models use the most recently clicked item as the user's short-term interest, as well as the query vector in the attention mechanism. based on it, the attention score is calculated with the remaining items to obtain the user's long-term interest. however, the obtained representation of long-term interest is one-sided. furthermore, unlike other recommendation technology, such as collaborative filtering that includes the user's entire history information, the session-based recommendation is more vulnerable to data sparsity. existing models primarily make predictions based on observable user-item interactions and ignore items not interacted with by users. to address the aforementioned issues, we propose the denoising autoencoder integrated with self-supervised learning (ssl) in graph neural networks (das-gnn). in das-gnn, the query extraction module based on denoising autoencoder can mine multiple user interests and assist long-term interest to express user needs more comprehensively. we propose an effective way of dividing positive and negative samples in the ssl module and use adaptive thresholds to mine negative hard samples, thereby improving training efficiency and alleviating data sparsity. extensive experiments demonstrate that the proposed das-gnn outperforms state-of-the-art models on four benchmarks. the source code is available at: https://github.com/daijiuqian/das-gnn.",AB_0035
"unpaired image-to-image translation for the generation field has made much progress recently. however, these methods suffer from mode collapse because of the overfitting of the discriminator. to this end, we propose a straightforward method to construct a contrastive loss using the feature information of the discriminator output layer, which is named multi-feature contrastive learning (mcl). our proposed method enhances the performance of the discriminator and solves the problem of model collapse by further leveraging contrastive learning. we perform extensive experiments on several open challenge datasets. our method achieves state-of-the-art results compared with current methods. finally, a series of ablation studies proved that our approach has better stability. in addition, our proposed method is also practical for single image translation tasks. code is available at https://github.com/gouayao/mcl.",AB_0035
"while network binarization is a promising method in memory saving and speedup on hardware, it in-evitably leads to binarization residual of intermediate features, resulting in performance capability degra-dation. to alleviate the above issue, we focus on the network topology design scheme to the more suit-able network structure for the extreme-low-bit scenario. in this paper, we propose the baseline-auxiliary expanding network design method to compensate for the binarization residual of features via searching for auxiliary branches, denoted as auxbranch. the intermediate feature maps are reasonably enhanced by combining baseline and auxiliary features, mimicking the corresponding feature output of the full -precision network. in addition, we devise a hybrid performance estimator (pe) with three elements of preliminary accuracy, feature similarity, and computational complexity. the pe jointly performs an ef-ficient architecture search for binarization baseline and enables automatic computation complexity ad-justment under diverse constraints. extensive experiments show that our approach is superior in terms of accuracy and computational performance, and is plug-and-play for different network backbones and binarization policies. our code is available at https://github.com/vipailab/auxbranch .(c) 2022 elsevier ltd. all rights reserved.",AB_0035
"the recommendation system is fundamental technology of the internet industry intended to solve the information overload problem in the big data era. top-k recommendation is an important task in this field. it generally functions through the comparison of positive pairs and negative pairs based on bayesian personalized ranking (bpr) loss. we find that the contrastive loss (cl) function used in contrastive learning is well-suited for top-k recommendation. however, there are two problems in the existing loss functions. first, all samples are treated the same, and hard samples are not considered. second, all nonpositive samples are considered negative samples, which ignores the fact that they are unlabelled data containing items that users may like. moreover, in our experiments, we find that when items are sorted by their similarities to the user, many negative items (or samples) appear before the positive items. we regard these negative items as hard samples and those at the top as potentially positive samples due to their high level of similarities with users. therefore, we propose a ranking -based contrastive loss (rcl) function to exploit both hard samples and potentially positive samples. experimental results demonstrate the effectiveness, broad applicability, and high training efficiency of the proposed rcl function. the code and data are available at https://github.com/haotangxjtu/rcl. (c) 2022 elsevier b.v. all rights reserved.",AB_0035
"in this paper, a novel and powerful metaheuristic optimizer, named the growth optimizer (go), is proposed. its main design inspiration originates from the learning and reflection mechanisms of individuals in their growth processes in society. learning is the process of individuals growing up by acquiring knowledge from the outside world. reflection is the process of checking the individual's own deficiencies and adjusting the individual's learning strategies to help the individual's growth. this work simulates this growth behavior mathematically and benchmarks the proposed algorithm on a total of 30 international test functions of the 2017 ieee congress on evolutionary computation real-parameter boundary constraint benchmark (cec 2017 test suite). a total of 50 state-of-the-art metaheuristic algorithms participated in the comparison process. the results of the convergence accuracy comparison and the two nonparametric statistics based on the friedman test and the wilcoxon signed-rank test showed that go provides competitive results compared to the 50 state-ofthe-art metaheuristic algorithms tested. in addition, to verify that go has the ability to solve different real-world optimization problems, go was applied to two different types of real-world optimization problems: the multiple sequence alignment (msa) problem based on the hidden markov model (hmm) and the multithresholding image segmentation problem based on kapur's entropy method. go provided more promising results than other metaheuristic techniques, especially in terms of solution quality and avoidance of local optima. the source code of the go algorithm is publicly available at https://github.com/tsingke/growth-optimizer.(c) 2022 elsevier b.v. all rights reserved.",AB_0035
"class incremental learning (cil) aims to learn new classes from the data stream, where old class data is largely discarded due to data privacy or memory restrictions. a handful of exemplars cannot reflect the complete distribution of old classes, and the separation between old and new classes is hard to guarantee, which is an important cause of catastrophic forgetting. to overcome this problem, we first propose incre-mental semantics mining (ism) to reduce the misclassification between old and new classes by excluding the semantics of old classes from the representation of new classes. then, we propose a distillation-based representation expansion strategy to encode the incremental semantics into an additional representation space. compared to the standard representation expansion strategy, our method features lower memory overhead and computational costs. in addition, an old model queue is proposed to facilitate the mainte-nance of earlier knowledge. extensive experiments on cifar-100 and imagenet datasets demonstrate the superiority of our method in both performance and parameter efficiency. several state-of-the-art results are established under different incremental settings. code: https://github.com/zihuanqiu/ism-net (c) 2022 elsevier b.v. all rights reserved.",AB_0035

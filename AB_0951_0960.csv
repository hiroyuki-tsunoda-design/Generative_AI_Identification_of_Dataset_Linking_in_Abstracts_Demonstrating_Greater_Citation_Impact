AB,NO
"this replicating computational report (rcr) describes (a) our dataflow fuzzer and (b) how to replicate the results in dataflow: toward a data-flow-guided fuzzer. our primary artifact is the dataflow fuzzer. unlike traditional coverage-guided greybox fuzzers-which use control-flow coverage to drive program exploration-dataflow uses data-flow coverage to drive exploration. this is achieved through a set of llvm-based analyses and transformations. in addition to dataflow, we also provide a set of tools, scripts, and patches for (a) statically analyzing data flows in a target program, (b) compiling a target program with the dataflow instrumentation, (c) evaluating dataflow on the magma benchmark suite, and (d) evaluating dataflow on the ddfuzz dataset. dataflow is available at https://github.com/hexhive/dataflow.",AB_0096
"object-sensitive pointer analysis, which separates the calling contexts of a method by its receiver objects, is known to achieve highly useful precision for object-oriented languages such as java. despite recent advances, all object-sensitive pointer analysis algorithms still suffer from the scalability problem due to the combinatorial explosion of contexts in large programs. in this article, we introduce a new approach, conch, that can be applied to debloat contexts for all object-sensitive pointer analysis algorithms, thereby improving significantly their efficiency while incurring a negligible loss of precision. our key insight is to approximate a recently proposed set of two necessary conditions for an object in a program to be context-sensitive, i.e., context-dependent (whose precise verification is undecidable) with a set of three linearly verifiable conditions in terms of the number of edges in the pointer assignment graph (pag) representation of the program. these three linearly verifiable conditions, which turn out to be almost always necessary in practice, are synthesized from three key observations regarding context-dependability for the objects created and used in real-world object-oriented programs. to develop a practical implementation for conch, we introduce an ifds-based algorithm for reasoning about object reachability in the pag of a program, which runs linearly in terms of the number of edges in the pag. by debloating contexts for three representative object-sensitive pointer analysis algorithms, which are applied to a set of representative java programs, conch can speed up these three baseline algorithms substantially at only a negligible loss of precision (less than 0.1%) with respect to several commonly used precision metrics. in addition, conch also improves their scalability by enabling them to analyze substantially more programs to completion than before (under a time budget of 12 hours). conch has been open-sourced (http://www.cse.unsw.edu.au/similar to corg/tools/conch), opening up new opportunities for other researchers and practitioners to further improve this research. to demonstrate this, we introduce one extension of conch to accelerate further the three baselines without losing any precision, providing further insights on extending conch to make precision-efficiency tradeoffs in future research.",AB_0096
"metaverse encapsulates our expectations of the next-generation internet, while bringing new key performance indicators (kpis). although conventional ultra-reliable and low-latency communications (urllc) can satisfy objective kpis, it is difficult to provide a personalized immersive experience that is a distinctive feature of the metaverse. since the quality of experience (qoe) can be regarded as a comprehensive kpi, the urllc is evolved towards the next generation urllc (xurllc) with a personalized resource allocation scheme to achieve higher qoe. to deploy metaverse xurllc services, we study the interaction between the metaverse service provider (msp) and the network infrastructure provider (inp), and provide an optimal contract design framework. specifically, the utility of the msp, defined as a function of metaverse users' qoe, is to be maximized, while ensuring the incentives of the inp. to model the qoe mathematically, we propose a novel metric named meta-immersion that incorporates both the objective kpis and subjective feelings of metaverse users. furthermore, we develop an attention-aware rendering capacity allocation scheme to improve qoe in xurllc. using a user-object-attention level dataset, we validate that the xurllc can achieve an average of 20.1% qoe improvement compared to the conventional urllc with a uniform resource allocation scheme. the code for this paper is available at https://github.com/hongyangdu/attentionqoe.",AB_0096
"arbitrary neural style transfer is a vital topic with great research value and wide industrial application, which strives to render the structure of one image using the style of another. recent researches have devoted great efforts on the task of arbitrary style transfer (ast) for improving the stylization quality. however, there are very few explorations about the quality evaluation of ast images, even it can potentially guide the design of different algorithms. in this paper, we first construct a new ast images quality assessment database (ast-iqad), which consists 150 content-style image pairs and the corresponding 1200 stylized images produced by eight typical ast algorithms. then, a subjective study is conducted on our ast-iqad database, which obtains the subjective rating scores of all stylized images on the three subjective evaluations, i.e., content preservation (cp), style resemblance (sr), and overall vision (ov). to quantitatively measure the quality of ast image, we propose a new sparse representation-based method, which computes the quality according to the sparse feature similarity. experimental results on our ast-iqad have demonstrated the superiority of the proposed method. the dataset and source code will be released at https://github.com/hangwei-chen/ast-iqad-srqe",AB_0096
"in this study, we address local photo enhancement to improve the aesthetic quality of an input image by applying different effects to different regions. existing photo enhancement methods are either not content-aware or not local; therefore, we propose a crowd-powered local enhancement method for content-aware local enhancement, which is achieved by asking crowd workers to locally optimize parameters for image editing functions. to make it easier to locally optimize the parameters, we propose an active learning based local filter. the parameters need to be determined at only a few key pixels selected by an active learning method, and the parameters at the other pixels are automatically predicted using a regression model. the parameters at the selected key pixels are independently optimized, breaking down the optimization problem into a sequence of single-slider adjustments. our experiments show that the proposed filter outperforms existing filters, and our enhanced results are more visually pleasing than the results by the existing enhancement methods. our source code and results are available at https://github.com/satoshi-kosugi/crowd-powered.",AB_0096
"preys in the wild evolve to be camouflaged to avoid being recognized by predators. in this way, camouflage acts as a key defence mechanism across species that is critical to survival. to detect and segment the whole scope of a camouflaged object, camouflaged object detection (cod) is introduced as a binary segmentation task, with the binary ground truth camouflage map indicating the exact regions of the camouflaged objects. in this paper, we revisit this task and argue that the binary segmentation setting fails to fully understand the concept of camouflage. we find that explicitly modeling the conspicuousness of camouflaged objects against their particular backgrounds can not only lead to a better understanding about camouflage, but also provide guidance to designing more sophisticated camouflage techniques. furthermore, we observe that it is some specific parts of camouflaged objects that make them detectable by predators. with the above understanding about camouflaged objects, we present the first triple-task learning framework to simultaneously localize, segment, and rank camouflaged objects, indicating the conspicuousness level of camouflage. as no corresponding datasets exist for either the localization model or the ranking model, we generate localization maps with an eye tracker, which are then processed according to the instance level labels to generate our ranking-based training and testing dataset. we also contribute the largest cod testing set to comprehensively analyse performance of the cod models. experimental results show that our triple-task learning framework achieves new state-of-the-art, leading to a more explainable cod network. our code, data, and results are available at: https://github.com/jingzhang617/cod-rank-localize-and-segment.",AB_0096
"reconstruction of high dynamic range image from a single low dynamic range image captured by a conventional rgb camera, which suffers from over- or under-exposure, is an ill-posed problem. in contrast, recent neuromorphic cameras like event camera and spike camera can record high dynamic range scenes in the form of intensity maps, but with much lower spatial resolution and no color information. in this article, we propose a hybrid imaging system (denoted as neurimg) that captures and fuses the visual information from a neuromorphic camera and ordinary images from an rgb camera to reconstruct high-quality high dynamic range images and videos. the proposed neurimg-hdr+ network consists of specially designed modules, which bridges the domain gaps on resolution, dynamic range, and color representation between two types of sensors and images to reconstruct high-resolution, high dynamic range images and videos. we capture a test dataset of hybrid signals on various hdr scenes using the hybrid camera, and analyze the advantages of the proposed fusing strategy by comparing it to state-of-the-art inverse tone mapping methods and merging two low dynamic range images approaches. quantitative and qualitative experiments on both synthetic data and real-world scenarios demonstrate the effectiveness of the proposed hybrid high dynamic range imaging system. code and dataset can be found at: https:// github.com/hjynwa/neurimg-hdr",AB_0096
"latent fingerprint enhancement is an essential preprocessing step for latent fingerprint identification. most latent fingerprint enhancement methods try to restore corrupted gray ridges/valleys. in this paper, we propose a new method that formulates latent fingerprint enhancement as a constrained fingerprint generation problem within a generative adversarial network (gan) framework. we name the proposed network fingergan. it can enforce its generated fingerprint (i.e, enhanced latent fingerprint) indistinguishable from the corresponding ground truth instance in terms of the fingerprint skeleton map weighted by minutia locations and the orientation field regularized by the fomfe model. because minutia is the primary feature for fingerprint recognition and minutia can be retrieved directly from the fingerprint skeleton map, we offer a holistic framework that can perform latent fingerprint enhancement in the context of directly optimizing minutia information. this will help improve latent fingerprint identification performance significantly. experimental results on two public latent fingerprint databases demonstrate that our method outperforms the state of the arts significantly. the codes will be available for non-commercial purposes from https://github.com/hubyz/latentenhancement.",AB_0096
"unmanned aerial vehicle (uav) tracking is of great significance for a wide range of applications, such as delivery and agriculture. previous benchmarks in this area mainly focused on small-scale tracking problems while ignoring the amounts of data, types of data modalities, diversities of target categories and scenarios, and evaluation protocols involved, greatly hiding the massive power of deep uav tracking. in this article, we propose webuav-3m, the largest public uav tracking benchmark to date, to facilitate both the development and evaluation of deep uav trackers. webuav-3m contains over 3.3 million frames across 4,500 videos and offers 223 highly diverse target categories. each video is densely annotated with bounding boxes by an efficient and scalable semi-automatic target annotation (sata) pipeline. importantly, to take advantage of the complementary superiority of language and audio, we enrich webuav-3m by innovatively providing both natural language specifications and audio descriptions. we believe that such additions will greatly boost future research in terms of exploring language features and audio cues for multi-modal uav tracking. in addition, a fine-grained uav tracking-under-scenario constraint (utusc) evaluation protocol and seven challenging scenario subtest sets are constructed to enable the community to develop, adapt and evaluate various types of advanced trackers. we provide extensive evaluations and detailed analyses of 43 representative trackers and envision future research directions in the field of deep uav tracking and beyond. the dataset, toolkits, and baseline results are available at https://github.com/983632847/webuav-3m.",AB_0096
"correlation has a critical role in the tracking field, especially in recent popular siamese-based trackers. the correlation operation is a simple fusion method that considers the similarity between the template and the search region. however, the correlation operation is a local linear matching process, losing semantic information and easily falling into a local optimum, which may be the bottleneck in designing high-accuracy tracking algorithms. in this work, to determine whether a better feature fusion method exists than correlation, a novel attention-based feature fusion network, inspired by the transformer, is presented. this network effectively combines the template and search region features using attention mechanism. specifically, the proposed method includes an ego-context augment module based on self-attention and a cross-feature augment module based on cross-attention. first, we present a transformer tracking (named transt) method based on the siamese-like feature extraction backbone, the designed attention-based fusion mechanism, and the classification and regression heads. based on the transt baseline, we also design a segmentation branch to generate the accurate mask. finally, we propose a stronger version of transt by extending it with a multi-template scheme and an iou prediction head, named transt-m. experiments show that our transt and transt-m methods achieve promising results on seven popular benchmarks. code and models are available at https://github.com/chenxin-dlut/transt-m.",AB_0096

AB,NO
"genome edit is a modern technology to serve mankind the main idea is derived from rna mediated nuclease, which is the crispr/cas9 natural process of the bacterial genome. in this paper, we have developed an algorithm cmt-marl for finding the multiple editable target site from the similar sequences. among different types of genes, there are many common regions, which are important concerning the production of proteins or any other biological function in the organisms. tracing multiple target sites is important for the case of gene duplication, gene fusion, finding mutations from co-expressed genes and transcripts from genes. the complexity to find out common editable targets from similar kind of sequences using brute force method is o(l(n)), where l is the genome sequence length and n is the number of sequences. if n goes higher then the complexity of the problem reaches to some infeasible computational time. we have applied reinforcement learning algorithm using eligibility trace and monte carlo method to tackle this problem. the time complexity of the algorithm cmt-marl is o (nl(2)). finally we have compared our result set with existing algorithm crispr- multitargeter [1] (http://www.multicrispr.nett ) concerning the goodness of editing. we have used the data set from ensembl biomart (http:// www.ensembl.org ). we have run our methodology in mouse, rat, zebrafish, chicken and human genes. finally, we locate the optimal regions for editing diseased or duplicated genes concerning our hybrid score mechanism with all types of biological factors.",AB_0065
"thanks to the digital age, online speech and information may now be disseminated anonymously without regard for repercussions. regulators face a unique problem with social media platforms because of the speed and volume of material and the lack of editorial supervision. the existing datasets on hate speech or offensive language identification lack diversity in the dataset's content. in this article, we create a multi-domain hate speech corpus (mhc) of english tweets that includes hate speech against religion, nationality, ethnicity, and gender in general and cover diverse domains, such as current affairs, politics, terrorism, technology, natural disasters, and human/drugs trafficking. each instance in our dataset is manually annotated as hate or non-hate. we use the existing state-of-the-art models and present a stacked-ensemble-based hate speech classifier (sehc) to identify hate speech from twitter data. our results indicate that the proposed method may serve as a strong baseline for future studies using this dataset. (the dataset is available at https://www.iitp.ac.in/-ai-nlp-ml/resources.html#mhc.)",AB_0065
"it has been declared by the world health organization (who) the novel coronavirus a global pandemic due to an exponential spread in covid-19 in the past months reaching over 100 million cases and resulting in approximately 3 million deaths worldwide. amid this pandemic, identification of cyberbullying has become a more evolving area of research over posts or comments in social media platforms. in multilingual societies like india, code-switched texts comprise the majority of the internet. identifying the online bullying of the code-switched user is bit challenging than monolingual cases. as a first step towards enabling the development of approaches for cyberbullying detection, we developed a new code-switched dataset, collected from twitter utterances annotated with binary labels. to demonstrate the utility of the proposed dataset, we build different machine learning (support vector machine & logistic regression) and deep learning (multilayer perceptron, convolution neural network, bilstm, bert) algorithms to detect cyberbullying of english-hindi (en-hi) code-switched text. our proposed model integrates different handcrafted features and is enriched by sequential and semantic patterns generated by different state-of-the-art deep neural network models. initial experimental results of the proposed deep ensemble model on our code-switched data reveal that our approach yields state-of-the-art results, i.e., 0.93 in terms of macro-averaged f1 score. the dataset and codes of the present study will be made publicly available on the paper's companion repository [https:// github.com/95sayanta/covid-19-and-cyberbullying].",AB_0065
"we present tchem, a performance portable software toolkit to enable the analysis of complex kinetic mechanisms. the software provides tools for gas-phase and surface chemistry, thermodynamic properties, and implements formulations for several canonical reactor models. analytical derivatives necessary to construct jacobian matrices corresponding to all implemented functionalities are available through automatic differentiation. tchem uses the kokkos framework to achieve portability across multiple heterogeneous computing platforms with a single version of the code. we implement a hierarchical parallelism framework to enable efficient chemical source term and thermodynamic property evaluations over the number of samples assigned to the local computing device. we analyze parallel efficiency results extracted from test cases for thermodynamic properties, source terms, and jacobians evaluations on intel xeon cpus and nvidia volta gpus.program summaryprogram title: tchemcpc library link to program files: https://doi .org /10 .17632 /25prt5g35w.1developer's repository link: https://github .com /sandialabs /tchemlicensing provisions: bsd 2-clause programming language: c++nature of problem: tchem seeks efficient solutions of models that involve complex chemical kinetic mechanisms, which are essential for various applications areas such as combustion modeling, atmospheric chemistry and catalysis. in general, a detailed chemical kinetic mechanism involves a number of species and associated elementary reactions. the system of governing equations is typically highly non-linear and stiff, involving a large range of time scales.solution method: tchem provides source term functions and numerical/analytic jacobians for canonical reactor models. in particular, the analytic jacobian is computed using automatic differentiation techniques implemented in the sacado library. for solving stiff time ode/dae systems, tchem uses the tines implementation of an adaptive 2nd-order backward difference formula to obtain efficient solutions that evolve on a range of time scales. the software employs batch parallelism to exploit massively parallel modern computing devices. target workflows correspond to reactive flow problems or uncertainty quantification studies, which require the solutions of many samples corresponding to different grid points or input conditions. the software provides performance portable implementations aiming to use modern heterogeneous computing platforms i.e., multi/many core host processors with external gpu accelerators. we achieve the performance portability using the kokkos parallel programming model that enables translation of a single kokkos implementation to multiple device-specific backend codes.published by elsevier b.v.",AB_0065
"chemistry simulations using interactive graphic user interfaces (guis) represent uniquely effective and safe tools to support multidimensional learning. computer literacy and coding skills have become increasingly important in the chemical sciences. in response to both of these facts, a series of jupyter notebooks hosted on google colaboratory were developed for undergraduate students enrolled in physical chemistry. these modules were developed for use during the covid-19 pandemic when millsaps college courses were virtual and only virtual or online laboratories could be used. these interactive exercises employ the python programming language to explore a variety of chemical problems related to kinetics, the maxwell-boltzmann distribution, numerical versus analytical solutions, and real-world application of concepts. all of the modules are available for download from github (https://github.com/abravene/python-notebooks-for-physical-chemistry). accessibility was prioritized, and students were assumed to have no prior programming experience; the notebooks are cost-free and browser-based. students were guided to use widgets to build interactive guis that provide dynamic representations, immediate access to multiple investigations, and interaction with key variables. to evaluate the perceived effectiveness of this introduction to python programming, participants were surveyed at the beginning and end of the course to gauge their interest in pursuing programming and data analysis skills and how they viewed the importance of programming and data analysis for their future careers. student reactions were generally positive and showed increased interest in programming and its importance in their futures, so these notebooks will be incorporated into the in-person laboratory in the future.",AB_0065
"deep convolutional neural networks (cnns) have been widely used for medical image segmentation. in most studies, only the output layer is exploited to compute the final segmentation results and the hidden representations of the deep learned features have not been well understood. in this paper, we propose a prototype segmentation (protoseg) method to compute a binary segmentation map based on deep features. we measure the segmentation abilities of the features by computing the dice between the feature segmentation map and ground-truth, named as the segmentation ability score (sa score for short). the corresponding sa score can quantify the segmentation abilities of deep features in different layers and units to understand the deep neural networks for segmentation. in addition, our method can provide a mean sa score which can give a performance estimation of the output on the test images without ground-truth. finally, we use the proposed protoseg method to compute the segmentation map directly on input images to further understand the segmentation ability of each input image. results are presented on segmenting tumors in brain mri, lesions in skin images, covid-related abnormality in ct images, prostate segmentation in abdominal mri, and pancreatic mass segmentation in ct images. our method can provide new insights for interpreting and explainable ai systems for medical image segmentation. our code is available on: https://github.com/shengfly/protoseg.",AB_0065
"background: concerns about the rise in adolescent vaping and cannabis use suggest the need for effective sub-stance use prevention programs. botvin lifeskills training (lst) has a strong evidence base at the middle school level for preventing or reducing tobacco use and related problems. a high school (grades 9-10) version of the lst program was also developed and shows promising initial evidence for reducing tobacco use in a single pilot study. however, the high school version of lst has not been sufficiently tested in an experimental trial, despite being widely implemented in high schools across the u.s. this paper outlines the study protocol for a large-scale cluster randomized trial of botvin high school lst, with objectives of documenting the design of prospective research and promoting transparency.methods: a total of 60 high schools in colorado and ohio were randomized to the 10-session, teacher-led intervention group (n = 33 schools) or business-as-usual control group (n = 27 schools). across two cohorts of schools, 9th-grade students complete self-report surveys at pretest, immediate posttest, 1-year follow-up, and 21-month follow-up. primary outcomes are tobacco (nicotine) use and cannabis use. secondary outcomes are alcohol use, illicit drug use, psychosocial behaviors (e.g., violence and mental health), and academic achieve-ment. intent-to-treat analyses will use multilevel modeling to estimate intervention effects across assessment points.conclusion: this independent evaluation will help to determine whether the intervention is appropriate for large-scale adoption. this trial is preregistered with the open science framework (https://osf.io/dnz5q/).",AB_0065
codetta is a python program for predicting the genetic code table of an organism from nucleotide sequences. codetta can analyze an arbitrary nucleotide sequence and needs no sequence annotation or taxonomic placement. the most likely amino acid decoding for each of the 64 codons is inferred from alignments of profile hidden markov models of conserved proteins to the input sequence. availability and implementation: codetta 2.0 is implemented as a python 3 program for macos and linux and is available from http://eddylab.org/software/codetta/codetta2.tar.gz and at http://github.com/kshulgina/codetta. contact: seaneddy@fas.harvard.edu supplementary information: supplementary data are available at bioinformatics online.,AB_0065
"background: hiv disproportionally affects persons who inject drugs (pwid), but engagement with hiv preexposure prophylaxis (prep) is low. we describe the rationale and study design for a new study, contingency management and pre-exposure prophylaxis (prep) adherence support services (compass), a hybrid type 1 effectiveness-implementation trial to promote hiv risk reduction among pwid. methods: in four community-based programs in the northeastern united states, prep-eligible pwid (target n = 526) are randomized to treatment as usual or contingency management (cm) and, as indicated, stepped up to prep adherence support services (compass) over 24 weeks. during cm sessions, participants receive timely tangible rewards for verifiable activities demonstrating 1) prep initiation and adherence, and 2) engagement with medications for opioid use disorder (moud) and other oud- related care. participants who do not have high levels of biomarker-confirmed prep adherence at week 12 will be stepped up to receive prep adherence support services (pass) consisting of strengths- based case management over 12 weeks. interventions are delivered by trained prep navigators, staff embedded within the respective sites. the primary outcome is sustained prep adherence by dried blood spot testing at 24 weeks. to inform future implementation, we are conducting implementation- focused process evaluations throughout the clinical trial. conclusions: results from this protocol are anticipated to yield novel findings regarding the impact and scalability of compass to promote hiv prevention among pwid in partnership with community-based organizations. http://clinicaltrials.gov identifier: nct04738825.",AB_0065
"here, we introduce ratestools, an automated pipeline to infer de novo mutation rates from parent-offspring trio data of diploid organisms. by providing a reference genome and high-coverage, whole-genome resequencing data of a minimum of three individuals (sire, dam and offspring), ratestools provides a list of candidate de novo mutations and calculates a putative mutation rate. ratestools uses several quality filtering steps, such as discarding sites with low mappability and highly repetitive regions, as well as sites with low genotype and mapping qualities to find potential de novo mutations. in addition, ratestools implements several optional filters based on post hoc assumptions of the heterozygosity and mutation rate of the organism. filters are highly customizable to user specifications in order to maximize utility across a wide range of applications. availability and implementation: ratestools is freely available at https://github.com/campanam/ratestools under a creative commons zero (cc0) license. the pipeline is implemented in nextflow (), ruby (http://www.ruby-lang.org), bash (https://www.gnu.org/software/bash/) and r () with reliance upon several other freely available tools. ratestools is compatible with macos and linux operating systems. contact: campanam@si.edu supplementary information: supplementary data are available at bioinformatics online.",AB_0065

AB,NO
"the non-local network (nlnet) presents a pioneering approach for capturing long-range dependencies within an image, via aggregating query-specific global context to each query position. however, through a rigorous empirical analysis, we have found that the global contexts modeled by the non-local network are almost the same for different query positions. in this paper, we take advantage of this finding to create a simplified network based on a query-independent formulation, which maintains the accuracy of nlnet but with significantly less computation. we further replace the one-layer transformation function of the non-local block by a two-layer bottleneck, which further reduces the parameter number considerably. the resulting network element, called the global context (gc) block, effectively models global context in a lightweight manner, allowing it to be applied at multiple layers of a backbone network to form a global context network (gcnet). experiments show that gcnet generally outperforms nlnet on major benchmarks for various recognition tasks. the code and network configurations are available at https://github.com/xvjiarui/gcnet.",AB_0355
"multi-instance learning (mil) is a recent machine learning paradigm which is immensely useful in various real-life applications, like image analysis, video anomaly detection, text classification, etc. it is well known that most of the existing machine learning classifiers are highly vulnerable to adversarial perturbations. since mil is a weakly supervised learning, where information is available for a set of instances, called bag and not for every instance, adversarial perturbations can be fatal. in this paper, we have proposed two adversarial perturbation methods to analyze the effect of adversarial perturbations to interpret the vulnerabilities of mil methods. out of the two algorithms, one can be customized for every bag, and the other is a universal one, which can affect all bags in a given data set and thus has some generalizability. furthermore, through simulations, we have demonstrated the efficacy of the proposed algorithms in fooling state-of-the-art mil approaches, such that these models make incorrect predictions regarding the label assigned to the bag. finally, we have discussed, through experiments, about taking care of these kind of adversarial perturbations through a simple strategy. source codes are available at https://github.com/inkiinki/mi-uap. (c) 2023 elsevier ltd. all rights reserved.",AB_0355
"fine-tuning pre-trained cross-lingual language models alleviates the need for annotated data in different languages, as it allows the models to transfer task-specific supervision between languages, especially from high- to low-resource languages. in this work, we propose to improve cross-lingual language understanding with consistency regularization-based fine-tuning. specifically, we use example consistency regularization to penalize the prediction sensitivity to four types of data augmentations, i.e., subword sampling, gaussian noise, code-switch substitution, and machine translation. in addition, we employ model consistency to regularize the models trained with two augmented versions of the same training set. experimental results on the xtreme benchmark show that our method (the code is available at https://github.com/bozheng-hit/xtune) achieves significant improvements across various cross-lingual language understanding tasks, including text classification, question answering, and sequence labeling. furthermore, we extend our method to the few-shot cross-lingual transfer setting, particularly considering a more realistic setting where machine translation systems are available. meanwhile, machine translation as data augmentation can be well combined with our consistency regularization method. experimental results demonstrate that our method also benefits the few-shot scenario.",AB_0355
"segmentation via level-set methods plays a significant role in natural and medical image analysis. re-cently, the distance regularized level-set evolution (drlse) model, which is based on variational level-set formulation has been proven very useful. however, the drlse model suffers from difficulties related to its computational cost due to the sign distance function (sdf) and courant-friedrichs-lewy (cfl) condition applied by the gradient descent method. this paper analyzes and tests the well-known fast computing al-gorithm known as alternating direction method of multipliers (admm) for level-set based image segmen-tation. that is, we compute the drlse model by using the admm algorithm. the comparison between the classical gradient descent method and the proposed admm for two-phase and multi-phase level-set formulation is provided. the numerical experiments on standard public data sets, particularly in the case of medical image segmentation, demonstrate the effectiveness and efficiency of the proposed method. the average segmentation coefficients for dice and jaccard against ground truth are 0.97 and 0.92, respec-tively, and the average running time is 1.70 seconds. 0.0932, 0.993, 0.981, and 0.964 are average estimated values for mean absolute distance (mad), accuracy, sensitivity, and specificity, respectively. the source code can be found at link https://github.com/walisamad/drlse- admm- medical- image-segmentation . & copy; 2023 elsevier b.v. all rights reserved.",AB_0355
"hyperspectral image (hsi) denoising is an ill-posed problem, leading to integrating proper prior knowledge about hyperspectral noise is critical to developing an efficient denoising method. most existing methods share a common assumption that all bands have equal noise intensity. however, such assumption runs counter to the practical hsis, leading to unpleasant denoising results. to tackle this, we intend to investigate the intrinsic properties of real hsi noise in the spectral dimension and construct a novel denoising framework bootstrapping by spectral noise distribution (n) over cap , termed (n) over cap -net. on the one hand, we develop dense and sparse recurrent calculations, exploiting intrinsic properties of hsi noise (i.e. , diversity, dense dependency, and global sparsity) to estimate spectral noise distribution. on the other hand, having the estimated spectral noise distribution, we develop a bootstrap mechanism with a repetitive emphasis on its guidance for subsequent spatial noise separation and clean hsi recovery, ensuring a more delicate denoising effect. in particular, we verify that the proposed denoising framework can achieve promising denoising performances due to the merit of spectral noise distribution bootstrapping, which also promotes new insights for future related research. the code is avaliable at https://github.com/etpan/n-net . (c) 2023 elsevier ltd. all rights reserved.",AB_0355
"the main purpose of rgb-t salient object detection (sod) is to fully integrate and exploit the information from the complementary fusion of modalities to address the underperformance of rgb sod in some challenging scenes. in this paper, we propose a novel feature aggregation network that can fully mine multi-scale and multi-modal information for complete and accurate rgb-t sod. subsequently, a cross-attention fusion module is proposed to adaptively integrate high-level features by using the attention mechanism in the transformer. then we design a simple yet effective fast feature aggregation module to fuse low-level features. through the combined work of the above modules, our network can perform well in some complex scenes by effectively fusing features from rgb and thermal modalities. finally, sev-eral experiments on publicly available datasets such as vt821, vt1000, and vt5000 demonstrate that our method outperforms state-of-the-art methods. and our code has been released at:https://github.com/ eloeszhang/fanet.(c) 2023 elsevier b.v. all rights reserved.",AB_0355
"unsupervised graph contrastive learning has recently emerged as the solution to the crisis of label in-formation scarcity for graph data in the real world. however, from the general paradigm of graph con-trastive learning, most of the existing methods are still flawed in the design and use of augmented views and the design of contrastive targets. therefore, the works on how to generate reasonable augmented views and utilize them canonically and how to construct efficient and comprehensive contrastive ob-jectives are very meaningful. based on the teaching concept, this paper proposes a new triplet teach-ing graph contrastive network with self-evolving adaptive augmentation. firstly, after carefully analyzing the internal relationships between different augmented perspectives, we present a triple teaching graph neural network framework based on the improved triplet idea. it creates contrastive objectives depend-ing on different contrastive angle levels, providing thorough guidance for graph encoders. secondly, a self-evolving adaptive graph augmentation scheme based on topology and feature information is pro-posed. it is worth mentioning that with the continuous deepening of the training process, the scheme can utilize the learnable self-attention mechanism to constantly supply our network framework with an increasing number of reliable augmented views as input. finally, when designing the contrastive objec-tives, we introduce a stochastic hybrid module to mine the unexploited information, which opportunely complements the contrastive sample space formed by our network framework. furthermore, extensive experiments on multiple real-world node classification datasets demonstrate that our model can gener-ate better-quality node embedding for downstream tasks. the implementation of this paper is available at https://github.com/papermiao/t-gcsa . (c) 2023 elsevier ltd. all rights reserved.",AB_0355
"deep neural networks have powerful capabilities, but they are vulnerable to adversarial attacks. for image classification tasks, if a small disturbance is introduced into the input image, the model is likely to be misled and causes misclassification. in this paper, we develop a robust attention ranking architecture with frequency-domain transform to defend against adversarial samples, which is called rarfta. we import the discrete cosine transform as the activation layer after the first convolutional layer, which effectively suppresses the attack based on the gradient method. to eliminate the interference of residual adversarial noise, we dynamically select key points from the feature map for classification with the attention mechanism to reduce the impact of other attacked pixels. experimental results on different datasets show that our method is superior to the existing defense methods in both black-box and white-box attacks and significantly improves the robustness of the deep neural network model. the code for our work is available at https://github.com/lixiaowenaaa/ rartfa/tree/master.",AB_0355
"domain generalization semantic segmentation methods aim to generalize well on out-of-distribution scenes, which is crucial for real-world applications. recent works focus on learning domain-invariant content information by using normalization, whitening, and domain randomization to remove style information. although these methods improve the performance on out-of-distribution scenes to some extent, they ignore the learning of edge and semantic layout information. the edge information describes the shape and boundary of an object and the semantic layout information contains the common sense priors (e.g., the spatial position of objects). for one thing, we observe that the shape of the same object with different styles is domain-invariant in the edge map. for another, we observe that the common sense priors in the semantic layout information of different scenes are domain-invariant. motivated by these observations, a novel approach is proposed for domain generalization semantic segmentation by using the edge and semantic layout information. specifically, the proposed approach contains the edge reconstruction module (erm), the semantic layout reconstruction module (slrm), and the triple informa-tion aggregation module (tiam). the erm and slrm aim to explicitly learn the edge and semantic layout information. the tiam aggregates the edge and semantic layout information to refine the content infor-mation. extensive experiments demonstrate that our approach achieves superior performance over cur-rent approaches on domain generalization segmentation tasks. the source code will be released at https://github.com/seabearlmx/diia. (c) 2023 elsevier b.v. all rights reserved.",AB_0355
"utilizing multi-modal neuroimaging data is proven to be effective in investigating human cognitive activ-ities and certain pathologies. however, it is not practical to obtain the full set of paired neuroimaging data centrally since the collection faces several constraints, e.g., high examination cost, long acquisition time, and image corruption. in addition, these data are dispersed into different medical institutions and thus cannot be aggregated for centralized training considering the privacy issues. there is a clear need to launch federated learning and facilitate the integration of dispersed data from different institutions. in this paper, we propose a new benchmark for federated domain translation on unsupervised brain image synthesis (fedmed-gan) to bridge the gap between federated learning and medical gan. fedmed-gan mitigates the mode collapse without sacrificing the performance of generators, and is widely applied to different proportions of unpaired and paired data with variation adaptation properties. we treat the gradient penalties using the federated averaging algorithm and then leverage the differential privacy gra-dient descent to regularize the training dynamics. a comprehensive evaluation is provided for comparing fedmed-gan and other centralized methods, demonstrating that the proposed algorithm outperforms the state-of-the-art. our code is available at: https://github.com/m-3lab/fedmed-gan.(c) 2023 elsevier b.v. all rights reserved.",AB_0355

AB,NO
"study objectives: patients with chronic insomnia may respond differently to therapeutic modalities. this study examined differences in response of individuals with 2 insomnia phenotypes-short sleep duration (i-ssd; < 6 hours) and normal sleep duration (i-nsd; & ge; 6 hours) determined by polysomnography-to treatment with lemborexant and zolpidem tartrate extended-release 6.25 mg (zolpidem er), compared with placebo.methods: study e2006-g000-304 (study 304; sunrise-1; nct02783729) was a global, randomized, double-blind, placebo, and active comparator-controlled, parallel-group study comparing lemborexant 5 and 10 mg in individuals aged & ge; 55 years with insomnia disorder. in this analysis, changes in subjective (self-reported) variables based on sleep diaries and objective variables based on polysomnographs were assessed after 1-month administration of study drugs. data from participants with i-ssd and i-nsd were compared.results: in the i-ssd subgroup, both lemborexant doses provided significant benefit for sleep-onset latency (sol), total sleep time (tst), and wake after sleep onset (waso) vs placebo; zolpidem er also provided significant benefit for tst and waso, but not sol, on both measures vs placebo. in the i-nsd subgroup, lemborexant and zolpidem er provided significant benefit for tst and waso vs placebo objectively but not subjectively; both doses of lemborexant provided significant benefit for sol vs placebo subjectively, but not objectively.conclusions: both drugs, but lemborexant more consistently, showed subjective and objective benefits compared with placebo in participants with insomnia with objective short sleep duration. however, neither lemborexant nor zolpidem provided consistent benefits for participants with normal sleep duration on sleep-onset and sleep maintenance variables.clinical trial registration: registry: clinicaltrials.gov; name: study of the efficacy and safety of lemborexant in subjects 55 years and older with insomnia disorder (sunrise 1); url: https://clinicaltrials.gov/ct2/show/record/nct02783729; identifier: nct02783729.",AB_0113
"unsupervised feature selection can play an important role in addressing the issue of processing massive unlabelled high-dimensional data in the domain of machine learning and data mining. this paper presents a novel unsupervised feature selection method, referred to as multi-group adaptive graph representation (mgagr). different from existing methods, the relationship between features is explored via the global similarity matrix, which is reconstructed by local similarities of multiple groups. specifically, the similarity of a feature compared to other features can be represented by the linear combination of all the local similarities. the local similarity of a representative group is given a large weight to reconstruct the global similarity. besides, an iterative algorithm is given to solve the optimization problem, in which the global similarity matrix, its corresponding reconstruction weights and the self-representation matrix are iteratively improved. experimental results on 8 benchmark datasets demonstrates that the proposed method outperforms the state-of-the-art unsupervised feature selection methods in terms of clustering performance. the source code is available at: https://github.com/misteru/mgagr.",AB_0113
"n6-methyladenosine (m6a) is a common post-transcriptional alteration that plays a critical function in a variety of biological processes. although experimental approaches for identifying m6a sites have been developed and deployed, they are currently expensive for transcriptome-wide m6a identification. some computational strategies for identifying m6a sites have been presented as an effective complement to the experimental procedure. however, their performance still requires improvement. in this study, we have proposed a novel tool called dl-m6a for the identification of m6a sites in mammals using deep learning based on different encoding schemes. the proposed tool uses three encoding schemes which give the required contextual feature representation to the input rna sequence. later these contextual feature vectors individually go through several neural network layers for shallow feature extraction after which they are concatenated to a single feature vector. the concatenated feature map is then used by several other layers to extract the deep features so that the insight features of the sequence can be used for the prediction of m6a sites. the proposed tool is firstly evaluated on the tissue-specific dataset and later on a full transcript dataset. to ensure the generalizability of the tool we assessed the proposed model by training it on a full transcript dataset and test on the tissue-specific dataset. the achieved results by the proposed model have outperformed the existing tools. the results demonstrate that the proposed tool can be of great use for the biology experts and therefore a freely accessible web-server is created which can be accessed at: http://nsclbio.jbnu.ac.kr/tools/dl-m6a/.",AB_0113
"the most striking success of deep hashing for large-scale image retrieval benefits from its powerful dis-criminative representation of deep learning and the attractive computational efficiency of compact hash code learning. most existing deep semantic-preserving hashing regard the available semantic labels as the ground truth for classification or transform them into prevalent pairwise similarities. however, such strategies fail to capture the interactive correlations between the visual semantics embedded in images and the given category-level labels. moreover, they utilize the fixed piecewise or pairwise semantics as the optimization objectives, which suffers from the limited flexibility on semantic representation and adaptive knowledge communication in hash code learning. in this paper, we propose a novel deep col-laborative graph hashing (dcgh), which collectively considers multi-level semantic embeddings, latent common space construction, and intrinsic structure mining in discriminative hash codes learning, for large-scale image retrieval. to the best of our knowledge, this is the first collaborative graph hashing for image retrieval. specifically, instead of using the conventional single-flow visual network architecture, we design a dual-stream feature encoding network to jointly explore the multi-level semantic information across visual and semantic features. moreover, a well-established shared latent space is constructed based on space reconstruction to explore the concurrent information and bridge the semantic gap between vi-sual and semantic space. furthermore, a graph convolutional network is introduced to preserve the latent structural relations in the optimal pairwise similarity-preserving hash codes. the whole learning frame-work is optimized in an end-to-end fashion. extensive experiments on different datasets demonstrate that our dcgh can achieve superb image retrieval performance against state-of-the-art supervised hash-ing methods. the source codes of the proposed dcgh are available at https://github.com/jalinwang/dcgh .(c) 2023 elsevier ltd. all rights reserved.",AB_0113
"in the past decade, convolutional neural networks (cnns) have shown prominence for semantic segmentation. although cnn models have very impressive performance, the ability to capture global representation is still insufficient, which results in suboptimal results. recently, transformer achieved huge success in nlp tasks, demonstrating its advantages in modeling long-range dependency. recently, transformer has also attracted tremendous attention from computer vision researchers who reformulate the image processing tasks as a sequence-to-sequence prediction but resulted in deteriorating local feature details. in this work, we propose a lightweight real-time semantic segmentation network called letnet. letnet combines a u-shaped cnn with transformer effectively in a capsule embedding style to compensate for respective deficiencies. meanwhile, the elaborately designed lightweight dilated bottleneck (ldb) module and feature enhancement (fe) module cultivate a positive impact on training from scratch simultaneously. extensive experiments performed on challenging datasets demonstrate that letnet achieves superior performances in accuracy and efficiency balance. specifically, it only contains 0.95m parameters and 13.6g flops but yields 72.8% miou at 120 fps on the cityscapes test set and 70.5% miou at 250 fps on the camvid test dataset using a single rtx 3090 gpu. source code will be available at https://github.com/iviplab/letnet.",AB_0113
"protein structure prediction (psp) has achieved significant progress lately. prediction of inter-residue distances by machine learning and their exploitation during the conformational search is largely among the critical factors behind the progress. real values than bin probabilities could more naturally represent inter-residue distances, while the latter, via spline curves more naturally helps obtain differentiable objective functions than the former. consequently, psp methods that exploit predicted binned distances perform better than those that exploit predicted real-valued distances. to leverage the advantage of bin probabilities in getting differentiable objective functions, in this work, we propose techniques to convert real-valued distances into distance bin probabilities. using standard benchmark proteins, we then show that our real-to-bin converted distances help psp methods obtain three-dimensional structures with 4%-16% better root mean squared deviation (rmsd), template modeling score (tm-score), and global distance test (gdt) values than existing similar psp methods. our proposed psp method is named real to bin (r2b) inter-residue distance predictor, and its code is available from https://gitlab.com/mahnewton/r2b.",AB_0113
"traditionally, vegetable and fruit production has relied on empirical and ambiguous decisions made by human farmers. to overcome this uncertainty in agriculture, smart farm robots have been widely studied in recent years. however, measuring growth information with robots remains a challenge because of the similarity in the appearance of the target plant and those around it. in this study, we propose a smart farm robot that accurately measures the growth information of a target plant based on object detection, image fusion, and data augmen-tation with fused images. the proposed smart farm robot uses an end-to-end real-time deep learning-based object detector that shows state-of-the-art performances. to distinguish the target plant from other plants with a higher accuracy and improved robustness than those of existing methods, we exploited image fusion using both rgb and depth images. in particular, the data augmentation, based on the fused rgb, and depth information, contributes to the precise measurement of growth information from smart farms, regardless of the high density of vegetables and fruits in these farms. we propose and evaluate a real-time measurement system to obtain precise target-plant growth information in precision agriculture. the code and models are publicly available on github: https://gith ub.com/kistvision/plant_growth_measurement.",AB_0113
"immunopeptidomics has made tremendous contributions to our understanding of antigen processing and presentation, by identifying and quantifying antigenic peptides presented on the cell surface by major histocompatibility complex (mhc) molecules. large and complex immunopeptidomics datasets can now be routinely generated using liquid chromatography-mass spectrometry techniques. the analysis of this data - often consisting of multiple replicates/conditions - rarely follows a standard data processing pipe-line, hindering the reproducibility and depth of analysis of immunopeptidomic data. here, we present immunolyser, an automated pipeline designed to facilitate computational analysis of immunopeptidomic data with a minimal initial setup. immunolyser brings together routine analyses, including peptide length distribution, peptide motif analysis, sequence clustering, peptide-mhc binding affinity prediction, and source protein analysis. immunolyser provides a user-friendly and interactive interface via its webserver and is freely available for academic purposes at https://immunolyser.erc.monash.edu/. the open-access source code can be downloaded at our github repository: https://github.com/prmunday/immunolyser. we anticipate that immunolyser will serve as a prominent computational pipeline to facilitate effortless and reproducible analysis of immunopeptidomic data.(c) 2023 the author(s). published by elsevier b.v. on behalf of research network of computational and structural biotechnology. this is an open access article under the cc by-nc-nd license ().",AB_0113
"because of its non-invasive nature, one of the most commonly used event-related potentials in brain -computer interface (bci) system designs is the p300 electroencephalogram (eeg) signal. the fact that the p300 response can easily be stimulated and measured is particularly important for participants with severe motor disabilities. in order to train and test p300-based bci speller systems in more realistic high-speed settings, there is a pressing need for a large and challenging benchmark dataset. various datasets already exist in the literature but most of them are not publicly available, and they either have a limited number of participants or utilize relatively long stimulus duration (sd) and inter-stimulus intervals (isi). they are also typically based on a 36 target (6 x 6) character matrix. the use of long isi, in particular, not only reduces the speed and the information transfer rates (itrs) but also oversimplifies the p300 detection. this leaves a limited challenge to state-of-the-art machine learning and signal processing algorithms. in fact, near-perfect p300 classification accuracies are reported with the existing datasets. therefore, one certainly needs a large-scale dataset with challenging settings to fully exploit the recent advancements in algorithm design (machine learning and signal processing) and achieve high-performance speller results. to this end, in this article we introduce a new freely-and publicly-accessible p300 dataset obtained using 32-channel eeg, in the hope that it will lead to new research findings and eventually more efficient bci designs. the introduced dataset comprises 18 participants performing a 40 -target (5 x 8) cued-spelling task, with reduced sd (66.6 ms) and isi (33.3 ms) for fast spelling. we have also processed, analyzed, and character-classified the introduced dataset and we presented the accuracy and itr results as a benchmark. the introduced dataset and the codes of our experiments are publicly accessible at https://data .mendeley.com /datasets /vyczny2r4w.(c) 2023 elsevier inc. all rights reserved.",AB_0113
"most recent 3d medical image segmentation methods adopt convolutional neural networks (cnns) that rely on deep feature representation and achieve adequate performance. however, due to the convolutional architectures having limited receptive fields, they cannot explicitly model the long-range dependencies in the medical image. recently, transformer can benefit from global dependencies using self-attention mechanisms and learn highly expressive representations. some works were designed based on the trans-formers, but the existing transformers suffer from extreme computational and memories, and they can-not take full advantage of the powerful feature representations in 3d medical image segmentation. in this paper, we aim to connect the different resolution streams in parallel and propose a novel network, named transformer based high resolution network (transhrnet), with an effective transformer (efftrans) block, which has sufficient feature representation even at high feature resolutions . given a 3d image, the encoder first utilizes cnn to extract the feature representations to capture the local information, and then the different f eature maps are reshaped elaborately for tokens that are fed into each transformer stream in parallel to learn the global information and repeatedly exchange the information across streams. unfortu-nately, the proposed framework based on the standard transformer needs a huge amount of computation, thus we introduce a deep and effective transformer to deliver better performance with fewer parameters. the proposed transhrnet is evaluated on the multi-atlas labeling beyond the cranial vault (bcv) dataset that consists of 11 major human organs and the medical segmentation decathlon (msd) dataset for brain tumor and spleen segmentation tasks. experimental results show that it performs better than the convo-lutional and other related transformer-based methods on the 3d multi-organ segmentation tasks. code is available at https://github.com/duweidai/transhrnet . (c) 2023 elsevier ltd. all rights reserved.",AB_0113

AB,NO
"nonnegative matrix factorization (nmf) has been widely used to learn low-dimensional representations of data. however, nmf pays the same attention to all attributes of a data point, which inevitably leads to inaccurate representations. for example, in a human-face dataset, if an image contains a hat on a head, the hat should be removed or the importance of its corresponding attributes should be decreased during matrix factorization. this article proposes a new type of nmf called entropy weighted nmf (ewnmf), which uses an optimizable weight for each attribute of each data point to emphasize their importance. this process is achieved by adding an entropy regularizer to the cost function and then using the lagrange multiplier method to solve the problem. experimental results with several datasets demonstrate the feasibility and effectiveness of the proposed method. the code developed in this study is available at https://github.com/poisson-em/entropy-weighted-nmf.",AB_0023
"emotional prosody is fully embedded in language and can be influenced by the linguistic properties of a specific language. considering the limitations of existing chinese auditory stimulus database studies, we developed and validated an emotional auditory stimuli database composed of chinese pseudo-sentences, recorded by six professional actors in mandarin chinese. emotional expressions included happiness, sadness, anger, fear, disgust, pleasant surprise, and neutrality. all emotional categories were vocalized into two types of sentence patterns, declarative and interrogative. in addition, all emotional pseudo-sentences, except for neutral, were vocalized at two levels of emotional intensity: normal and strong. each recording was validated with 40 native chinese listeners in terms of the recognition accuracy of the intended emotion portrayal; finally, 4361 pseudo-sentence stimuli were included in the database. validation of the database using a forced-choice recognition paradigm revealed high rates of emotional recognition accuracy. the detailed acoustic attributes of vocalization were provided and connected to the emotion recognition rates. this corpus could be a valuable resource for researchers and clinicians to explore the behavioral and neural mechanisms underlying emotion processing of the general population and emotional disturbances in neurological, psychiatric, and developmental disorders. the mandarin chinese auditory emotion stimulus database is available at the open science framework (https://osf.io/sfbm6/?view_only=e22a521e2a7d44c6b3343e11b88f39e3).",AB_0023
"real-time semantic segmentation is widely used in autonomous driving and robotics. most previous networks achieved great accuracy based on a complicated model involving mass computing. the existing lightweight networks generally reduce the parameter sizes by sacrificing the segmentation accuracy. it is critical to balance the parameters and accuracy for real-time semantic segmentation. in this article, we propose a lightweight multiscale-feature-fusion network (lmffnet) mainly composed of three types of components: split-extract-merge bottleneck (sem-b) block, feature fusion module (ffm), and multiscale attention decoder (mad), where the sem-b block extracts sufficient features with fewer parameters. ffms fuse multiscale semantic features to effectively improve the segmentation accuracy and the mad well recovers the details of the input images through the attention mechanism. without pretraining, lmffnet-3-8 achieves 75.1% mean intersection over union (miou) with 1.4 m parameters at 118.9 frames/s using rtx 3090 gpu. more experiments are investigated extensively on various resolutions on other three datasets of camvid, kitti, and wilddash2. the experiments verify that the proposed lmffnet model makes a decent tradeoff between segmentation accuracy and inference speed for real-time tasks. the source code is publicly available at https://github.com/greak-1124/lmffnet.",AB_0023
"attributed graph clustering aims to partition nodes of a graph structure into different groups. recent works usually use variational graph autoencoder (vgae) to make the node representations obey a specific distribution. although they have shown promising results, how to introduce supervised information to guide the representation learning of graph nodes and improve clustering performance is still an open problem. in this article, we propose a collaborative decision-reinforced self-supervision (cdrs) method to solve the problem, in which a pseudo node classification task collaborates with the clustering task to enhance the representation learning of graph nodes. first, a transformation module is used to enable end-to-end training of existing methods based on vgae. second, the pseudo node classification task is introduced into the network through multitask learning to make classification decisions for graph nodes. the graph nodes that have consistent decisions on clustering and pseudo node classification are added to a pseudo-label set, which can provide fruitful self-supervision for subsequent training. this pseudo-label set is gradually augmented during training, thus reinforcing the generalization capability of the network. finally, we investigate different sorting strategies to further improve the quality of the pseudo-label set. extensive experiments on multiple datasets show that the proposed method achieves outstanding performance compared with state-of-the-art methods. our code is available at https://github.com/jillian555/tnnls_cdrs.",AB_0023
"traditional sequential pattern mining methods were designed for symbolic sequence. as a collection of measurements in chronological order, a time series needs to be discretized into symbolic sequences, and then users can apply sequential pattern mining methods to discover interesting patterns in time series. the discretization will not only cause the loss of some important information, which partially destroys the continuity of time series, but also ignore the order relations between time-series values. inspired by order-preserving matching, this article explores a new method called order-preserving sequential pattern (opp) mining, which does not need to discretize time series into symbolic sequences and represents patterns based on the order relations of time series. an inherent advantage of such representation is that the trend of a time series can be represented by the relative order of the values underneath time series. we propose an opp-miner algorithm to mine frequent patterns in time series with the same relative order. opp-miner employs the filtration and verification strategies to calculate the support and uses the pattern fusion strategy to generate candidate patterns. to compress the result set, we also study to find the maximal opps. experimental results validate that opp-miner is not only efficient but can also discover similar subsequences in time series. in addition, case studies show that our algorithms have high utility in analyzing the covid-19 epidemic by identifying critical trends and improve the clustering performance. the algorithms and data can be downloaded from https://github.com/wuc567/pattern-mining/tree/master/opp-miner.",AB_0023
"background subtraction of videos has been a fundamental research topic in computer vision in the past decades. to alleviate the computation burden and enhance the efficiency, background subtraction from online compressive measurements has recently attracted much attention. however, current methods still have limitations. first, they are all based on matrix modeling, which breaks the spatial structure within video frames. second, they generally ignore the complex disturbance within the background, which reduces the efficiency of the low-rank assumption. to alleviate this issue, we propose a tensor-based online compressive video reconstruction and background subtraction method, abbreviated as niotenrpca, by explicitly modeling the background disturbance in different frames as nonidentical but correlated noise. by virtue of such sophisticated modeling, the proposed method can well adapt to complex video scenes and, thus, perform more robustly. extensive experiments on a series of real-world video datasets have demonstrated the effectiveness of the proposed method compared with the existing state of the arts. the code of our method is released on the website: https://github.com/crystalzina/niotenrpca.",AB_0023
"image-based virtual try-on tasks with the goal of transferring a target clothing item onto the corresponding region of a person have attracted increasing research attention recently. however, most of the existing image-based virtual try-on methods have a shortcoming in detail generation and preservation. to resolve these issues, we propose a novel virtual try-on network to generate photo-realistic try-on image while preserving the details of clothes and non-target regions. we introduce two key innovations. one is the clothing warping module, which uses a warping strategy combining feature with pixel transformation to obtain the warped clothes with realistic texture and robust alignment. the other is the arm generation module, which is an original module and is highly effective for dealing with occlusion and generating the details of the arm region. in addition, we use a distillation strategy to solve the degeneration caused by the wrong parsing, which further proves the effectiveness of our components. extensive experiments on a public fashion dataset demonstrate our system achieves the state-of-the-art virtual try-on performance both qualitatively and quantitatively. the code is available at https://github.com/changyuan96/vtnct.",AB_0023
"this article presents a new text-to-image (t2i) generation model, named distribution regularization generative adversarial network (dr-gan), to generate images from text descriptions from improved distribution learning. in dr-gan, we introduce two novel modules: a semantic disentangling module (sdm) and a distribution normalization module (dnm). sdm combines the spatial self-attention mechanism (ssam) and a new semantic disentangling loss (sdl) to help the generator distill key semantic information for the image generation. dnm uses a variational auto-encoder (vae) to normalize and denoise the image latent distribution, which can help the discriminator better distinguish synthesized images from real images. dnm also adopts a distribution adversarial loss (dal) to guide the generator to align with normalized real image distributions in the latent space. extensive experiments on two public datasets demonstrated that our dr-gan achieved a competitive performance in the t2i task. the code link: https://github.com/tan-h-c/dr-gan-distribution-regularization-for-text-to-image-generation.",AB_0023
"the powerful learning ability of deep neural networks enables reinforcement learning (rl) agents to learn competent control policies directly from continuous environments. in theory, to achieve stable performance, neural networks assume identically and independently distributed (i.i.d.) inputs, which unfortunately does not hold in the general rl paradigm where the training data are temporally correlated and nonstationary. this issue may lead to the phenomenon of ``catastrophic interference'' and the collapse in performance. in this article, we present interference-aware deep q-learning (iq) to mitigate catastrophic interference in single-task deep rl. specifically, we resort to online clustering to achieve on-the-fly context division, together with a multihead network and a knowledge distillation regularization term for preserving the policy of learned contexts. built upon deep q networks (dqns), iq consistently boosts the stability and performance when compared to existing methods, verified with extensive experiments on classic control and atari tasks. the code is publicly available at https://github.com/sweety-dm/interference-aware-deep-q-learning.",AB_0023
"knowledge distillation (kd) transfers discriminative knowledge from a large and complex model (known as teacher) to a smaller and faster one (known as student). existing advanced kd methods, limited to fixed feature extraction paradigms that capture teacher's structure knowledge to guide the training of the student, often fail to obtain comprehensive knowledge to the student. toward this end, in this article, we propose a new approach, synchronous teaching knowledge distillation (stkd), to integrate online teaching and offline teaching for transferring rich and comprehensive knowledge to the student. in the online learning stage, a blockwise unit is designed to distill the intermediate-level knowledge and high-level knowledge, which can achieve bidirectional guidance of the teacher and student networks. intermediate-level information interaction provides more supervisory information to the student network and is useful to enhance the quality of final predictions. in the offline learning stage, the stkd approach applies a pretrained teacher to further improve the performance and accelerate the training process by providing prior knowledge. trained simultaneously, the student learns multilevel and comprehensive knowledge by incorporating online teaching and offline teaching, which combines the advantages of different kd strategies through our stkd method. experimental results on the svhn, cifar-10, cifar-100, and imagenet ilsvrc 2012 real-world datasets show that the proposed method achieves significant performance improvements compared with the state-of-the-art methods, especially with satisfying accuracy and model size. code for stkd is provided at https://github.com/nanxiaotong/stkd.",AB_0023

AB,NO
"3d point cloud registration is a fundamental problem in computer vision (cv) and computer graphics (cg). recently, a series of learning-based algorithms have been proposed to show the advantages in regis-tration accuracy and inference speed. however, those learning-based methods usually ignore transforma-tions with constrained rotations and translations in registration. in this paper, we propose a novel hybrid optimization method to solve the constrained rotational and translational transformations. a mapping function is introduced to deal with the restrained variables in optimization. our method achieves supe-rior performance on the multi-view partial point dataset, which won the first place on the registration challenge in iccv 2021. the method is also validated on the synthetic datasets modelnet, icl-nuim, and the realistic 3dmatch dataset. we demonstrate that the global optimization methods still have great po-tential research for point cloud registration. the code is available at https://github.com/dizzy-cell/houv .(c) 2022 elsevier ltd. all rights reserved.",AB_0036
"the size and shape of the tongue can reflect different pathological changes of the human body in traditional chinese medicine (tcm). recently, convolutional neural networks (cnns) have been widely used for the classification of the color, thickness and teeth marks of the tongue. however, only a few works have been devoted to tongue size and shape classification, which is also key evidence for tongue diagnosis. in this work, we proposed an efficient deep network, tscwnet, for tongue size and shape classification. the proposed tsc-wnet consists of two subnetworks, i.e. tsc-net and tsc-unet. while tsc-net is a straightforward and effective classification backbone, tsc-unet is built for tongue segmentation and offers complementary beneficial features to enhance the classification performance of the networks. our classification backbone requires fewer parameters than classic cnns like alexnet, vgg16 and resnet18, and achieves better classification performance. employing tsc-net as the encoder, the tsc-unet was used to provide the segmentation information for helping better tongue size and shape classification. two different datasets, i.e. fjtcm/szu and biohit, were employed for performance evaluation. the experimental results show that tsc-net achieves at least 2% higher accuracy and f1 score than the baseline networks. ablation studies show that the fusion of tsc-net and tsc-unet at both input and feature levels can further improve the accuracy and f1 score by about 2%. the code is available at: https://github. com/yating-huang/tsc-wnet.",AB_0036
"sequential recommendations have become a focus of attention across the deep learning community owing to their fitness to the actual application scenario. although recently we have witnessed a surge of work on sequential recommender systems, they are still insufficient in exploring and exploiting item-attribute relations to enhance prediction accuracy. in this work, we propose a novel technological framework, mia-sr, for sequential recommendation (sr) by modeling and predicting user preferences with multiple item attributes (mia). when modeling the dynamic behavior of a user, not only the item sequence but also the attribute sequence is used to generate the fused representation of users. further, we propose using a graph convolution network on the item-attribute bipartite graph to enhance the representations of items and attribute entities. moreover, mia-sr is naturally empowered with a multi-tasking strategy to exploit inductive bias among different preference signals and enhance item recommendation. extensive experiments on public benchmark datasets have verified the merits of mia-sr. the source code and data are available at: https://github.com/619496775/mia-sr.(c) 2022 elsevier b.v. all rights reserved.",AB_0036
"recently, deep neural networks (dnns) promote mainly by network architectures and loss functions; however, the development of neuron models has been quite limited. in this study, inspired by the mechanism of human cognition, a hyper-sausage coverage function (hscf) neuron model possessing a high flexible plasticity. then, a novel cross-entropy and volume-coverage (ce_vc) loss is defined, which compresses the volume of the hyper-sausage to the hilt, and helps alleviate confusion among different classes, thus ensuring the intra-class compactness of the samples. finally, a divisive iteration method is introduced, which considers each neuron model as a weak classifier, and iteratively increases the number of weak classifiers. thus, the optimal number of the hscf neuron is adaptively determined and an endto-end learning framework is constructed. in particular, to improve the classification performance, the hscf neuron can be applied to classical dnns. comprehensive experiments on eight datasets in several domains demonstrate the effectiveness of the proposed method. the proposed method exhibits the feasibility of boosting dnns with neuron plasticity and provides a novel perspective for further developments in dnns. the source code is available at https://github.com/tough2011/hscfnet.git .(c) 2022 the author(s). published by elsevier ltd. this is an open access article under the cc by license (  )",AB_0036
"artificial intelligence-enabled histopathological data analysis has become a valuable assistant to the pathologist. however, existing models lack representation and inference abilities compared with those of pathologists, especially in cancer subtype diagnosis, which is unconvincing in clinical practice. for instance, pathologists typically observe the lesions of a slide from global to local, and then can give a diagnosis based on their knowledge and experience. in this paper, we propose a data and knowledge co-driving (d&k) model to replicate the process of cancer subtype classification on a histopathological slide like a pathologist. specifically, in the data-driven module, the bagging mechanism in ensemble learning is leveraged to integrate the histological features from various bags extracted by the embedding representation unit. furthermore, a knowledge-driven module is established based on the gestalt principle in psychology to build the three-dimensional (3d) expert knowledge space and map histological features into this space for metric. then, the diagnosis can be made according to the euclidean distance between them. extensive experimental results on both public and in-house datasets demonstrate that the d&k model has a high performance and credible results compared with the state-of-the-art methods for diagnosing histopathological subtypes. code: https://github.com/dennis-yb/data-and-knowledge-co-driving-for-cancer-subtypes-classification.(c) 2022 published by elsevier b.v.",AB_0036
"low-rank multi-view subspace clustering has recently attracted increasing attention in the multi-view learning research. despite significant progress, most existing approaches still suffer from two issues. first, they mostly focus on exploiting the low-rank consistency across multiple views, but often ignore the low-rank structure within each view. second, they often encounter the expensive time overhead, typically owing to the costs of matrix inversion and singular value decomposition (svd) at each iteration. in light of this, we propose an efficient and effective approach termed facilitated low-rank multi-view subspace clustering (flmsc) in this paper. in terms of efficiency, our approach factorizes the view-specific representation matrix into two small factor matrices, i.e., an orthogonal dictionary and a latent representation, which mitigates the computation cost of solving svd problems. in terms of effectiveness, our approach preserves the latent low-rank structure within each view, while at the same time encourages the structural consistency across different views by imposing an agreement term. based on this, our approach can fully explore the underlying subspace structure of multiple views, so as to better serve for the following spectral clustering. besides, a facilitated iterative algorithm is developed for the resultant optimization problem, upon which the matrix inversion operation is substantially accelerated during iterations. experimental results on a variety of multi-view data sets demonstrate the effectiveness and efficiency of our approach. the source code and data sets are available at: https://www.researchgate.net/publication/365349930_flmsc_v1. (c) 2022 elsevier b.v. all rights reserved.",AB_0036
"lightweight network architecture is essential for autonomous and intelligent monitoring of unmanned aerial vehicles (uavs), such as in object detection, image segmentation, and crowd counting applications. the state-of-the-art lightweight network learning based on neural architecture search (nas) usually costs enormous computation resources. alternatively, low-performance embedded platforms and high-resolution drone images pose a challenge for lightweight network learning. to alleviate this problem, this paper proposes a new lightweight object detection model, called ghostshufflenet (gsnet), for uav images, which is built based on zero-shot neural architecture search. this paper also introduces the new components which compose gsnet, namely ghostshuffle units (loosely based on shufflenetv2) and the backbone gsmodel-l. firstly, a lightweight search space is constructed with the ghostshuffle (gs) units to reduce the parameters and floating-point operations (flops). secondly, the parameters, flops, layers, and memory access cost (mac) as constraints add to search strategy on a zero-shot neural structure search algorithm, which then searches for an optimal network gsmodell. finally, the optimal gsmodel-l is used as the backbone network and a ghost-pan feature fusion module and detection heads are added to complete the design of the lightweight object detection network (gsnet). extensive experiments are conducted on the visdrone2019 (14.92%map) dataset and the our uav-ouc-det (8.38%map) dataset demonstrating the efficiency and effectiveness of gsnet. the completed code is available at: https://github.com/yfq-yy/gsnet. (c) 2022 elsevier b.v. all rights reserved.",AB_0036
"visual relocalization aims to estimate the pose of a camera from one or more images. in recent years deep learning-based absolute pose regression (apr) methods have attracted many attentions. they feature predicting the absolute poses without relying on any prior built maps or stored images, making the relocalization very efficient. however, robust relocalization under environments with complex appearance changes and real dynamics remains very challenging. in this paper, we propose to enhance the distinctiveness of the image features by extracting the deep relationship among objects. in particular, we extract objects in the image and construct a deep object relation graph (org) to incorporate the semantic connections and relative spatial clues of the objects. we integrate our org module into several popular apr models. extensive experiments on various public indoor and outdoor datasets demonstrate that our org module greatly enhances the robustness of image representation to environmental changes and improves the pose regression performance. the code is available at https://github.com/qcyay/orgmapnet. (c) 2022 elsevier b.v. all rights reserved.",AB_0036
"deep hashing combines feature extraction or representation with hash coding jointly, which can significantly improve the speed of large-scale image retrieval. however, we notice that compared with traditional retrieval methods, due to the reduction of dimension and information loss, the retrieval performance of binaryhash coding has declined to a certain extent. most hash retrieval algorithms focus on the semantic similarity between image pairs, and ignore the ranking information between the returned samples. the returned samples should not only match the retrieved samples, but also rank the correct samples in front of the returned list. in addition, the performance difference of the deep model used in deep hash retrieval will also limit the efficiency of retrieval. to address such problem, we proposed an ensemble deep neural model robust framework for image retrieval, which can learn compact hash codes containing rich semantic information through hash constraints. the ensemble strategy is introduced, and the weighted voting is applied to integrate the ranking list. comprehensive experiments on three benchmark datasets show that the proposed method achieves very competitive results. codes are available at https://github.com/lidonggen-123/ensemble_deephash_image_retrieval.(c) 2022 elsevier b.v. all rights reserved.",AB_0036
"existing cnn-based segmentation approaches have achieved remarkable progresses on segmenting ob-jects in regular sizes. however, when migrating them to segment tiny retinal lesions, they encounter challenges. the feature reassembly operators that they adopt are prone to discard the subtle activations about tiny lesions and fail to capture long-term dependencies. this paper aims to solve these issues and proposes a novel many-to-many reassembly of features (m2mrf) for tiny lesion segmentation. our pro-posed m2mrf reassembles features in a dimension-reduced feature space and simultaneously aggregates multiple features inside a large predefined region into multiple output features. in this way, subtle acti-vations about small lesions can be maintained as much as possible and long-term spatial dependencies can be captured to further enhance the lesion features. experimental results on two lesion segmenta-tion benchmarks, i.e., ddr and idrid, show that 1) our m2mrf outperforms existing feature reassem-bly operators, and 2) equipped with our m2mrf, the hrnetv2 is able to achieve substantially better performances and generalisation ability than existing methods. our code is made publicly available at https://github.com/cviu- csu/m2mrf- lesion- segmentation .(c) 2022 elsevier ltd. all rights reserved.",AB_0036

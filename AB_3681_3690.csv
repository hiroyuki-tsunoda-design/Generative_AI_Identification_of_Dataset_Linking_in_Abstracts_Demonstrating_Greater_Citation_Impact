AB,NO
"this article substantially extends our work published at eccv (li et al., 2020), in which an intermediate-level attack was proposed to improve the transferability of some baseline adversarial examples. specifically, we advocate a framework in which a direct linear mapping from the intermediate-level discrepancies (between adversarial features and benign features) to prediction loss of the adversarial example is established. by delving deep into the core components of such a framework, we show that a variety of linear regression models can all be considered in order to establish the mapping, the magnitude of the finally obtained intermediate-level adversarial discrepancy is correlated with the transferability, and further boost of the performance can be achieved by performing multiple runs of the baseline attack with random initialization. in addition, by leveraging these findings, we achieve new state-of-the-arts on transfer-based l(8) and l(2) attacks. our code is publicly available at https://github.com/qizhangli/ila-plus-plus-lr.",AB_0369
"unsupervised learning is just at a tipping point where it could really take off. among these approaches, contrastive learning has led to state-of-the-art performance. in this paper, we construct a novel probabilistic graphical model that effectively incorporates the low rank promoting prior into the framework of contrastive learning, referred to as lorac. in contrast to the existing conventional self-supervised approaches that only considers independent learning, our hypothesis explicitly requires that all the samples belonging to the same instance class lie on the same subspace with small dimension. this heuristic poses particular joint learning constraints to reduce the degree of freedom of the problem during the search of the optimal network parameterization. most importantly, we argue that the low rank prior employed here is not unique, and many different priors can be invoked in a similar probabilistic way, corresponding to different hypotheses about underlying truth behind the contrastive features. empirical evidences show that the proposed algorithm clearly surpasses the state-of-the-art approaches on multiple benchmarks, including image classification, object detection, instance segmentation and keypoint detection. code is available: https://github.com/ssl-codelab/lorac.",AB_0369
"a fiducial marker system usually consists of markers, a detection algorithm, and a coding system. the appearance of markers and the detection robustness are generally limited by the existing detection algorithms, which are hand-crafted with traditional low-level image processing techniques. furthermore, a sophisticatedly designed coding system is required to overcome the shortcomings of both markers and detection algorithms. to improve the flexibility and robustness in various applications, we propose a general deep learning based framework, deeptag, for fiducial marker design and detection. deeptag not only supports detection of a wide variety of existing marker families, but also makes it possible to design new marker families with customized local patterns. moreover, we propose an effective procedure to synthesize training data on the fly without manual annotations. thus, deeptag can easily adapt to existing and newly-designed marker families. to validate deeptag and existing methods, beside existing datasets, we further collect a new large and challenging dataset where markers are placed in different view distances and angles. experiments show that deeptag well supports different marker families and greatly outperforms the existing methods in terms of both detection robustness and pose accuracy. both code and dataset are available at https://herohuyongtao.github.io/research/publications/deep-tag/.",AB_0369
"with rapid development of 3d scanning technology, 3d point cloud based research and applications are becoming more popular. however, major difficulties are still exist which affect the performance of point cloud utilization. such difficulties include lack of local adjacency information, non-uniform point density, and control of point numbers. in this paper, we propose a two-step intrinsic and isotropic (i&i) resampling framework to address the challenge of these three major difficulties. the efficient intrinsic control provides geodesic measurement for a point cloud to improve local region detection and avoids redundant geodesic calculation. then the geometrically-optimized resampling uses a geometric update process to optimize a point cloud into an isotropic or adaptively-isotropic one. the point cloud density can be adjusted to global uniform (isotropic) or local uniform with geometric feature keeping (being adaptively isotropic). the point cloud number can be controlled based on application requirement or user-specification. experiments show that our point cloud resampling framework achieves outstanding performance in different applications: point cloud simplification, mesh reconstruction and shape registration. we provide the implementation codes of our resampling method at https://github.com/vvvwo/ii-resampling.",AB_0369
"in the field of pattern classification, the training of deep learning classifiers is mostly end-to-end learning, and the loss function is the constraint on the final output (posterior probability) of the network, so the existence of softmax is essential. in the case of end-to-end learning, there is usually no effective loss function that completely relies on the features of the middle layer to restrict learning, resulting in the distribution of sample latent features is not optimal, so there is still room for improvement in classification accuracy. based on the concept of predefined evenly-distributed class centroids (pedcc), this article proposes a softmax-free loss function based on predefined optimal-distribution of latent features-pod loss. the loss function only restricts the latent features of the samples, including the norm-adaptive cosine distance between the latent feature vector of the sample and the center of the predefined evenly-distributed class, and the correlation between the latent features of the samples. finally, cosine distance is used for classification. compared with the commonly used softmax loss, some typical softmax related loss functions and pedcc-loss, experiments on several commonly used datasets on several typical deep learning classification networks show that the classification performance of pod loss is always significant better and easier to converge. code is available in https://github.com/tianyuzu/pod-loss.",AB_0369
"distortions from spatial and temporal domains have been identified as the dominant factors that govern the visual quality. though both have been studied independently in deep learning-based user-generated content (ugc) video quality assessment (vqa) by frame-wise distortion estimation and temporal quality aggregation, much less work has been dedicated to the integration of them with deep representations. in this paper, we propose a spatiotemporal interactive vqa (sti-vqa) model based upon the philosophy that video distortion can be inferred from the integration of both spatial characteristics and temporal motion, along with the flow of time. in particular, for each timestamp, both the spatial distortion explored by the feature statistics and local motion captured by feature difference are extracted and fed to a transformer network for the motion aware interaction learning. meanwhile, the information flow of spatial distortion from the shallow layer to the deep layer is constructed adaptively during the temporal aggregation. the transformer network enjoys an advanced advantage for long-range dependencies modeling, leading to superior performance on ugc videos. experimental results on five ugc video benchmarks demonstrate the effectiveness and efficiency of our sti-vqa model, and the source code will be available online at https://github.com/h4nwei/sti-vqa.",AB_0369
"in object detection, precise object representation is a key factor to successfully classify and locate objects of an image. existing methods usually use rectangular anchor boxes or a set of points to represent objects. however, these methods either introduce background noise or miss the continuous appearance information inside the object, and thus cause incorrect detection results. in this paper, we propose a novel anchor-free object detection network, called crossdet++, which uses a set of growing crosslines along horizontal and vertical axes as object representations. an object can be flexibly represented as crosslines in different combinations, which inspires us to select the expressive crossline to effectively reduce the interference of noise. meanwhile, the crossline representation takes into account the continuous adjacent object information, which is useful to enhance the discriminability of object features and find the object boundaries. based on the learned crosslines, we propose an axis-query crossline growing module to adaptively capture features of crosslines and query surrounding pixels related to the line features for subsequent growing of crosslines. their growing offsets and scales can be supervised by a decoupled regression mechanism, which limits the regression target to a specific direction for decreasing the optimization difficulty. during the training, we design a semantic-guided label assignment to emphasize the importance of crossline targets with higher semantic richness, further improving the detection performance. the experiment results demonstrate the effectiveness of our proposed method. code can be available at: https://github.com/qiuheqian/crossdet.",AB_0369
"the prevalence of short-video applications imposes more requirements for video quality assessment (vqa). user-generated content (ugc) videos are captured under an unprofessional environment, thus suffering from various dynamic degradations, such as camera shaking. to cover the dynamic degradations, existing recurrent neural network-based ugc-vqa methods can only provide implicit modeling, which is unclear and difficult to analyze. in this work, we consider explicit motion representation for dynamic degradations, and propose a motion-enhanced ugc-vqa method based on decomposition and recomposition. in the decomposition stage, a dual-stream decomposition module is built, and vqa task is decomposed into single frame-based quality assessment problem and cross frames-based motion understanding. the dual streams are well grounded on the two-pathway visual system during perception, and require no extra ugc data due to knowledge transfer. hierarchical features from shallow to deep layers are gathered to narrow the gaps from tasks and domains. in the recomposition stage, a progressively residual aggregation module is built to recompose features from the dual streams. representations with different layers and pathways are interacted and aggregated in a progressive and residual manner, which keeps a good trade-off between representation deficiency and redundancy. extensive experiments on ugc-vqa databases verify that our method achieves the state-of-the-art performance and keeps a good capability of generalization. the source code will be available in https://github.com/sissuire/dsd-pro.",AB_0369
"in this paper, we study how to make unsupervised cross-modal hashing (cmh) benefit from contrastive learning (cl) by overcoming two challenges. to be exact, i) to address the performance degradation issue caused by binary optimization for hashing, we propose a novel momentum optimizer that performs hashing operation learnable in cl, thus making on-the-shelf deep cross-modal hashing possible. in other words, our method does not involve binary-continuous relaxation like most existing methods, thus enjoying better retrieval performance; ii) to alleviate the influence brought by false-negative pairs (fnps), we propose a cross-modal ranking learning loss (crl) which utilizes the discrimination from all instead of only the hard negative pairs, where fnp refers to the within-class pairs that were wrongly treated as negative pairs. thanks to such a global strategy, crl endows our method with better performance because crl will not overuse the fnps while ignoring the true-negative pairs. to the best of our knowledge, the proposed method could be one of the first successful contrastive hashing methods. to demonstrate the effectiveness of the proposed method, we carry out experiments on five widely-used datasets compared with 13 state-of-the-art methods. the code is available at https://github.com/penghu-cs/ucch.",AB_0369
"semantic segmentation is important for scene understanding. to address the scenes of adverse illumination conditions of natural images, thermal infrared (tir) images are introduced. most existing rgb-t semantic segmentation methods follow three cross-modal fusion paradigms, i. e., encoder fusion, decoder fusion, and feature fusion. some methods, unfortunately, ignore the properties of rgb and tir features or the properties of features at different levels. in this paper, we propose a novel feature fusion-based network for rgb-t semantic segmentation, named lasnet, which follows three steps of location, activation, and sharpening. the highlight of lasnet is that we fully consider the characteristics of cross-modal features at different levels, and accordingly propose three specific modules for better segmentation. concretely, we propose a collaborative location module (clm) for high-level semantic features, aiming to locate all potential objects. we propose a complementary activation module for middle-level features, aiming to activate exact regions of different objects. we propose an edge sharpening module (esm) for low-level texture features, aiming to sharpen the edges of objects. furthermore, in the training phase, we attach a location supervision and an edge supervision after clm and esm, respectively, and impose two semantic supervisions in the decoder part to facilitate network convergence. experimental results on two public datasets demonstrate that the superiority of our lasnet over relevant state-of-the-art methods. the code and results of our method are available at https://github.com/mathlee/lasnet.",AB_0369

AB,NO
"multi-exposure high dynamic range (hdr) imaging aims to generate an hdr image from multiple low dynamic range (ldr) images. there are two main challenges in this task; camera and object motions causing ghost artifacts and over/under-exposure areas having no information. to tackle these challenges, we propose a deep neural network that aligns the multiple inputs through feature transformation and hallucinates the washed-out areas after fusion. specifically, we propose a pyramidal feature adjustment network (pfan) that adjusts the reference image features' brightness and structure with respect to ldr inputs and regard them as the aligned features of the ldr inputs. then, the features from the pfans are integrated in a coarse-to-fine manner. they are first merged into an hdr image in a fusion network, and the washed-out regions are restored using valid information in a hallucination network. to deal with larger displacements in motion alignment, we also present a progressive training strategy, which begins the training with easy samples having little motion and then transfers the network with more dynamic samples. extensive experiments demonstrate that our method achieves state-of-the-art performance on benchmark datasets. our codes are available at https://github.com/haesoochung/pfan.",AB_0123
"kernel point convolution (kpconv) can effectively represent the point features of point cloud data. however, kpconv-based methods just consider the local information of each point, which is very difficult to characterize the intrinsic properties of airborne laser scanning (als) point clouds for complex laser scanning conditions. therefore, we rethink kpconv and propose a recurrent residual dual attention network (rrdan) based on the encoder-decoder structure for the semantic segmentation of als point cloud data. in the encoder stage, we design an attention kpconv (akpconv) block by using a scaling factor of batch normalization to highlight the significant channel information. then, we use the akpconv block to develop a recurrent residual kernel attention (rrka) module to iteratively aggregate the local neighborhood features. in the decoder stage, we design a global and local channel attention (glca) module with global connection and local 1-d convolution to interact the global and local information after fusing the upsampled high-level representations and the skip-connected low-level features. in addition, to reduce the influence of the long-tailed distribution of reflection intensity, we apply gamma transformation to correct the data as a normal distribution. the proposed rrdan can achieve diversified feature aggregation to implement the refined semantic segmentation of als point clouds. we evaluate our method on three als datasets (i.e., isprs, dcf2019, and lasdu) to demonstrate its performance compared to a few advanced methods. the code is available at https://github.com/sc-shendazt/rrdan.",AB_0123
"camera, inertial measurement unit (imu), and ultra-wideband (uwb) sensors are commonplace solutions to unmanned aerial vehicle (uav) localization problems. the performance of a localization system can be improved by integrating observations from different sensors. in this paper, we propose a learning-based uav localization method using the fusion of vision, imu, and uwb sensors. our model consists of visual-inertial (vi) and uwb branches. we combine the estimation results of both branches to predict global poses. to evaluate our method, we augment a public vi dataset with uwb simulations and conduct a real-world experiment. the experimental results show that our method provides more robust and accurate results than vi/uwb-only localization. our codes and data are available at https://imlabntu.github.io/viunet/.",AB_0123
"a hyperspectral video contains frames with numerous spectral bands, providing fine reflectance information for object identification and tracking. enriched features can be learned from spectral-spatial data using deep learning models. however, due to the difficulty in hyperspectral video collection, deep model training is often insufficient, causing reduced performance during the testing stage. to address this issue, we present a novel band attention grouping-based siamese framework (siambag) for hyperspectral object tracking. siambag uses massive color object tracking data to train a deep neural network. band weights obtained by the band attention module are used to group a hyperspectral image (hsi) into multiple three-channel false-color images with approximate total group weights. then multiple enhanced images obtained by histogram equalization are fed to the proposed siambag network to generate a classification branch, a regression branch, and a scale-tuning branch. in the classification branch, the response maps of multiple groups are fused by regularized group weights to estimate the position of objects. then the regression branch is used to obtain the initial object position of objects. the position offsets are fed back to the scale tune branch to relocate and fine-tune the object position by exploiting the similarity between template features and detection features. experimental results demonstrate that the proposed tracker achieves superior tracking performance than other methods. the source codes of this article will be released at https://github.com/zephyrhours/hyperspectral-object-tracking-siambag.",AB_0123
"one of the promising ways for the representation learning is contrastive learning. it enforces that positive pairs become close while negative pairs become far. contrastive learning utilizes the relative proximity or distance between positive and negative pairs. however, contrastive learning might fail to handle the easily distinguished positive-negative pairs because the gradient of easily divided positive-negative pairs comes to vanish. to overcome the problem, we propose a dynamic mixed margin (dmm) loss that generates the augmented hard positive-negative pairs that are not easily clarified. dmm generates hard positive-negative pairs by interpolating the dataset with mixup. besides, dmm adopts the dynamic margin incorporating the interpolation ratio, and dynamic adaptation improves representation learning. dmm encourages making close for positive pairs far away, whereas making a little far for strongly nearby positive pairs alleviates overfitting. our proposed dmm is a plug-and-play module compatible with diverse contrastive learning loss and metric learning. we validate that the dmm is superior to other baselines on various tasks, video-text retrieval, and recommender system task in unimodal and multimodal settings. besides, representation learned from dmm shows better robustness even if the modality missing occurs that frequently appears on the real-world dataset. implementation of dmm at downstream tasks is available here: https://github.com/teang1995/dmm",AB_0123
"this paper introduces a multiscopic cyber-physical-social system (cpss) to bridge the gap between independent rehabilitation in physical and cognitive aspects. specifically, we focus on hand-object interaction (hoi) recognition with visual attention for the block-design test (bdt). the proposed framework utilizes three levels which consist of microscopic, mesoscopic, and macroscopic models. in the microscopic model, a hand-tracking vision captures hand-skeletal data and finger joint angle features, enabling the estimation of physical hand postures. in the mesoscopic model, an egocentric vision with an eye tracker records to hand and eye movements, allowing for the symbolic representation of hand-eye coordination through hand gestures and visual attention focus during the test. an evaluation vision system employs color feature classification in the macroscopic model to determine whether the design matches the given task. through the first eight designs of wais-iv bdt with two scenarios, the system successfully measures human behavior from the physical to the cognitive domain. the experiment involving eight healthy participants investigates the relationship between physical measurement and cognitive evaluation. regression and correlation analyses between the dominant and non-dominant hands reveal that evaluation indices (task completion time, skewness-kurtosis of hand posture, attention to pattern and blocks) can indicate improvement during bdt. the outcomes of this study have significant implications for clinicians and researchers, providing valuable information that is typically unavailable in clinical settings. the proposed multiscopic cpss framework holds promise for advancing independent rehabilitation practices. code and datasets are available online at https://github.com/anom-tmu/bdt-multiscopic.",AB_0123
"as violent criminals, such as child sex offenders, tend to have high recidivism rates in modern society, there is a need to prevent such offenders from approaching socially disadvantaged and crime-prone areas, such as schools or childcare centers. accordingly, national governments and related institutions have installed surveillance cameras and provided additional personnel to manage and monitor them via video surveillance equipment. however, naked-eye monitoring by guards and manual image processing cannot properly evaluate the video captured by surveillance cameras. to address the various problems of conventional systems that simply store and retrieve image data, a system is needed that can actively classify captured images in real-time, in addition to assisting surveillance personnel. therefore, this paper proposes a video surveillance system based on a composable deep face recognition method. the proposed system detects the faces of criminals in real time from videos captured by a surveillance camera and notifies relevant institutions of the appearance of criminals. for real-time face detection, a down-sampled image forked from the original is used to localize unspecified faces. to improve accuracy and confidence in the recognition task, a scoring method based on face tracking is proposed. the final score combines the recognition confidence and the standard score to determine the embedding distance from the criminal face embedding data. the blind spots of surveillance personnel can be effectively addressed through early detection of criminals approaching crime-prone areas. the contributions of the paper are as follows. the proposed system can process images from surveillance cameras in real-time by using down-sampling. it can effectively identify the identity of criminals by using a face tracking id unit and minimizes prediction reversal by solving the congested embedding problem in the feature space that may occur when performing identification matching on a large amount of face embedding dbs. additionally, the reliability of the identification results is complemented by an identification score accumulation method. in this paper, we prototyped the proposed system and experimented with the recognition model, achieving an accuracy of 0.900 and an f-1 score of 0.943. we also experimentally confirmed that the models proposed in other studies have higher performance when using the tracked instance-level face identification method proposed in this paper. it is expected that the proposed system can be used to locate criminals and protect national facilities, and such responses can quickly prevent accidents/incidents. the dataset and code are available at https://github.com/aengoo/focusface",AB_0123
"background: accessible, cost-effective, and scalable mental health interventions are limited, particularly in low-and middle-income countries, where disparities between mental health needs and services are greatest. microinterventions (ie, brief, stand-alone, or digital approaches) aim to provide immediate reprieve and enhancements in mental health states and offer a novel and scalable framework for embedding evidence-based mental health promotion techniques into digital environments. body image is a global public health issue that increases young peoples' risk of developing more severe mental and physical health issues. embedding body image microinterventions into digital environments is one avenue for providing young people with immediate and short-term reprieve and protection from the negative exposure effects associated with social media.objective: this 2-armed, fully remote, and preregistered randomized controlled trial assessed the impact of a body image chatbot containing microinterventions on brazilian adolescents' state and trait body image and associated well-being outcomes.methods: geographically diverse brazilian adolescents aged 13-18 years (901/1715, 52.54% girls) were randomized into the chatbot or an assessment-only control condition and completed web-based self-assessments at baseline, immediately after the intervention time frame, and at 1-week and 1-month follow-ups. the primary outcomes were mean change in state (at chatbot entry and at the completion of a microintervention technique) and trait body image (before and after the intervention), with the secondary outcomes being mean change in affect (state and trait) and body image self-efficacy between the assessment time points.results: most participants who entered the chatbot (258/327, 78.9%) completed & ge;1 microintervention technique, with participants completing an average of 5 techniques over the 72-hour intervention period. chatbot users experienced small significant improvements in primary (state: p<.001, cohen d=0.30, 95% ci 0.25-0.34; and trait body image: p=.02, cohen d range=0.10, 95% ci 0.01-0.18, to 0.26, 95% ci 0.13-0.32) and secondary outcomes across various time points (state: p<.001, cohen d=0.28, 95% ci 0.22-0.33; trait positive affect: p=.02, cohen d range=0.15, 95% ci 0.03-0.27, to 0.23, 95% ci 0.08-0.37; negative affect: p=.03, cohen d range=-0.16, 95% ci -0.30 to -0.02, to -0.18, 95% ci -0.33 to -0.03; and self-efficacy: p=.02, cohen d range=0.14, 95% ci 0.03-0.25, to 0.19, 95% ci 0.08-0.32) relative to the control condition. intervention benefits were moderated by baseline levels of concerns but not by gender.conclusions: this is the first large-scale randomized controlled trial assessing a body image chatbot among brazilian adolescents. intervention attrition was high (531/858, 61.9%) and reflected the broader digital intervention literature; barriers to engagement were discussed. meanwhile, the findings support the emerging literature that indicates microinterventions and chatbot technology are acceptable and effective web-based service provisions. this study also offers a blueprint for accessible, cost-effective, and scalable digital approaches that address disparities between health care needs and provisions in low-and middle-income countries.trial registration: clinicaltrials.gov nct04825184; http://clinicaltrials.gov/ct2/show/nct04825184international registered report identifier (irrid): rr2-10.1186/s12889-021-12129-1(jmir mhealth uhealth 2023;11:e39934) doi: 10.2196/39934",AB_0123
"background: internalizing and externalizing personality traits are robust risk factors for substance use and mental health, and personality-targeted interventions are effective in preventing substance use and mental health problems in youth. however, there is limited evidence for how personality relates to other lifestyle risk factors, such as energy balance-related behaviors, and how this might inform prevention efforts.objective: this study aimed to examine concurrent cross-sectional associations between personality traits (ie, hopelessness, anxiety sensitivity, impulsivity, and sensation seeking) and sleep, diet, physical activity (pa), and sedentary behaviors (sb), 4 of the leading risk factors for chronic disease, among emerging adults.methods: data were drawn from a cohort of young australians who completed a web-based, self-report survey in 2019 during early adulthood. a series of poisson and logistic regressions were conducted to examine the concurrent associations between the risk behaviors (sleep, diet, pa, and sitting and screen time) and personality traits (hopelessness, anxiety sensitivity, impulsivity, and sensation seeking) among emerging adults in australia.results: a total of 978 participants (mean age 20.4, sd 0.5 years) completed the web-based survey. the results indicated that higher scores on hopelessness were associated with a greater daily screen (risk ratio [rr] 1.12, 95% ci 1.10-1.15) and sitting time (rr 1.05, 95% ci 1.0-1.08). similarly, higher scores on anxiety sensitivity were associated with a greater screen (rr 1.04, 95% ci 1.02-1.07) and sitting time (rr 1.04, 95% ci 1.02-1.07). higher impulsivity was associated with greater pa (rr 1.14, 95% ci 1.08-1.21) and screen time (rr 1.06, 95% ci 1.03-1.08). finally, higher scores on sensation seeking were associated with greater pa (rr 1.08, 95% ci 1.02-1.14) and lower screen time (rr 0.96, 95% ci 0.94-0.99).conclusions: the results suggest that personality should be considered when designing preventive interventions for lifestyle risk behaviors, particularly in relation to sb, such as sitting and screen time.trial registration: australian new zealand clinical trials registry actrn12612000026820; https://tinyurl.com/ykwcxspr",AB_0123
"in digital pathology, pathological tissue images that are obtained using scanners are analyzed and diseases are diagnosed. one crucial aspect of this process is the staining of the tissue slides. however, differences appear in the staining color even when using the same staining protocol owing to various factors such as different facilities, hospitals, and scanning equipment. many stain style normalization studies have been conducted to solve this problem. in this study, we propose a model named multi-domain single image reconstruction-based stain-style transfer. the proposed model is trained using a reconstruction-based learning framework, which can efficiently reduce the complexity and training time compared with that associated with the gan objective. we randomly extracted stained tissue image patches from the camelyon17 and mitos-atypia-14 datasets and demonstrated an effective stain-style translation. our study reveals that it is possible to perform translation among multiple domains using a single training image per domain. furthermore, we experimentally demonstrated that translation among color temperature domains was possible in the natural image domain. our code is publicly available at: https://github.com/jwkweon/ms-sst.",AB_0123

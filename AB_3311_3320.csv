AB,NO
"low-light image enhancement (llie) is a common pretext task for computer vision, which aims to adjust the luminance of the low-light image to obtain the normal-light image. at present, unsupervised llie has been developed. however, its performance is limited due to the lack of sufficient semantic information and guidance from a strict discriminator. in this work, a semantic-aware generative adversarial network is proposed to alleviate the above limitations. we use the pre-trained vgg model on imagenet to extract the prior semantic information, which is organically fed into the generator to refine its feature representation, and develop an adaptive image fusion strategy working on the output layer of the generator. further, to improve the discriminator's capacity of supervising generator, we design the dual-discriminator with dense connection and two image quality-driven priority queues with time-aware. the quantitative and qualitative experiments on four testing datasets demonstrate the competitiveness of the proposed model and the effectiveness of each component. our code is available at: https://github.com/shecyy/sagan.",AB_0332
"group discussions and assignments play a pivotal role in the classroom and online study. existing research has mainly focused on exploring the educational impact of group learning, while the study on automated grouping still remains under-explored. this paper proposes a principled method that aims to achieve personalized, accurate, and efficient grouping outcomes. dubbed as personas-based student grouping (psg), our method first applies unsupervised clustering techniques to assign personas to students based on their behavioral characteristics. based on their personas, we then utilize deep reinforcement learning to search for appropriate grouping rules and perform linear programming to obtain a suitable grouping scheme. finally, the teaching effectiveness is fed back as the rewards to the reinforcement learning model to optimize future grouping scheme selections. extensive experiments conducted on moocs datasets show that psg can achieve more advantageous performance in both efficiency and effectiveness compared to the manual or random grouping mechanism. we hope psg can provide students with a more enhanced learning experience and contribute to the future development of education. our project homepage is available at https://psg-project.pages.dev.",AB_0332
"automatic epilepsy detection based on electroencephalography (eeg) is crucial for advancing the diagnosis and treatment of epilepsy. in this paper, we propose a novel classification algorithm called svm-ksrc, which differs from integrated learning approaches. the algorithm establishes a connection between support vector machine (svm) and kernel sparse representation classification (ksrc) using support vectors. specifically, we extract two types of features from the pre-processed eeg signals in this study. during the training phase, these features are utilized to train the svm model and construct the kernel sparse representation dictionary. we differentiate the svm part of the features of the test data to determine whether svm or ksrc should be employed for classifying the test data. our method is evaluated on two publicly available datasets: university of bonn dataset and neurology and sleep centre-new delhi dataset. through 10 times 10-fold cross validation, our method demonstrates superior performance in epilepsy detection when compared to existing machine learning methods. the experimental results demonstrate that svm-ksrc is more effective compared to svm and ksrc used separately. it achieves over 99% accuracy in all binary classification tasks and attains 100% accuracy in certain tasks. the source code is publicly available at https://github.com/walkeraaa/svm-ksrc.",AB_0332
"enhancing images in low-light scenes is a challenging but widely concerned task in the computer vision. the mainstream learning-based methods mainly acquire the enhanced model by learning the data distribution from the specific scenes, causing poor adaptability (even failure) when meeting real-world scenarios that have never been encountered before. the main obstacle lies in the modeling conundrum from distribution discrepancy across different scenes. to remedy this, we first explore relationships between diverse low-light scenes based on statistical analysis, i.e., the network parameters of the encoder trained in different data distributions are close. we introduce the bilevel paradigm to model the above latent correspondence from the perspective of hyperparameter optimization. a bilevel learning framework is constructed to endow the scene-irrelevant generality of the encoder towards diverse scenes (i.e., freezing the encoder in the adaptation and testing phases). further, we define a reinforced bilevel learning framework to provide a meta-initialization for scene-specific decoder to further ameliorate visual quality. moreover, to improve the practicability, we establish a retinex-induced architecture with adaptive denoising and apply our built learning framework to acquire its parameters by using two training losses including supervised and unsupervised forms. extensive experimental evaluations on multiple datasets verify our adaptability and competitive performance against existing state-of-the-art works. the code and datasets will be available at https://github.com/vis-opt-group/bl.",AB_0332
"leveraging the capabilities of traditional dictionary learning (dicl) and drawing upon the success of deep neural networks (dnns), the recently proposed framework of deep convolutional dictionary learning (dcdicl) has exhibited remarkable behaviours in image denoising. note that, the application of the dcdicl method is confined to single modality scenarios, whereas the images in practice often originate from diverse modalities. in this paper, to broaden the application scope of the dcdicl method, we design a multi-modal version of it, dubbed mmdcdicl. specifically, within the mathematical model of mmdcdicl, we adopt an analytical approach to tackle the sub-problem linked to the guidance modality, harnessing its inherent reliability. meanwhile, like in dcdicl, we utilize a network-based learning approach for the noisy modality to extract trustworthy information from the data. based on the solution, we establish an interpretable network structure for mmdcdicl. additionally, wherein, we design a multi-kernel channel attention block (mkcab) in the structure to efficiently integrate the information from diverse modalities. experimental results suggest that mmdcdicl can reconstruct higher-quality outcomes both quantitatively and perceptually. code is available at http://www.diplab.net/lunwen/mmdcdicl.htm.",AB_0332
"attributed graph clustering is a fundamental task in graph learning field. because of the high-dimensional node features and the complex non-euclidean graph structure, it is challenging for attributed graph clustering methods to exploit graph information. recent studies on graph contrastive learning (gcl) have achieved promising results. however, existing gcl-based methods neither consider a clustering-friendly node representation nor a clustering-oriented loss function, resulting in inferior performance. to this end, we propose ncagc, a neighborhood contrastive representation learning method for attributed graph clustering task. specifically, ncagc constrains the representation learning of similar nodes by a neighborhood contrast module to ensure the compactness in the latent space, thus facilitating the clustering task. meanwhile, a contrastive self-expression module is present for learning a discriminative self-expression coefficient matrix, which is crucial for the subsequent subspace clustering. moreover, the two designed modules are trained and optimized jointly, which benefits the node representation learning and clustering to achieve mutual refinement. extensive experimental results on four attributed graph datasets demonstrate the superiority of ncagc compared with 16 state-of-the-art methods, which surpasses the sub-optimal method on cora dataset by 2.1%, 4.3%, and 3.7% in terms of acc, nmi, and ari, respectively. our code and dataset is available at https://github.com/wangtong627/ncagc-neurocom.",AB_0332
"with the aim of retrieving high-quality images from corrupted versions, image restoration meets the extensive demand of application scenarios. state-of-the-art methods solve this problem by means of designing convolution blocks in multistage architectures. however, the existing methods blindly extract and fuse features without considering which parts of the features are more effective for image restoration. in this paper, we propose a significance-wise mechanism with the goal of identifying the importance degree of each region in the feature representation and providing crucial feature information. through the calculation of nonlinear function in the significance-wise mechanism, the region which is more conducive to image restoration will get higher importance values. two important types of information are generated within the attention mechanism, including: (i) feature-sufficient maps with abundant feature representations, and (ii) significance-wise maps with the importance degree of patch information in the corrupted images. with the coordination of feature-sufficient maps and significance-wise maps, the network architecture can focus higher attention on crucial parts of feature information. furthermore, we design a multistage feature fusion block with the significance-wise mechanism. compared with existing attention mechanisms, our significance-wise mechanism has the ability to identify and generate crucial feature representation for multiple image restoration tasks. due to the novel design of the network, we successfully implement multiple restoration tasks only by fine-tuning the number of channels once on a network. abundant quantitative and qualitative experiments demonstrate that the effective image restoration network (eirn) outperforms existing state-of-the-art algorithms on eleven datasets across a series of image restoration tasks, including image deblurring, denoising, super-resolution, and deraining. the source code and pretrained models will be available at https://github .com /xinyuezhangqdu /eirn.",AB_0332
"all the existing models for deepfake detection focus on plaintext faces. however, outsourced computing is usually considered in practical applications for deepfake detection and the input data may contain private and sensitive information. thus, a privacy-preserving model named secure deepfake detection network (secdfd-net) is proposed for the first time in this paper. the secdfdnet uses the additive secret sharing method for secure deepfake face detection. specifically, firstly, some multi-party secure interaction protocols are designed for non -linear activation functions, i.e., secrelu for relu function, secsigm for sigmoid function, secspatial for spatial attention, and secchannel for channel attention. their security is proved in theory. our protocols have low communication and space complexity. then, the secdfdnet model is proposed by using the designed secure protocols and trained plaintext deepfake detection network (dfdnet). the experimental results show that the proposed secdfdnet can detect deepfake faces without revealing anything of private input, achieve the same accuracies as the plaintext dfdnet and outperform some existing models. the source code is available at https:// github.com/imagecbj/privacy-preserving-deepfake-face-image-detection.",AB_0332
"recent studies show that the use of multimodality can effectively enhance the understanding of social media content. the relations between texts and images become an important basis for developing multimodal data and models. some studies have attempted to label image-text relation (itr) and build supervised learning models. however, manually labeling itr is a challenging task and incurs many controversial labels because of disagreements among the annotators. in this paper, we present a novel unsupervised multimodal method called itr pseudo-labeling (itrp) that learns multimodal representations for various itr types using different finetuning strategies. our itrp method generates pseudo-labels by clustering and uses them as supervision to train the classifier and encoders. we evaluate the itrp method on the itr dataset and the effects of the samples with incorrect labels on both the supervised and unsupervised models. the code and data are available on the website https://github.com/suyindu/itrp.",AB_0332
"multi-behavior recommendation system aims to improve recommendation performance by using the interaction data of users ' multiple behaviors. although some methods have explored the dependencies between different behaviors, there are also existing challenges: (1) user-item interactions have complex dependencies; (2) the dependencies between multiple behaviors vary due to users ' personalized preferences. to address these challenges, we propose a new model mb-agcn (attention-guided graph convolutional network for multi -behavior recommendation), which considers personalized interaction patterns and cross-typed behavioral interdependencies. in the mb-agcn framework, we take the different effects of multi-behavior information on predicting user preferences into account. we first model the user multi-behavior relationships with the attention mechanism to capture the personalized multi-behavior characteristics. then, we explore the knowledge learned from the multi-behavior relationship modeling to generate a weight matrix that guides the graph neural network to learn the complex dependencies in different types of user-item interactions and capture the relationships between different types of behaviors. a comprehensive evaluation on three real-world datasets shows that mb-agcn consistently outperforms state-of-the-art methods. our codes will be available at https://github.com/3endurance/mb-agcn.",AB_0332

AB,NO
"federated learning (fl) is a distributed model training paradigm that preserves clients' data privacy. it has gained tremendous attention from both academia and industry. fl hyperparameters (e.g., the number of selected clients and the number of training passes) significantly affect the training overhead in terms of computation time, transmission time, computation load, and transmission load. however, the current practice of manually selecting fl hyperparameters imposes a heavy burden on fl practitioners because applications have different training preferences. in this article, we propose fedtune, an automatic fl hyperparameter tuning algorithm tailored to applications' diverse system requirements in fl training. fedtune iteratively adjusts fl hyperparameters during fl training and can be easily integrated into existing fl systems. through extensive evaluations of fedtune for diverse applications and fl aggregation algorithms, we show that fedtune is lightweight and effective, achieving 8.48%-26.75% system overhead reduction compared to using fixed fl hyperparameters. this article assists fl practitioners in designing high-performance fl training solutions. the source code of fedtune is available at https://github.com/datasystech/fedtune.",AB_0311
"indoor object detection has emerged as one of the key technologies for the success of numerous indoor system applications, such as autonomous navigation, accurate modeling of indoor environments, digital twin and terra hertz (thz) communications. this paper first proposes a flexible and inter-operational detection module, termed deep multi-scale context (dmsc) module, aiming at the development of efficient indoor object detection techniques using the point clouds. more specifically, by combining the deep contextual information of indoor objects and multi-scale features, a novel deep multi-scale contextual feature is designed. furthermore, we introduce the decoder part of the vision transformer into the indoor object proposal generation by means of a multi-head attention (mha) module from a three-dimensional (3d) point cloud to accurately extract object proposals generating high-quality bounding boxes. extensive experiments have shown that, the effective interoperability of the proposed dmsc module with three object detection networks, namely votenet, groupfree 3d and rbgnet, leads to improvements in their map@0.25 by 6.5%, 0.9% and 0.4% on the scannetv2 datasets, respectively. the proposed end-to-end network, termed as dmsc-net, consists of an indoor point cloud feature learning backbone (flb) unit, and three modules, namely the dmsc, a voting decision (vd) module, and an mha module. extensive experiments have shown that the dmsc-net outperforms other advanced indoor 3d detection networks, such as rbgnet, by 1.1% and 0.9% of map@0.25 when applied on scannet and sun rgb-d datasets, respectively. the developed code is publicly available at: https://github.com/cnu-dlandcv-lab/mha_dmsc.",AB_0311
"the complementary information from rgb and thermal images can remarkably boost semantic segmentation performance. existing rgb-t segmentation methods usually use simple interaction strategies to extract complementary information from rgb and thermal images, which ignores recognizability features from different imaging mechanisms. to address these problems, we propose a multistage information interaction network for rgb-t semantic segmentation called ms-irtnet. ms-irtnet has a dual-stream encoder structure that can extract multistage feature information. to better interact with multimodal information, we design a gate-weighted interaction module (gwim) and a feature information interaction module (fiim). gwim can learn multimodal information weights in different channels, while fiim integrates and fuses weighted rgb and thermal information into a single feature map. finally, multistage interactive information is fed into the decoder for semantic prediction. our method achieves 60.5 miou on the mfnet dataset, outperforming state-of-the-art methods. notably, ms-irtnet also achieved state-of-the-art results in tests of daytime images (51.7 miou) and nighttime images (62.5 miou). the code and pre-trained models are available at https://github .com /poisonzzw /ms -irtnet.",AB_0311
"sea surface temperature (sst) is one critical parameter of global climate change, and accurate sst prediction is important to various applications, e.g., weather forecasting, fishing directions, and disaster warnings. the global ocean system is unified and complex, and the sst patterns in different oceanic regions are highly diverse and correlated. however, existing data-driven sst prediction methods mainly consider the local patterns within a certain oceanic region, e.g., el nino region and the black sea. it is challenging but necessary to model the global sst correlations rather than that in a specific region to enhance the prediction accuracy of sst. in this work, we proposed a new method called hierarchical graph recurrent network (higrn) to address the issue. first, to learn the dynamic and diverse local sst patterns of specific locations, we design an adaptive node embedding with self-learned parameters to learn various sst patterns. then we develop a hierarchical cluster generator to aggregate the locations with similar patterns into regional clusters and utilize a graph convolution network to learn the spatial correlations among these clusters. finally, we introduce a multi-level attention mechanism to fuse the local patterns and regional correlations, and the output is fed into a recurrent network to achieve sst predictions. extensive experiments on two real-world datasets show that our method largely outperforms the state-of-the-art sst prediction methods. the source code is available at https://github.com/neoyanghc/higrn.",AB_0311
"matrix factorization has demonstrated promising performance in the incomplete multiview clustering (imc) tasks. however, many algorithms require feature normalization operations to ensure the stability of model results, so either the convergence is unstable, or the objective function cannot fit the data well. addressing these issues, we propose a novel imc algorithm using a normalizing alignment strategy (imcnas) based on nonnegative matrix factorization. specifically, the columns of the basis matrices are constrained into unit vector space, which integrates the feature normalization and the optimizing process, and makes the model converge fast and stable. on the other hand, this enables the model to fit the data better and produce more reasonable factorization results. further, we develop a novel pairwise co-regularization to align incomplete multiple views more directly, without introducing a common consensus matrix like traditional centroid-based co-regularization. graph regularization is also incorporated in the proposed model to utilize the geometrical information of data. we implement imcnas with a centroid-based regularization and a pairwise co-regularization respectively, and leads to two variants, i.e., imcnas-1 and imcnas-2. both variants are optimized with multiplicative updating rules. extensive experiments conducted on various real-world datasets comparing several state-of-the-art imc methods verified the effectiveness of the proposed methods. the source code is available at: https://github.com/guoshengcui/imcnas.",AB_0311
"this paper presents a strong data-mining method based on a rough set, which can simultaneously realize feature selection, classification, and knowledge representation. although a rough set, a popular method for feature selection, has good interpretability, it is not sufficiently efficient and accurate to deal with large-scale datasets with high dimensions, which prevents it from being immediately applied to real-world scenarios. to address the efficiency issue of a rough set, we discover the stability of the local redundancy (slr) of attributes and propose a theorem to prove it rigorously. based on slr, only the parts of objects in the boundary region are partitioned when calculating outer significance, which further improves the efficiency of the rough set. with regard to the accuracy issue, we show that overfitting may lead to ineffectiveness of the rough set, especially when processing noise attributes. we then propose relative importance, a robust measurement for an attribute, to alleviate such overfitting issues. in this paper, we propose a novel rough-set framework that significantly improves the efficiency and accuracy of existing rough-set methods. we further develop our rough set framework by proposing a rough concept tree for knowledge representation and classification. experimental results on public benchmark datasets show that our proposed framework achieves higher accuracy than seven state-of-the-art feature-selection methods. all the codes are available at https://github.com/syxiaa/powerroughset.",AB_0311
"graph-level representation learning is the pivotal step for downstream tasks that operate on the whole graph. the most common approach to this problem is graph pooling, where node features are typically averaged or summed to obtain the graph representations. however, pooling operations like averaging or summing inevitably cause severe information missing, which may severely downgrade the final performance. in this article, we argue what is crucial to graph-level downstream tasks includes not only the topological structure but also the distribution from which nodes are sampled. therefore, powered by existing graph neural networks (gnn), we propose a new plug-and-play pooling module, termed as distribution knowledge embedding (dkepool), where graphs are viewed as distributions on top of gnns and the pooling goal is to summarize the entire distribution information instead of retaining a certain feature vector by simple predefined pooling operations. a dkepool network de facto disassembles representation learning into two stages, structure learning and distribution learning. structure learning follows a recursive neighborhood aggregation scheme to update node features where structure information is obtained. distribution learning, on the other hand, omits node interconnections and focuses more on the distribution depicted by all the nodes. extensive experiments on graph classification tasks demonstrate that the proposed dkepool significantly and consistently outperforms the state-of-the-art methods. the code is avaliable at https://github.com/chenchkx/dkepool",AB_0311
"significant progress has been made by joint entity and relation extraction methods, which directly generate the relation triplets and mitigate the issue of overlapping relations. however, previous models generate the entity-relation triplets solely from input sentences. such information is insufficient to support the modeling of interactive information between entities and relations. in this paper, we define the features that provide mutual supports for entity and relation detection but can only be accessed at training time as privileged features for relation extraction, and devise two teacher models to exploit privileged entity and relation features, respectively. meanwhile, we propose a novel contrastive student-teacher learning framework for joint extraction of entities and relations (ster), where a student network is encouraged to amalgamate privileged knowledge from two expert teacher networks that additionally utilize the privileged features, based on contrastive learning. experiment results on three benchmark datasets (i.e., ade, scierc and conll04) demonstrate that ster has robust superiority over competitors and sets state-of-the-art. for reproducibility, we release the data and source code at: https://github.com/siat-nlp/ster.",AB_0311
"the bias problems in recommender systems are an important challenge. in this paper, we focus on solving the bias problems via uniform data. previous works have shown that simple modeling with a uniform data can alleviate the bias problems and improve the performance. however, the uniform data is usually few and expensive to collect in a real product. in order to use the valuable uniform data more effectively, we propose a novel and general knowledge distillation framework for counterfactual recommendation with four specific methods, including label-based distillation, feature-based distillation, sample-based distillation and model structure-based distillation. moreover, we discuss the relation between the proposed framework and the previous works. we then conduct extensive experiments on both public and product datasets to verify the effectiveness of the proposed four methods. in addition, we explore and analyze the performance trends of the proposed methods on some key factors, and the changes in the distribution of the recommendation lists. finally, we emphasize that counterfactual modeling with uniform data is a rich research area, and list some interesting and promising research topics worthy of further exploration. note that the source codes are available at https://github.com/dgliu/tkde_kdcrec.",AB_0311
"large-scale multidimensional cancer genomic and pharmacological profiles have been created by several large consortium projects, including nci-60, gdsc and depmap, providing novel opportunities for data mining and further understanding of intrinsic therapeutic response mechanisms. however, it is increasingly challenging for experimental biologists, especially those without a bioinformatic background, to integrate, explore, and analyse these tremendous pharmacogenomics. to address this gap, imopac, an interactive and easy-to-use web-based tool, was introduced to provide rapid visualizations and customizable functionalities on the basis of these three publicly available databases, which may reduce pharmacogenomic profiles from cell lines into readily understandable genetic, epigenetic, transcriptionomic, proteomic, metabolomic, and pharmacological events. the user-friendly query interface together with customized data storage enables users to interactively investigate and visualize multiomics alterations across genes and pathways and to link these alterations with drug responses across cell lines from diverse cancer types. the analyses in our portal include pancancer expression, drug-omics/ pathway correlation, cancer subtypes, omics-omics (cis-/trans-regulation) correlation, fusion query analysis, and drug response prediction analysis. the comprehensive multiomics and pharmacogenomic analyses with simple clicking through imopac will significantly benefit cancer precision medicine, contribute to the discoveries of potential biological mechanisms and facilitate pharmacogenomics mining in the identification of clinically actionable biomarkers for both basic researchers and clinical practitioners. imopac is freely available at http://www.hbpding.com/imopac.",AB_0311

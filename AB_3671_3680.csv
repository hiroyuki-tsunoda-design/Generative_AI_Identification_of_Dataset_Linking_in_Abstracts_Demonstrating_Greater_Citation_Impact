AB,NO
"mining interesting objects with trimap guidance and fusing multi-level features are two important issues for trimap-based matting. for feature mining, existing methods simply feed trimaps to an encoder network and mine features evenly in different regions with a decoding module, which lacks an efficient and effective way to mine interesting objects pointed out by trimaps. for emerging content-based feature fusion, most existing matting methods only focus on local features which lack the guidance of a global feature with strong semantic information related to the interesting object. in this paper, we propose a trimap-guided feature mining and fusion network consisting of our trimap-guided non-background multi-scale pooling (tmp) module and global-local context-aware fusion (glf) modules. considering that trimap provides strong semantic guidance, our tmp module focuses effective feature mining on interesting objects under the guidance of trimap without extra parameters. furthermore, our glf modules use global semantic information of interesting objects mined by our tmp module to guide an effective global-local context-aware multi-level feature fusion. in addition, we build a common interesting object matting (ciom) dataset to advance high-quality image matting. experimental results on the composition-1k test set, alphamatting benchmark, and our ciom test set demonstrate that our method outperforms state-of-the-art approaches. codes and models will be publicly available at https://github.com/serge-weihao/tmf-matting.",AB_0368
"deep neural networks (dnns) usually contain massive parameters, but there is redundancy such that it is guessed that they could be trained in low-dimensional subspaces. in this paper, we propose a dynamic linear dimensionality reduction (dldr) based on the low-dimensional properties of the training trajectory. the reduction method is efficient, supported by comprehensive experiments: optimizing dnns in 40-dimensional spaces can achieve comparable performance as regular training over thousands or even millions of parameters. since there are only a few variables to optimize, we develop an efficient quasi-newton-based algorithm, obtain robustness to label noise, and improve the performance of well-trained models, which are three follow-up experiments that can show the advantages of finding such low-dimensional subspaces. the code is released (pytorch: https://github.com/nblt/dldr and mindspore: https://gitee.com/mindspore/docs/tree/r1.6/docs/sample_code/dimension_reduce_training).",AB_0368
"we propose a fast single-stage method for both image and video instance segmentation, called sipmask, that preserves the instance spatial information by performing multiple sub-region mask predictions. the main module in our method is a light-weight spatial preservation (sp) module that generates a separate set of spatial coefficients for the sub-regions within a bounding-box, enabling a better delineation of spatially adjacent instances. to better correlate mask prediction with object detection, we further propose a mask alignment weighting loss and a feature alignment scheme. in addition, we identify two issues that impede the performance of single-stage instance segmentation and introduce two modules, including a sample selection scheme and an instance refinement module, to address these two issues. experiments are performed on both image instance segmentation dataset ms coco and video instance segmentation dataset youtube-vis. on ms coco test-dev set, our method achieves a state-of-the-art performance. in terms of real-time capabilities, it outperforms yolact by a gain of 3.0% (mask ap) under the similar settings, while operating at a comparable speed. on youtube-vis validation set, our method also achieves promising results. the source code is available at https://github.com/jialecao001/sipmask.",AB_0368
"driving safely requires multiple capabilities from human and intelligent agents, such as the generalizability to unseen environments, the safety awareness of the surrounding traffic, and the decision-making in complex multi-agent settings. despite the great success of reinforcement learning (rl), most of the rl research works investigate each capability separately due to the lack of integrated environments. in this work, we develop a new driving simulation platform called metadrive to support the research of generalizable reinforcement learning algorithms for machine autonomy. metadrive is highly compositional, which can generate an infinite number of diverse driving scenarios from both the procedural generation and the real data importing. based on metadrive, we construct a variety of rl tasks and baselines in both single-agent and multi-agent settings, including benchmarking generalizability across unseen scenes, safe exploration, and learning multi-agent traffic. the generalization experiments conducted on both procedurally generated scenarios and real-world scenarios show that increasing the diversity and the size of the training set leads to the improvement of the rl agent's generalizability. we further evaluate various safe reinforcement learning and multi-agent reinforcement learning algorithms in metadrive environments and provide the benchmarks. source code, documentation, and demo video are available at https://metadriverse.github.io/metadrive.",AB_0368
"we show that pre-trained generative adversarial networks (gans) such as stylegan and biggan can be used as a latent bank to improve the performance of image super-resolution. while most existing perceptual-oriented approaches attempt to generate realistic outputs through learning with adversarial loss, our method, generative latent bank (glean), goes beyond existing practices by directly leveraging rich and diverse priors encapsulated in a pre-trained gan. but unlike prevalent gan inversion methods that require expensive image-specific optimization at runtime, our approach only needs a single forward pass for restoration. glean can be easily incorporated in a simple encoder-bank-decoder architecture with multi-resolution skip connections. employing priors from different generative models allows glean to be applied to diverse categories (e.g., human faces, cats, buildings, and cars). we further present a lightweight version of glean, named lightglean, which retains only the critical components in glean. notably, lightglean consists of only 21% of parameters and 35% of flops while achieving comparable image quality. we extend our method to different tasks including image colorization and blind image restoration, and extensive experiments show that our proposed models perform favorably in comparison to existing methods. codes and models are available at https://github.com/open-mmlab/mmediting.",AB_0368
"the learning rate (lr) is one of the most important hyperparameters in stochastic gradient descent (sgd) algorithm for training deep neural networks (dnn). however, current hand-designed lr schedules need to manually pre-specify a fixed form, which limits their ability to adapt to practical non-convex optimization problems due to the significant diversification of training dynamics. meanwhile, it always needs to search proper lr schedules from scratch for new tasks, which, however, are often largely different with task variations, like data modalities, network architectures, or training data capacities. to address this learning-rate-schedule setting issue, we propose to parameterize lr schedules with an explicit mapping formulation, called mlr-snet. the learnable parameterized structure brings more flexibility for mlr-snet to learn a proper lr schedule to comply with the training dynamics of dnn. image and text classification benchmark experiments substantiate the capability of our method for achieving proper lr schedules. moreover, the explicit parameterized structure makes the meta-learned lr schedules capable of being transferable and plug-and-play, which can be easily generalized to new heterogeneous tasks. we transfer our meta-learned mlr-snet to query tasks like different training epochs, network architectures, data modalities, dataset sizes from the training ones, and achieve comparable or even better performance compared with hand-designed lr schedules specifically designed for the query tasks. the robustness of mlr-snet is also substantiated when the training data are biased with corrupted noise. we further prove the convergence of the sgd algorithm equipped with lr schedule produced by our mlr-snet, with the convergence rate comparable to the best-known ones of the algorithm for solving the problem. the source code of our method is released at https://github.com/xjtushujun/mlr-snet.",AB_0368
"self-supervised learning based on instance discrimination has shown remarkable progress. in particular, contrastive learning, which regards each image as well as its augmentations as an individual class and tries to distinguish them from all other images, has been verified effective for representation learning. however, conventional contrastive learning does not model the relation between semantically similar samples explicitly. in this paper, we propose a general module that considers the semantic similarity among images. this is achieved by expanding the views generated by a single image to cross-samples and multi-levels, and modeling the invariance to semantically similar images in a hierarchical way. specifically, the cross-samples are generated by a data mixing operation, which is constrained within samples that are semantically similar, while the multi-level samples are expanded at the intermediate layers of a network. in this way, the contrastive loss is extended to allow for multiple positives per anchor, and explicitly pulling semantically similar images together at different layers of the network. our method, termed as csml, has the ability to integrate multi-level representations across samples in a robust way. csml is applicable to current contrastive based methods and consistently improves the performance. notably, using moco v2 as an instantiation, csml achieves 76.6% top-1 accuracy with linear evaluation using resnet-50 as backbone, 66.7% and 75.1% top-1 accuracy with only 1% and 10% labels, respectively. all these numbers set the new state-of-the-art. the code is available at https://github.com/haohang96/csml.",AB_0368
"in pixel-based reinforcement learning (rl), the states are raw video frames, which are mapped into hidden representation before feeding to a policy network. to improve sample efficiency of state representation learning, recently, the most prominent work is based on contrastive unsupervised representation. witnessing that consecutive video frames in a game are highly correlated, to further improve data efficiency, we propose a new algorithm, i.e., masked contrastive representation learning for rl (m-curl), which takes the correlation among consecutive inputs into consideration. in our architecture, besides a cnn encoder for hidden presentation of input state and a policy network for action selection, we introduce an auxiliary transformer encoder module to leverage the correlations among video frames. during training, we randomly mask the features of several frames, and use the cnn encoder and transformer to reconstruct them based on context frames. the cnn encoder and transformer are jointly trained via contrastive learning where the reconstructed features should be similar to the ground-truth ones while dissimilar to others. during policy evaluation, the cnn encoder and the policy network are used to take actions, and the transformer module is discarded. our method achieves consistent improvements over curl on 14 out of 16 environments from dmcontrol suite and 23 out of 26 environments from atari 2600 games. the code is available at https://github.com/teslacool/m-curl.",AB_0368
"arbitrary shape text detection is a challenging task due to the significantly varied sizes and aspect ratios, arbitrary orientations or shapes, inaccurate annotations, etc. due to the scalability of pixel-level prediction, segmentation-based methods can adapt to various shape texts and hence attracted considerable attention recently. however, accurate pixel-level annotations of texts are formidable, and the existing datasets for scene text detection only provide coarse-grained boundary annotations. consequently, numerous misclassified text pixels or background pixels inside annotations always exist, degrading the performance of segmentation-based text detection methods. generally speaking, whether a pixel belongs to text or not is highly related to the distance with the adjacent annotation boundary. with this observation, in this paper, we propose an innovative and robust segmentation-based detection method via probability maps for accurately detecting text instances. to be concrete, we adopt a sigmoid alpha function (saf) to transfer the distances between boundaries and their inside pixels to a probability map. however, one probability map can not cover complex probability distributions well because of the uncertainty of coarse-grained text boundary annotations. therefore, we adopt a group of probability maps computed by a series of sigmoid alpha functions to describe the possible probability distributions. in addition, we propose an iterative model to learn to predict and assimilate probability maps for providing enough information to reconstruct text instances. finally, simple region growth algorithms are adopted to aggregate probability maps to complete text instances. experimental results demonstrate that our method achieves state-of-the-art performance in terms of detection accuracy on several benchmarks. notably, our method with watershed algorithm as post-processing achieves the best f-measure on total-text (88.79%), ctw1500 (85.75%), and msra-td500 (88.93%). besides, our method achieves promising performance on multi-oriented datasets (icdar2015) and multilingual datasets (icdar2017-mlt). code is available at: https://github.com/gxym/textpms.",AB_0368
"deep learning algorithms face great challenges with long-tailed data distribution which, however, is quite a common case in real-world scenarios. previous methods tackle the problem from either the aspect of input space (re-sampling classes with different frequencies) or loss space (re-weighting classes with different weights), suffering from heavy over-fitting to tail classes or hard optimization during training. to alleviate these issues, we propose a more fundamental perspective for long-tailed recognition, i.e., from the aspect of parameter space, and aims to preserve specific capacity for classes with low frequencies. from this perspective, the trivial solution utilizes different branches for the head, medium, tail classes respectively, and then sums their outputs as the final results is not feasible. instead, we design the effective residual fusion mechanism - with one main branch optimized to recognize images from all classes, another two residual branches are gradually fused and optimized to enhance images from medium+tail classes and tail classes respectively. then the branches are aggregated into final results by additive shortcuts. we test our method on several benchmarks, i.e., long-tailed version of cifar-10, cifar-100, places, imagenet, and inaturalist 2018. experimental results manifest the effectiveness of our method. our code is available at https://github.com/jiequancui/reslt.",AB_0368

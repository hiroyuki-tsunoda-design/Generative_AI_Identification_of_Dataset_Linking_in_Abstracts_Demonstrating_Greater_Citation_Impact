AB,NO
"feature extractor plays a critical role in text recognition (tr), but customizing its architecture is relatively less explored due to expensive manual tweaking. in this article, inspired by the success of neural architecture search (nas), we propose to search for suitable feature extractors. we design a domain-specific search space by exploring principles for having good feature extractors. the space includes a 3d-structured space for the spatial model and a transformed-based space for the sequential model. as the space is huge and complexly structured, no existing nas algorithms can be applied. we propose a two-stage algorithm to effectively search in the space. in the first stage, we cut the space into several blocks and progressively train each block with the help of an auxiliary head. we introduce the latency constrain into the second stage and search sub-network from the trained supernet via natural gradient descent. in experiments, a series of ablation studies are performed to better understand the designed space, search algorithm, and searched architectures. we also compare the proposed method with various state-of-the-art ones on both hand-written and scene tr tasks. extensive results show that our approach can achieve better recognition performance with less latency. code is avaliable at https://github.com/automl-research/trefe",AB_0360
"weakly supervised semantic segmentation (wsss) trains segmentation models by only weak labels, aiming to save the burden of expensive pixel-level annotations. this paper tackles the wsss problem of utilizing image-level labels as the weak supervision. previous approaches address this problem by focusing on generating better pseudo-masks from weak labels to train the segmentation model. however, they generally only consider every single image and overlook the potential cross-image contexts. we emphasize that the cross-image contexts among a group of images can provide complementary information for each other to obtain better pseudo-masks. to effectively employ cross-image contexts, we develop an end-to-end cross-image context module containing a memory bank mechanism and a transformer-based cross-image attention module. the former extracts cross-image contexts online from the feature encodings of input images and stores them as the memory. the latter mines useful information from the memorized contexts to provide the original queries with additional information for better pseudo-mask generation. we conduct detailed experiments on the pascal voc 2012 and the coco dataset to demonstrate the advantage of utilizing cross-image contexts. besides, state-of-the-art performance is also achieved. codes are available at https://github.com/js-fan/mcic.git.",AB_0360
"in this paper, we consider the challenging task of simultaneously locating and recovering multiple hands from a single 2d image. previous studies either focus on single hand reconstruction or solve this problem in a multi-stage way. moreover, the conventional two-stage pipeline firstly detects hand areas, and then estimates 3d hand pose from each cropped patch. to reduce the computational redundancy in preprocessing and feature extraction, for the first time, we propose a concise but efficient single-stage pipeline for multi -hand reconstruction. specifically, we design a multi-head auto-encoder structure, where each head network shares the same feature map and outputs the hand center, pose and texture, respectively. besides, we adopt a weakly-supervised scheme to alleviate the burden of expensive 3d real-world data annotations. to this end, we propose a series of losses optimized by a stage-wise training scheme, where a multi-hand dataset with 2d annotations is generated based on the publicly available single hand datasets. in order to further improve the accuracy of the weakly supervised model, we adopt several feature consistency constraints in both single and multiple hand settings. specifically, the keypoints of each hand estimated from local features should be consistent with the re-projected points predicted from global features. extensive experiments on public benchmarks including freihand, ho3d, interhand2.6m and rhd demonstrate that our method outperforms the state-of-the-art model-based methods in both weakly-supervised and fully-supervised manners. the code and models are available at https://github.com/zijinxuxu/smhr.",AB_0360
"dental caries segmentation based on oral panoramic medical images is a demanding medical task. however, it is challenging to determine imaging diagnosis results as the actual pathological changes under certain conditions, especially in the suspected pathological locations that distinguish the artifacts from the lesions. this paper proposes introducing the semi-supervised learning framework to redistribute the collected cases to set up exact lesion areas and divide suspected areas with uncertainties into unlabeled data instead of reducing dataset labeling costs. consistent regularization learning allows us to exploit the feature of ambiguous lesions to optimize decision boundaries. unfortunately, the labels generated by the general ssl method for fuzzy regions are volatile, especially encountering no specific morphological rules and various scales that fluctuate more seriously, making a devastating impact on the regularization training relying on steady prediction. for such a challenge, we consider places that always form stable predictions under various disorders are often highly deterministic. therefore, we propose introducing multi-level disturbances, including noise, iterative, and multi-scale disturbances. we simultaneously present in-depth supervision training on the multi-layer decoder to form stable and consistent multi-scale intermediate predictions, which significantly enrich the number of samples gathered in the following integration process. then, monte carlo sampling is applied to integrate multi-level prediction results to assemble a more robust uncertainty mask map, which gradually clarifies the inter-class feature representation of actual lesions and artifacts. the extended experiment shows that we have successfully and effectively improved the performance of the caries segmentation task by using such uncertain lesion sample features. the dataset is now public, and the code is available at https://github.com/zzz512/mlua. (c) 2023 elsevier b.v. all rights reserved.",AB_0360
"due to the different photosensitive properties of infrared and visible light, infrared and visible light images have individual features. however, since the registered rgb-t image pairs shot in the same scene, they also contain common features. this paper proposes a siamese infrared and visible light fusion network (siamivfn) for rbg-t image-based tracking. siamivfn contains two main subnetworks: a complementary-feature-fusion network (cffn) and a contribution-aggregation network (can). cffn utilizes a two-stream multilayer convolutional structure that separately extracts individual features, and filters in each layer are partially coupled to extract common features. cffn is a feature-level fusion network, which can cope with the misalignment of the rgb-t image pairs. through adaptively calculating the contributions of infrared and visible light features obtained from cffn, can makes the tracker robust under various light conditions. experiments show that compared to state-of-the-art techniques, siamivfn improves the pr/sr score with 1.5%/8.8% on rgbt234 and 2.1%/6.9% on gtot. the tracking speed of siamivfn is 147.6fps, the current fastest rgb-t fusion tracker. the source codes are available at https://github.com/pengjingchao/siamivfn.",AB_0360
"affinity graph-based segmentation methods have become a major trend in computer vision. the perfor-mance of these methods rely on the constructed affinity graph, with particular emphasis on the neigh-borhood topology and pairwise affinities among superpixels. however, these graph-based methods ignore the noisy data from images, that influence the accuracy of pairwise similarities. multiscale combinato-rial grouping and graph fusion also generate a higher computational complexity. in this paper, we pro-pose an adaptive fusion affinity graph with noise-free low-rank representation in an online manner for natural image segmentation. an input image is first over-segmented into superpixels at different scales and then filtered by an improved kernel density estimation method. moreover, we select global nodes of these superpixels on the basis of their subspace-preserving presentation, which reveals the feature distribution of superpixels exactly. to reduce time complexity while improving performance, a sparse representation of global nodes based on noise-free online low-rank representation is used to obtain a global graph at each scale. experimental results on bsd30 0, bsd50 0, msrc, sbd, and pascal voc show the effectiveness of our method in comparison with the state-of-the-art approaches. the code is available at https://github.com/yangzhangcst/afa-graph .(c) 2023 elsevier ltd. all rights reserved.",AB_0360
"few-shot classification aims to learn a classifier that categorizes objects of unseen classes with limited samples. one general approach is to mine as much information as possible from limited samples. this can be achieved by incorporating data from multiple modalities. however, existing multi-modality methods only use additional modality in support samples while adhering to a single modal in query samples. such approach could lead to information imbalance between support and query samples, which confounds model generalization from support to query samples. towards this problem, we propose a task-adaptive semantic feature learning mechanism to incorporate semantic features for both support and query samples. the semantic feature learner is trained episodic-wisely by regressing from the feature vectors of the support samples. it is utilized to predict semantic features for the query samples. such method maintains a consistent training scheme between support and query samples and enables direct model transfer from support to query data, which significantly improves model generalization. we conduct extensive experiments on four benchmarks in both inductive and transductive settings. results show that the proposed tasnet outperforms state-of-the-art methods with an improvement of 1% to 5% in classification accuracy, demonstrating the superiority of our method. the exhaustive ablation studies further validate the effectiveness of our framework. the code is available at: https://github.com/pmhdl/tasnet (c) 2023 elsevier ltd. all rights reserved.",AB_0360
"although convolution neural networks (cnns) have made substantial progress in the low-light image en-hancement task, one critical problem of cnns is the paradox of model complexity and performance. this paper presents a novel surroundnet that only involves less than 150 k parameters (about 80-98 percent size reduction compared to sotas) and achieves very competitive performance. the proposed network comprises several adaptive retinex blocks (arblock), which can be viewed as a novel extension of single scale retinex in feature space. the core of our arblock is an efficient illumination estimation function called adaptive surround function (asf). it can be regarded as a general form of surround functions and be implemented by convolution layers. in addition, we also introduce a low-exposure denoiser (led) to smooth the low-light image before the enhancement. we evaluate the proposed method on two real -world low-light datasets. experimental results demonstrate the superiority of our submitted surround -net in both performance and network parameters against state-of-the-art low-light image enhancement methods. the code is available at https://github.com/ouc- ocean- group/surroundnet .(c) 2023 elsevier ltd. all rights reserved.",AB_0360
"it has been difficult to achieve a suitable balance between effectiveness and efficiency in lightweight semantic segmentation networks in recent years. the goal of this work is to present an efficient and reliable semantic segmentation method called ebunet, which is aimed at achieving a favorable trade-off between inference speed and prediction accuracy. initially, we develop an efficient bottleneck unit (ebu) that employs depth-wise convolution and depth-wise dilated convolution to obtain adequate features with moderate computation costs. then, we developed a novel image partition attention module (ipam), which divides feature maps into subregions and generates attention weights based on them. as a third step, we developed a novel lightweight attention decoder with which to retrieve spatial information effectively. extensive experiments show that our ebunet achieves 73.4% miou and 152 fps on the cityscapes dataset and 72.2% miou and 147 fps on the camvid dataset with only 1.57 m parameters. the results of the experiment confirm that the proposed model is capable of making a decent trade-off in terms of accuracy, inference, and model size. the source code of our ebunet is available at (https://github.com/skybird1101/ebunet).",AB_0360
"session-based recommendation (sbr) emphasizes mining user interests to predict the next click based on recent interactions within sessions. most current sbr methods suffer from insufficient interactive information problems and fail to distinguish session representations with high similarities, which can neglect the inherent features within sessions. to fill the gap, we propose a triplet mining enhanced graph neural networks (tme-gnn) approach to enhance the recommendation systems by mining structural and inherent information. technically, we first generate anchor, positive and negative embeddings based on the given session and set a triplet mining task to improve the recommendation task with subtle features by pushing positive pairs close and pulling negative pairs away. second, to robust the model, we employ a self-supervised auxiliary task by adding dynamic perturbations to the embedding space. we conduct extensive experiments to demonstrate the superiority of our method against other state-of-the-art algorithms. our implementations are available on the following site https://github.com/info4rec/tme-gnn.",AB_0360

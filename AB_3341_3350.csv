AB,NO
"multi-head self-attention (msa) endows vision transformers (vits) with the ability of modeling long-range interactions between tokens. however, recent works have uncovered that current arbitrary attention makes tokens distracted by extraneous dependencies, complicating the understanding of vits and hindering the overall optimization of vits. in this paper, we propose constituent attention (ca), a straightforward yet effective constraint on msa to resolve aforementioned issues in different variants of vits with negligible overhead. specifically, ca is designed to encourage the mutual attention between spatially connectable tokens via gathering such token pairs to the same group (termed constituent). furthermore, with the layers going deeper in vits, small adjacent constituents are gradually merged into larger ones, exploring hierarchical structures in the visual objectives. extensive experiments on four popular benchmarks demonstrate that ca assists the optimization of vits and contributes to significant performance gains especially at data -scarce scenarios. moreover, the layer-wise reasoning mechanism aids vits in more consistent and progressive attention across different layers, rendering the inner workings easier to interpret. our code is publicly available at https://github.com/zju-vipa/constituentattention.",AB_0335
"multivariate time series forecasting is an important issue in industries, agriculture, finance, and other applications. there are many challenging problems in it such as non-linear and complicated relationships among the series. the entanglement of latent multiple different sequence patterns maybe one of the most reasons for the time series complex behavior, and decomposition can help reveal the hidden evolution law. graph is a good modelling tool for multiple entities and graph neural network has showed better learning ability for spatial dependence, but its high memory consumption requires valid solutions. inspired by the above two points, we propose a temporal decomposition enhanced graph neural network for multivariate time series forecasting, namely tdg4msf, which mainly consists of four components: temporal decomposition enhanced representation learning, graph structure learning, gated gnnml-based representation learning and mlp-based forecasting. a progressive quadratic decomposition architecture is designed in the temporal decomposition enhanced representation learning that extracts the different periodic patterns of time series. graph structure learning is used to construct adjacency matrix to represent the spatial topological structure. the temporal decomposition enhanced representation and adjacency matrix are fed into gated gnnml to integrating temporal and spatial information between variables. a mlp-based forecasting is utilized to make multivariate time series prediction. experimental results show the effectiveness of our model in short- and medium-term prediction scenarios are superior to the state-of-the-art methods, which help make exact decisions timely. code is available at: https://github.com/tyut-theta/mhzn.git.",AB_0335
"zero-shot neural architecture search has garnered attention due to its training-free nature and rapid search speed. however, existing zero-shot estimators commonly suffer from low consistency, which hampers their practicality. in this work, we theoretically analyze that network generalization and convergence are highly correlated with sweet gradient of parameter, i.e., the number of parameters whose gradient absolute values are within a certain interval. empirical results indicate that sweet gradient of parameter brings a higher consistency than the overall number of parameters. additionally, we demonstrate a positive correlation between the network depth and the proportion of parameters with sweet gradients in each layer. based on the analysis, we propose a training-free method to find the sweet gradient interval and obtain an estimator, named sweetimator. furthermore, sweet gradient can be an effective and general approach to promote the consistency of zero-shot estimators. experiments show that sweetimator and sweet-enhanced estimators have significant consistency improvement in multiple benchmarks. our method achieves state-of-the-art performance with 256x speedup in nas-bench-201 and maintains high competitiveness in darts, mobilenet, and transformer search spaces. the source code is available at https://github.com/xingxing-123/sweetgradient.",AB_0335
"convolutional neural networks(cnn), especially u-shaped networks, have become the mainstream approach for medical image segmentation. however, due to the intrinsic locality of convolutional operations, cnn has inherent limitations in capturing long-range dependencies. although transformer-based methods have demonstrated remarkable performance in computer vision by modeling long-range dependencies, their high computational complexity and reliance on large-scale pre-training present challenges, particularly for higher-resolution medical images. in this paper, we introduce maxformer, a u-shaped hierarchical network that effectively leverages global context within individual samples and relationships between different samples. our transformer module reformulates the self-attention mechanism into two parts: local-global attention and external attention. the local-global attention provides an efficient alternative to self-attention with linear complexity, employing a parallel architecture that allows local-global spatial interactions. the local attention branch captures high-frequency local information, while the global attention branch captures low-frequency global information. furthermore, we have designed the refined fused connection module to effectively merge feature outputs from each encoder block with the decoder output, mitigating spatial detail loss due to downsampling. extensive experiments on two different medical image segmentation datasets show that our proposed method outperforms other state-of-the-art methods without requiring pre-training weights. code will be available at https://github.com/zhiwei-liang/maxformer.",AB_0335
"convolutional neural networks (cnns) have always been the dominant method for scene sketch semantic segmentation, but their performance seems to have plateaued due to the limitation of local receptive fields. to address this problem, we propose sketchseger, a hierarchical transformer-based model for scene sketch semantic segmentation. accurate scene sketch segmentation relies on both high-level semantics and low-level details. to obtain better segmentation performance, we designed an mlp-based feature fusion module for the model decoder to merge feature maps captured at different scales efficiently. compared to cnn-based models, sketchseger exhibits a stronger ability in contextual modeling and can obtain global receptive fields even in its shallow layers. besides the model architecture, the absence of large-scale pre-training datasets also presents a significant challenge for advancing scene sketch semantic segmentation. to promote further research, we propose a novel hand-drawn style scene sketch synthesis method and use it to synthesize a dataset containing 300,000 annotated scene sketches. we conduct extensive experiments and visual analysis to validate the efficacy of our proposed sketchseger model and dataset synthesis approach. the results show that sketchseger significantly outperforms state-of-the-art models on three benchmark datasets (sketchyscene, sky-scene, and tub-scene) with similar parameter scales. codes and datasets are available at https://github.com/jayangcs/sketchseger. (c) 2023 elsevier b.v. all rights reserved.",AB_0335
"capsule networks (capsnets) are new neural networks that classify images based on the spatial relationships of features. by analyzing the pose of features and their relative positions, it is more capable of recognizing images after affine transformation. the stacked capsule autoencoder (scae) is a state-of-the-art capsnet that achieved unsupervised classification of capsnets for the first time. however, the security vulnerabilities and the robustness of the scae have rarely been explored. in this paper, we propose an evasion attack against scae, where the attacker can generate adversarial perturbations by reducing the contribution of the object capsules related to the original category of the image in the scae. adversarial perturbations are then applied to the original images, and the perturbed images are misclassified with a high probability. for such an evasion attack, we further propose a defense method called hybrid adversarial training (hat), which makes use of adversarial training and adversarial distillation to achieve better robustness of scae against the evasion attack. we evaluate the defense method and the experimental results show that the scae trained with hat ensures that the model can maintain relatively high classification accuracy under the evasion attack and achieve similar classification accuracy to that of the original scae model on clean samples. the source code is available at https://github.com/frostbitexsw/scae_defense.",AB_0335
"accurate and robust correspondence matching is of utmost importance for various 3d computer vision tasks. however, traditional explicit programming-based methods often struggle to handle challenging scenarios, and deep learning-based methods require large well-labeled datasets for network training. in this article, we introduce epipolar-constrained cascade correspondence (e3cm), a novel approach that addresses these limitations. unlike traditional methods, e3cm leverages pre-trained convolutional neural networks to match correspondence, without requiring annotated data for any network training or fine-tuning. our method utilizes epipolar constraints to guide the matching process and incorporates a cascade structure for progressive refine-ment of matches. we extensively evaluate the performance of e3cm through comprehensive experiments and demonstrate its superiority over existing methods. to promote further research and facilitate reproducibility, we make our source code publicly available at https://mias.group/e3cm/.",AB_0335
"most of the cutting-edge 3d convolutional-based video saliency prediction models adopt a fully convolutional encoder-decoder architecture, which provides a good spatiotemporal representation of salient regions. however, the spatiotemporal cues of the saliency models will be continuously diluted during the decoding process, leading to a decreased ability to locate salient regions. to address this limitation, we propose a simple and effective gated fusion network (gfnet) to conduct video saliency prediction. specifically, gfnet is built on a fully 3d convolutional encoder-decoder architecture and consists of a key component named the gated fusion (gf) module, which acts as a message screening unit between each level encoder and decoder features. in the gf module, the gate can be obtained via the combination of features from the previous decoder block and the current encoder block, which is employed to weight the encoder features. in this way, gfnet can control the message passing between each level encoder and decoder block. extensive experimental results on four video saliency datasets show that our method achieves comparable performance against state-of-the-art models. the code is available at https://github.com/wusonghe/gfnet.",AB_0335
"multi-label data classification has received much attention due to its wide range of application domains. unfortunately, a class imbalance problem often occurs in multi-label datasets, causing challenges for classification algorithms. oversampling is one of the most important approaches, as it generates minority label instances to balance the class distribution. however, existing oversampling methods ignore existing label correlations, resulting in the generation of inappropriate synthetic minority samples and making multi-label data classification tasks harder. in this work, we propose an oversampling method that considers label correlations and identifies two critical boundary regions for generating synthetic minority samples. moreover, we propose a weighting strategy to assign weights to these instances based on their distance information. to evaluate the performance of our proposed method, we conducted experiments on sixteen public datasets. the results show that our approach outperforms the state-of-the-art approaches in terms of various assessment metrics, such as macro f1 and macro auc. the code is available at https://github.com/intellidal/multi-label/tree/main/lcos. (c) 2023 elsevier b.v. all rights reserved.",AB_0335
"graph contrastive learning aims to learn informative and discriminative node representations for downstream tasks by maximizing the mutual information between representations of different augmentation views of the same node. however, according to the multi-view information bottleneck principle, redundant information in learned representations can negatively impact the performance of downstream tasks. to avoid this issue, we propose adversarial cluster-level and global-level graph contrastive learning (acg-gcl) for learning minimal sufficient node representations. acg-gcl is optimized alternately under an adversarial learning framework with a min-max objective. at the min step, acg-gcl eliminates redundant information in both the graph structure and feature content of nodes while producing a new graph that provides multi-view information. at the max step, acg-gcl seeks to preserve shared task-relevant information in the learned representation by maximizing the mutual information of node-cluster level and node-global level representations. we demonstrate the effectiveness of the proposed method on the tasks of node classification and node clustering tasks. code is available at https://github.com/tangq123/acg-gcl.(c) 2023 elsevier b.v. all rights reserved.",AB_0335

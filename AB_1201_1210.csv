AB,NO
"haze in hyperspectral images (hsis) can lead to crosstalk between multiple bands, resulting in errors that can be amplified and transmitted during data processing. as a consequence, this may cause a reduction in the accuracy and precision of remote sensing data. the purpose of haze removal is to restore high-quality hsis from degraded ones. the high spectral resolution and typically dozens to hundreds of spectral bands in hsis pose significant challenges for haze removal. thus, many methods designed for natural and multispectral images are not effective in removing haze in hsis. to address this challenge, we develop a model called asymmetric attention convolution network (aacnet) designed for haze removal in hsis. specifically, the basic architecture of aacnet is mainly composed of several residual asymmetric attention groups (raags), where the core components are residual asymmetric attention blocks (raabs). this design enables the full utilization of deep spatial-spectral features while skipping low-frequency regions and focusing more on the haze-affected areas. to more accurately restore the spectral information in areas polluted by haze, a pooling channel self-attention (pcsa) module has been proposed. this module can effectively reconstruct the spectral response curve that is affected by the haze. our experiments on both simulated and real datasets demonstrate that the proposed aacnet outperforms several leading haze removal methods in both precision and visual quality. the source code and data of this article will be made publicly available at https://github.com/szu710/aacnet for reproducible research.",AB_0121
"scene-text image synthesis techniques that aim to naturally compose text instances on background scene images are very appealing for training deep neural networks due to their ability to provide accurate and comprehensive annotation information. prior studies have explored generating synthetic text images on two-dimensional and three-dimensional surfaces using rules derived from real-world observations. some of these studies have proposed generating scene-text images through learning; however, owing to the absence of a suitable training dataset, unsupervised frameworks have been explored to learn from existing real-world data, which might not yield reliable performance. to ease this dilemma and facilitate research on learning-based scene text synthesis, we introduce decompst, a real-world dataset prepared from some public benchmarks, containing three types of annotations: quadrilateral-level bboxes, stroke-level text masks, and text-erased images. leveraging the decompst dataset, we propose a learning-based text synthesis engine (lbts) that includes a text location proposal network (tlpnet) and a text appearance adaptation network (taanet). tlpnet first predicts the suitable regions for text embedding, after which taanet adaptively adjusts the geometry and color of the text instance to match the background context. after training, those networks can be integrated and utilized to generate the synthetic dataset for scene text analysis tasks. comprehensive experiments were conducted to validate the effectiveness of the proposed lbts along with existing methods, and the experimental results indicate the proposed lbts can generate better pretraining data for scene text detectors. our dataset and code are made available at: https://github.com/iiclab/decompst.",AB_0121
"fire is one of the worst disasters for human life. fire can happen anywhere and the leading cause can be natural or man. over the last century, scientists have invented sensor-based methods to minimize damage and provide early warning of fires. however, these applications are only applied in a limited space and distance. for the purpose of fire remote warning and deploying on low-computing devices, this paper proposes a vision-based method using a lightweight convolutional neural network architecture combined with the inception and attention mechanisms. this proposed network includes two main modules: a feature extractor and a classifier. the feature extractor exploits convolution layers, depthwise separable convolution layers, inception module, and attention mechanism to extract high-level feature maps. next, the classifier applies the global average pooling layer to quickly reduce the feature map dimensions and uses the softmax function to calculate the probability of each class. the experiments performed the training and evaluation on six datasets with an accuracy of over 96%. the fire surveillance system was implemented with simulation videos on gpu, cpu, and jetson nano devices, with the highest speeds of 200.95 fps, 31.08 fps, and 14.27 fps, respectively. a set of demonstration videos, source code, and proposed dataset are provided here: https://bit.ly/3wlpycf.",AB_0121
"we propose a weakly supervised approach for salient object detection from multi-modal rgb-d data. our approach only relies on labels from scribbles, which are much easier to annotate, compared with dense labels used in conventional fully supervised setting. in contrast to existing methods that employ supervision signals on the output space, our design regularizes the intermediate latent space to enhance discrimination between salient and non-salient objects. we further introduce a contour detection branch to implicitly constrain the semantic boundaries and achieve precise edges of detected salient objects. to enhance the long-range dependencies among local features, we introduce a cross-padding attention block (cpab). extensive experiments on seven benchmark datasets demonstrate that our method not only outperforms existing weakly supervised methods, but is also on par with several fully-supervised state-of-the-art models. code is available at https://github.com/leolyj/dhfr-sod.",AB_0121
"defi, a decentralized financial service based on blockchain, not only provides innovative financial services, but also poses various risks, such as the terra luna crash. therefore, anomaly detection in defi is necessary to ensure the safety and reliability of the defi ecosystem. however, this is very difficult because of the complex protocol, interaction among smart contracts, and high market volatility. in this study, we propose a novel method to effectively detect anomalies in defi. to the best of our knowledge, this is the first study that utilizes deep learning to detect anomalies in defi. we propose a deep learning model, anomaly vae-transformer, which combines the variational autoencoder to extract local information in the short term, and the transformer, to identify dependencies between data in the long term. based on a deep understanding of defi protocols, the proposed model collects and analyzes various on-chain data of olympus dao, a representative defi protocol, for extracting features suitable for anomaly detection. then, we demonstrate the superiority of the proposed model by analyzing four anomaly cases detected successfully by the proposed model in olympus dao. a malicious attack attempt and structural changes in defi protocols can be identified quickly using the proposed method; this is expected to help protect the assets of defi users and improve the safety, reliability, and transparency of the defi market. the dataset and codes are available at https://github.com/fialle/anomaly-vae-transformer",AB_0121
"despite the remarkable progress made by the salient object detection of natural sensing images (nsi-sod), the complex background and scale diversity issues of remote sensing images (rsis) still pose a substantial obstacle. in this study, we build an end-to-end channel-enhanced remodeling-based network (crnet) for optical rsis (orsis) to highlight salient objects through feature augmentation. first, the backbone convolutional block is used to suggest the fundamental characteristics. then, we use the channel enhance module (cem) to enhance the shallow features. cem primarily relies on the channel attention (ca) mechanism and uses a no-downscaling strategy to produce local cross-channel interaction, which lowers model complexity while enhancing extraction performance. meanwhile, we use the redefined feature module (rfm) to reconstruct the deep features and generate global attention features by dimensional transformation and feature relationship aggregation to achieve the role of locating salient targets. finally, the cascade combines the multiscale features to provide the final saliency map. to further enhance the representational power of the network, we use a hybrid loss function to improve performance. the proposed approach outperforms current state-of-the-art (sota) methods, as shown by several experiments on three available datasets. the source code of the proposed crnet is available publicly at https://github.com/hilitteq/crnet.git.",AB_0121
"north china was a key centre of middle ordovician stromatoporoid diversification. however, detailed studies of the subsequent late ordovician stromatoporoid development in this terrane are lacking; thus, the spatiotemporal development of north chinese stromatoporoids is poorly understood. the beiguoshan formation (middle katian age, late ordovician) contains the youngest ordovician stromatoporoids in north china, comprising a unique stromatoporoid fauna, consisting of 12 species across 10 genera and three orders of traditional taxonomic groupings: labechiids rosenella woyuense ozaki, 1938, pseudostylodictyon poshanense ozaki, 1938, pseudostylodictyon chunhuaensis (jiang et al., 2011), labechia sp., labechiella gondwanense jeon in jeon, liang, kershaw, park, and zhang, 2022, labechiella regularis (yabe & sugiyama, 1930a); clathrodictyids clathrodictyon sp. cf. cl. mammillatum (schmidt, 1858), camptodictyon amzassensis (khalfina, 1960), ecclimadictyon tiewadianensis (jiang et al., 2011), plexodictyon xibeiense jeon sp. nov., petriterastroma exililamellatum jeon and kershaw gen. et sp. nov.; and the stromatoporellid simplexodictyon conspicus jeon and kershaw sp. nov. this assemblage is distinguished by: (1) succeeding darriwilian species of north china, (2) few peri-gondwanan species, and (3) stromatoporoid genera common in siluro-devonian assemblages. plexodictyon and simplexodictyon species (commonly found in middle palaeozoic rocks) are here recorded in the ordovician for the first time. their stratigraphical occurrence in the middle katian reveals an interval of absences before their faunal development in the middle silurian, a stratigraphical gap caused by the huaiyuan epeirogeny, which largely shaped and controlled the regional stratigraphy of north china. this unique assemblage of katian stromatoporoids is not known from other contemporary terranes, supporting the interpretation that north china was separated from the north-eastern peri-gondwanan regions, thus constituting an independent palaeobiogeographical unit during the late ordovician. early occurrence of these common siluro-devonian-type stromatoporoids indicates a prologue of the ordovician-silurian stromatoporoid faunal transition in north china, characterized by a decrease in labechiids and rapid diversification of clathrodictyids and related stromatoporoids of typical silurian types.http://zoobank.org/urn:lsid:zoobank.org:pub:e8e8c006-d15d-490c-86b8-469e6f02a5a1",AB_0121
"palmprint has gained popularity as a biometric modality and has recently attracted significant research interest. the competition-based method is the prevailing approach for hand-crafted palmprint recognition, thanks to its powerful discriminative ability to identify distinctive features. however, the competition mechanism possesses vast untapped advantages that have yet to be fully explored. in this paper, we reformulate the traditional competition mechanism and propose a comprehensive competition network (ccnet). the traditional competition mechanism focuses solely on selecting the winner of different channels without considering the spatial information of the features. our approach considers the spatial competition relationships between features while utilizing channel competition features to extract a more comprehensive set of competitive features. moreover, existing methods for palmprint recognition typically focus on first-order texture features without utilizing the higher-order texture feature information. our approach integrates the competition process with multi-order texture features to overcome this limitation. ccnet incorporates spatial and channel competition mechanisms into multi-order texture features to enhance recognition accuracy, enabling it to capture and utilize palmprint information in an end-to-end manner efficiently. extensive experimental results have shown that ccnet can achieve remarkable performance on four public datasets, showing that ccnet is a promising approach for palmprint recognition that can achieve state-of-the-art performance. related codes will be released at https://github.com/zi-yuanyang/ccnet.",AB_0121
"hyperspectral images (hsis) are prone to noise because of the imaging mechanism and environment. this article proposes a multitask sparse representation (mtsr) model-inspired neural network for hsi denoising. unlike other deep learning (dl)-based methods, our network is interpretable, whose network architecture is induced by unfolding the iterative optimization of an mtsr model. on one hand, the model globally represents the common structure among bands, such as image edges, with the shared sparse coefficients. on the other hand, it separately encodes the unique structure of individual bands with unshared ones to capture image details. accordingly, our network has three modules: the shared sparse representation (ssr) module, the unshared sparse representation (usr), and the image reconstruction (ir) module. all the modules are connected with a specific operation of the iterative optimization algorithm, equipping the network with clear physical interpretation. experimental results on both the synthetic and real-world datasets demonstrate the superior performance of our method, visually and quantitatively. the codes will be publicly available at https://github.com/bearshng/mtsrnn for reproducible research.",AB_0121
"oriented object detection has made astonishing progress. however, existing methods neglect to address the issue of false positives caused by the background or nearby clutter objects. meanwhile, class imbalance and boundary overflow issues caused by the predicting rotation angles may affect the accuracy of rotated bounding box predictions. to address the above issues, we propose a single-stage rotate object detector via dense prediction and false positive suppression (srdf). specifically, we design an instance-level false positive suppression module (ifpsm), ifpsm acquires the weight information of target and nontarget regions by supervised learning of spatial feature encoding, and applies these weight values to the deep feature map, thereby attenuating the response signals of nontarget regions within the deep feature map. compared to commonly used attention mechanisms, this approach more accurately suppresses false-positive regions. then, we introduce a hybrid classification and regression method to represent the object orientation, the proposed method divide the angle into two segments for prediction, reducing the number of categories and narrowing the range of regression. this alleviates the issue of class imbalance caused by treating one degree as a single category in classification prediction, as well as the problem of boundary overflow caused by directly regressing the angle. in addition, we transform the traditional post-processing steps based on matching and searching to a 2-d probability distribution mathematical model, which accurately and quickly extracts the bounding boxes from dense prediction results. extensive experiments on remote sensing, synthetic aperture radar (sar), and scene text benchmarks demonstrate the superiority of the proposed srdf method over state-of-the-art (sota) rotated object detection methods. our codes are available at https://github.com/tomzandjerryz/srdf.",AB_0121

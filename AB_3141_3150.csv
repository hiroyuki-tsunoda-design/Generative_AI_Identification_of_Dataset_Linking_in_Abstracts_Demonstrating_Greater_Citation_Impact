AB,NO
"soybean (glycine max (l.) merr.) is a globally significant crop, widely cultivated for oilseed production and animal feeds. in recent years, the rapid growth of multi-omics data from thousands of soybean accessions has provided unprecedented opportunities for researchers to explore genomes, genetic variations, and gene functions. to facilitate the utilization of these abundant data for soybean breeding and genetic improvement, the soybeangdb database (https://venyao.xyz/soybeangdb/) was developed as a comprehensive platform. soybeangdb integrates high-quality de novo assemblies of 39 soybean genomes and genomic variations among thousands of soybean accessions. genomic information and variations in user-specified genomic regions can be searched and downloaded from soybeangdb, in a user-friendly manner. to facilitate research on genetic resources and elucidate the biological significance of genes, soybeangdb also incorporates a variety of bioinformatics analysis modules with graphical interfaces, such as linkage disequilibrium analysis, nucleotide diversity analysis, allele frequency analysis, gene expression analysis, primer design, gene set enrichment analysis, etc. in summary, soybeangdb is an essential and valuable resource that provides an open and free platform to accelerate global soybean research.(c)2023 the authors. published by elsevier b.v. on behalf of research network of computational and structural biotechnology. this is an open access article under the cc by-nc-nd license ().",AB_0315
"single-image rain removal is an extremely challenging task as it requires not only removing rain streaks with complex shapes, scales, and opacities but also recovering spatial details and high-level contextual structures of the underlying image. although deep learning networks have achieved encouraging performance, current research mainly focuses on building deeper and more complex network architectures to recover reliable detailed textures or utilizing multi-scale encoder-decoder structures to learn semantic contexts in larger receptive fields, they are still not sufficient to balance rain streak removal and detail preservation. in this study, we propose a novel end-to-end network, called a dual-task complementary network (dtcn), composed of a detail recovery progressive network (drpn) and a multifeature fusion encoder-decoder network (medn), to balance rain streak removal and detail preservation. specifically, drpn is designed to recover details in the original image, while medn is used to remove structural rain streaks. in addition, to reconstruct more natural and clear images, we integrate multiple network training losses, including structural similarity loss, perceptual contrast loss, perceptual image similarity loss, and edge loss. experimental results demonstrate that our method outperforms several state-of-the-art methods on both synthetic and real rainy images. the code will be uploaded to https://github.com/zhang152267/dtcn.",AB_0315
"sequential recommendation has recently played an important role on various platforms due to its ability to understand users' intentions from their historical interactions. however, modeling user's intention on time-based representations poses challenges, such as fast-evolving interests, noisy interactions, and sparse data. while contrastive self-supervised learning can mitigate these issues, the complexity of time-based interactions limits the utility of understanding the user's intention. motivated by this limitation, we posit that intent representations need to accommodate different domains. to this end, we expect both the frequency-domain augmented view and the time-domain augmented view of the same sample should be maximally consistent with their original input in their corresponding domains. inspired by this idea, we propose contrastive learning with frequency domain for sequential recommendation (clf4srec), where a learnable fourier layer provides the frequency-based self-supervised signal. instead of pre-training, we employ a multi-task learning framework jointly with contrastive learning and recommendation learning to optimize the user representation encoder. we conduct comprehensive experiments on four real-world datasets, where clf4srec outperforms the recent strongest baselines from 7.58% to 67.85%, showing its effectiveness for sequential recommendation tasks. specifically, clf4srec can achieve a boost of 41.88% to 67.85% on the dense dataset, which might be attributed to the ability of frequency domain technology to handle dense signals. the implementation code is available at https://github.com/zhangyichi1z/clf4srec. & copy; 2023 elsevier b.v. all rights reserved.",AB_0315
"backdoor attack which carries out a threat to model training has received increasing attention in recent years. reviewing the previous research on adversarial attacks posing risk at the testing stage while at the same time facilitating the understanding of model predictions, we argue that the backdoor attack also has the potential to probe into the model learning process and help improve model performance. we started by attributing the phenomenon of clean accuracy drop (cad) in backdoor attack as the result of pseudo-deletion to the training data. then an explanation from the perspective of model classification boundary is provided to explain this phenomenon that backdoor attack has advantages over undersampling in the data debiasing problem. based on the above findings, we proposed debiasing backdoor attack (dba), employing backdoor attacks to address the data bias problem. experiments demonstrate the effectiveness of backdoor attacks in debiasing tasks, with the envisioning of a broader range of benign application scenarios. our code for the study can be found at https://github .com /kirinng /dba.",AB_0315
"multivariate time series forecasting (mtsf) has gathered extensive attention in various research areas. many researchers leverage deep neural networks to explore spatial-temporal relationships for mtsf with great success. nevertheless, plentifully available data required by deep neural networks often struggle to satisfy practical scenarios. to overcome this limitation, we exploit the internal structure of deep neural networks to automatically learn sample relationships, aiming to mitigate data scarcity by propagating information among different data samples. consequently, in this paper, we propose a multi-relations aware convolutional attention network, termed mrcan, which integrates spatial-temporal relation learning and sample relation learning, ad hoc for addressing mtsf issues. in mrcan, we propose a novel spatial-temporal attention module for spatial-temporal relationship representation learning. with the proposed batch attention module, we further explore relational modeling among samples in each mini-batch to implicitly enrich the training sample information. in particular, we introduce parameter-sharing regressors located before and after the batch attention module to alleviate the training and testing inconsistency in learning batch invariant representations. extensive experiments on six practical datasets demonstrate that mrcan compares favorably to nine baseline models. larger performance gaps are exhibited, especially on small datasets like the sml2010 dataset. code is publicly available at https://github.com/jzhangna/mrcan.",AB_0315
"the ability of spatial-temporal traffic demand prediction is crucial for urban computing, traffic management and future autonomous driving. in this paper, a novel spatial-temporal guided multi-graph sandwich-transformer (stgmt) is suggested to address the ubiquitous spatial -temporal heterogeneity in traffic demand forecasting. compared to the original transformer, we employ time to vector (time2vec) and node to vector (node2vec) in the embedding layer to obtain universal representations for temporal nodes and spatial nodes, respectively, which are then combined to form spatial-temporal embedding (ste) blocks. the ste guides the attention mechanism, maintaining a unique parameter space for spatial-temporal nodes and enabling the learning of node-specific patterns. in stgmt, we develop multi-head temporal attention (mta) and multi-head temporal interactive attention (mtia) for extracting temporal features, while multi-head spatial attention (msa) is employed for extracting spatial features. furthermore, msa incorporates both the accessibility graph determined by road topology and the similarity graph determined by specific traffic events to characterize the pairwise relationships among spatial nodes. various attentions and feed-forward layers are rearranged and combined to form the sandwich-transformer. extensive experiments are conducted on public datasets of node-level tasks of two different types (highway and urban) and indicate that the stgmt outperforms state-of-the-art models. the proposed stgmt effectively addresses the ubiquitous spatial-temporal heterogeneity challenge in traffic demand forecasting, thereby enhancing the accuracy of traffic demand prediction and offering valuable guidance for traffic planning and operations. our code and data are open source at https://github .com /yanjiewen /stgmt-tensorflow-implementation.",AB_0315
"text adversarial attack is an effective strategy to investigate the vulnerability of natural language processing (nlp) models. most of text attack studies focus on word-level attacks with static or dynamic optimization algorithms. however, they are hard to balance (1) attack performance (i.e., attack success rate, word substitution rate) and (2) attack efficiency. generally, static optimization is fast but suffers from low attack performance, and the dynamic adversary improves the attacking quality but is time-consuming. to address these challenges, a generation-based parallel particle swarm optimization (gp2so) is proposed for the adversarial text attack. specifically, the gp2so employs an adaptive strategy to determine the word modification priority, which produces a high attack performance owing to the aggressive objective function. to achieve time efficiency, we parallelize the pso on multiple pipelines in a generation-overlapping manner. extensive experiments on four public text recognition datasets are conducted by attacking four deep models to evaluate the effectiveness of the gp2so. experimental results manifest that the proposed gp2so averagely improves the time efficiency by 272% with only 0.3% success rate reduction compared to the pso. besides, the gp2so also shows superiorities in adversarial training and transferability compared with baselines. the code is provided to ensure reproducibility https:// github .com /outdoormanofml /gppso.",AB_0315
"knowledge distillation is a technique to enhance the generalization ability of a student model by exploiting outputs from a teacher model. recently, feature-map based variants explore knowledge transfer between manually assigned teacher-student pairs in intermediate layers for further improvement. however, layer semantics may vary in different neural networks, resulting in performance degeneration due to negative regularization from semantic mismatch in manual layer associations. to address this issue, we propose semantic calibration for cross-layer knowledge distillation (semckd), which automatically assigns proper target layers of the teacher model for each student layer with an attention mechanism. with a learned attention distribution, each student layer distills knowledge contained in multiple teacher layers rather than a specific intermediate layer for appropriate cross-layer supervision. we further provide theoretical analysis of the association weights and conduct extensive experiments to demonstrate the effectiveness of our approach. on average, semckd improves the student top-1 classification accuracy by 4.27% across twelve different teacher-student model combinations on cifar-100. code is available at https://github.com/defangchen/semckd.",AB_0315
"this article presents flgc, a simple yet effective fully linear graph convolutional network for semi-supervised and unsupervised learning. instead of using gradient descent, we train flgc based on computing a global optimal closed-form solution with a decoupled procedure, resulting in a generalized linear framework and making it easier to implement, train, and apply. we show that (1) flgc is powerful to deal with both graph-structured data and regular data, (2) training graph convolutional models with closed-form solutions improve computational efficiency without degrading performance, and (3) flgc acts as a natural generalization of classic linear models in the non-euclidean domain (e.g., ridge regression and subspace clustering). furthermore, we implement a semi-supervised flgc and an unsupervised flgc by introducing an initial residual strategy, enabling flgc to aggregate long-range neighborhoods and alleviate over-smoothing. we compare our semi-supervised and unsupervised flgcs against many state-of-the-art methods on a variety of classification and clustering benchmarks, demonstrating that the proposed flgc models consistently outperform previous methods in terms of accuracy, robustness, and learning efficiency. the core code of our flgc is released at https://github.com/angrycai/flgc.",AB_0315
"federated learning allows multiple clients to jointly train a model on their private data without revealing their local data to a centralized server. thereby, federated learning has attracted increasing attention in recent years, and many algorithms have been proposed. however, existing federated learning algorithms often focus on static data, which tend to fail in the scenarios of data streams. due to the varying distributions/concepts within and among the clients over time, the joint learning model must learn these different emerging concepts dynamically and simultaneously. the task becomes more challenging when the continuous arriving data are partially labeled for the participating clients. in this paper, we propose sfleds (semi-supervised federated learning on evolving data streams), a new federated learning prototype-based method to tackle the problems of label scarcity, concept drift, and privacy preservation in the federated semi-supervised evolving data stream environment. extensive experiments show that sfleds outperforms both state-of-the-art semi-supervised and supervised algorithms. the source code for the proposed method is publicly available on github (https://github .com /mvisionai /fedlimited).",AB_0315

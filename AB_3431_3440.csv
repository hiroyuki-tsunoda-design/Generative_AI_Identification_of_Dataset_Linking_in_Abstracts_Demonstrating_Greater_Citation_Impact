AB,NO
"speech disentanglement aims to decompose independent causal factors of speech signals into separate codes. perfect disentanglement benefits to a broad range of speech processing tasks. this paper presents a simple but effective disentanglement approach based on cycle consistency loss and random factor substitution. this leads to a novel random cycle (rc) loss that enforces analysis-and-resynthesis consistency, a main principle of reductionism. we theoretically demonstrate that the proposed rc loss can achieve independent codes if well optimized, which in turn leads to superior disentanglement when combined with information bottleneck (ib). extensive simulation experiments were conducted to understand the properties of the rc loss, and experimental results on voice conversion further demonstrate the practical merit of the proposal. source code and audio samples can be found on the webpage http://rc.cslt.org.",AB_0344
"point cloud completion aims to predict complete shape from its partial observation. current approaches mainly consist of generation and refinement stages in a coarse-to-fine style. however, the generation stage often lacks robustness to tackle different incomplete variations, while the refinement stage blindly recovers point clouds without the semantic awareness. to tackle these challenges, we unify point cloud completion by a generic pretrainprompt-predict paradigm, namely cp3. inspired by prompting approaches from nlp, we creatively reinterpret point cloud generation and refinement as the prompting and predicting stages, respectively. then, we introduce a concise self-supervised pretraining stage before prompting. it can effectively increase robustness of point cloud generation, by an incompletion-of-incompletion (ioi) pretext task. moreover, we develop a novel semantic conditional refinement (scr) network at the predicting stage. it can discriminatively modulate multi-scale refinement with the guidance of semantics. finally, extensive experiments demonstrate that our cp3 outperforms the state-of-the-artmethods with a large margin. code will be available at https://github.com/ mingyexu/cp3.",AB_0344
"super-resolution from a single motion blurred image (srb) is a severely ill-posed problem due to the joint degradation of motion blurs and low spatial resolution. in this article, we employ events to alleviate the burden of srb and propose an event-enhanced srb (e-srb) algorithm, which can generate a sequence of sharp and clear images with high resolution (hr) from a single blurry image with low resolution (lr). to achieve this end, we formulate an event-enhanced degeneration model to consider the low spatial resolution, motion blurs, and event noises simultaneously. we then build an event-enhanced sparse learning network (esl-net++) upon a dual sparse learning scheme where both events and intensity frames are modeled with sparse representations. furthermore, we propose an event shuffle-and-merge scheme to extend the single-frame srb to the sequence-frame srb without any additional training process. experimental results on synthetic and real-world datasets show that the proposed esl-net++ outperforms state-of-the-art methods by a large margin. datasets, codes, and more results are available at https://github.com/shinywang33/esl-net-plusplus.",AB_0344
"both network pruning and neural architecture search (nas) can be interpreted as techniques to automate the design and optimization of artificial neural networks. in this paper, we challenge the conventional wisdom of training before pruning by proposing a joint search-and-training approach to learn a compact network directly from scratch. using pruning as a search strategy, we advocate three new insights for network engineering: 1) to formulate adaptive search as a cold start strategy to find a compact subnetwork on the coarse scale; and 2) to automatically learn the threshold for network pruning; 3) to offer flexibility to choose between efficiency and robustness. more specifically, we propose an adaptive search algorithm in the cold start by exploiting the randomness and flexibility of filter pruning. the weights associated with the network filters will be updated by threshnet, a flexible coarse-to-fine pruning method inspired by reinforcement learning. in addition, we introduce a robust pruning strategy leveraging the technique of knowledge distillation through a teacher-student network. extensive experiments on resnet and vggnet have shown that our proposed method can achieve a better balance in terms of efficiency and accuracy and notable advantages over current state-of-the-art pruning methods in several popular datasets, including cifar10, cifar100, and imagenet. the code associate with this paper is available at: https:// see.xidian.edu.cn/ faculty/ wsdong/ projects/ ast-np.htm.",AB_0344
"global channel pruning (gcp) aims to remove a subset of channels (filters) across different layers from a deep model without hurting the performance. previous works focus on either single task model pruning or simply adapting it to multitask scenario, and still face the following problems when handling multitask pruning: 1) due to the task mismatch, a well-pruned backbone for classification task focuses on preserving filters that can extract category-sensitive information, causing filters that may be useful for other tasks to be pruned during the backbone pruning stage; 2) for multitask predictions, different filters within or between layers are more closely related and interacted than that for single task prediction, making multitask pruning more difficult. therefore, aiming at multitask model compression, we propose a performance-aware global channel pruning (pagcp) framework. we first theoretically present the objective for achieving superior gcp, by considering the joint saliency of filters from intra- and inter-layers. then a sequentially greedy pruning strategy is proposed to optimize the objective, where a performance-aware oracle criterion is developed to evaluate sensitivity of filters to each task and preserve the globally most task-related filters. experiments on several multitask datasets show that the proposed pagcp can reduce the flops and parameters by over 60% with minor performance drop, and achieves 1.2x similar to 3.3x acceleration on both cloud and mobile platforms. our code is available at http://www.github.com/hankye/pagcp.git.",AB_0344
"the teacher-free online knowledge distillation (kd) aims to train an ensemble of multiple student models collaboratively and distill knowledge from each other. although existing online kd methods achieve desirable performance, they often focus on class probabilities as the core knowledge type, ignoring the valuable feature representational information. we present a mutual contrastive learning (mcl) framework for online kd. the core idea ofmclis to perform mutual interaction and transfer of contrastive distributions among a cohort of networks in an online manner. our mcl can aggregate cross-network embedding information and maximize the lower bound to the mutual information between two networks. this enables each network to learn extra contrastive knowledge from others, leading to better feature representations, thus improving the performance of visual recognition tasks. beyond the final layer, we extend mcl to intermediate layers and perform an adaptive layer-matching mechanism trained by meta-optimization. experiments on image classification and transfer learning to visual recognition tasks show that layer-wise mcl can lead to consistent performance gains against state-of-the-art online kd approaches. the superiority demonstrates that layer-wise mcl can guide the network to generate better feature representations. our code is publicly avaliable at https://github.com/winycg/l-mcl.",AB_0344
"we present roreg, a novel point cloud registration framework that fully exploits oriented descriptors and estimated local rotations in the whole registration pipeline. previous methods mainly focus on extracting rotation-invariant descriptors for registration but unanimously neglect the orientations of descriptors. in this paper, we show that the oriented descriptors and the estimated local rotations are very useful in the whole registration pipeline, including feature description, feature detection, feature matching, and transformation estimation. consequently, we design a novel oriented descriptor roreg-desc and apply roreg-desc to estimate the local rotations. such estimated local rotations enable us to develop a rotation-guided detector, a rotation coherence matcher, and a one-shot-estimation ransac, all of which greatly improve the registration performance. extensive experiments demonstrate that roreg achieves state-of-the-art performance on the widely-used 3dmatch and 3dlomatch datasets, and also generalizes well to the outdoor eth dataset. in particular, we also provide in-depth analysis on each component of roreg, validating the improvements brought by oriented descriptors and the estimated local rotations. source code and supplementary material are available at https://github.com/hpwang-whu/roreg.",AB_0344
"previous knowledge distillation (kd) methods for object detection mostly focus on feature imitation instead of mimicking the prediction logits due to its inefficiency in distilling the localization information. in this paper, we investigate whether logit mimicking always lags behind feature imitation. towards this goal, we first present a novel localization distillation (ld) method which can efficiently transfer the localization knowledge from the teacher to the student. second, we introduce the concept of valuable localization region that can aid to selectively distill the classification and localization knowledge for a certain region. combining these two new components, for the first time, we show that logit mimicking can outperform feature imitation and the absence of localization distillation is a critical reason for why logit mimicking under-performs for years. the thorough studies exhibit the great potential of logit mimicking that can significantly alleviate the localization ambiguity, learn robust feature representation, and ease the training difficulty in the early stage. we also provide the theoretical connection between the proposed ld and the classification kd, that they share the equivalent optimization effect. our distillation scheme is simple as well as effective and can be easily applied to both dense horizontal object detectors and rotated object detectors. extensive experiments on the ms coco, pascal voc, and dota benchmarks demonstrate that our method can achieve considerable ap improvement without any sacrifice on the inference speed. our source code and pretrained models are publicly available at https://github.com/hikaritju/ld.",AB_0344
"the mainstream approach for filter pruning is usually either to force a hard-coded importance estimation upon a computation-heavy pretrained model to select important filters, or to impose a hyperparameter-sensitive sparse constraint on the loss objective to regularize the network training. in this paper, we present a novel filter pruning method, dubbed dynamic-coded filter fusion (dcff), to derive compact cnns in a computation-economical and regularization-free manner for efficient image classification. each filter in our dcff is first given an inter-similarity distribution with a temperature parameter as a filter proxy, on top of which, a fresh kullback-leibler divergence based dynamic-coded criterion is proposed to evaluate the filter importance. in contrast to simply keeping high-score filters in other methods, we propose the concept of filter fusion, i.e., the weighted averages using the assigned proxies, as our preserved filters. we obtain a one-hot inter-similarity distribution as the temperature parameter approaches infinity. thus, the relative importance of each filter can vary alongwith the training of the compactcnn, leading to dynamically changeable fused filters without both the dependency on the pretrained model and the introduction of sparse constraints. extensive experiments on classification benchmarks demonstrate the superiority of our dcff over the compared counterparts. for example, our dcff derives a compact vggnet-16 with only 72.77m flops and 1.06m parameters while reaching top-1 accuracy of 93.47% on cifar-10. a compact resnet-50 is obtained with 63.8% flops and 58.6% parameter reductions, retaining 75.60% top-1 accuracy on ilsvrc-2012. our code, narrower models and training logs are available at https://github.com/lmbxmu/dcff.",AB_0344
"deep learning for change detection is one of the current hot topics in the field of remote sensing. however, most end-to-end networks are proposed for supervised change detection, and unsupervised change detection models depend on traditional pre-detection methods. therefore, we proposed a fully convolutional change detection framework with generative adversarial network, to unify unsupervised, weakly supervised, regional supervised, and fully supervised change detection tasks into one end-to-end framework. a basic unet segmentor is used to obtain change detection map, an image-to-image generator is implemented to model the spectral and spatial variation between multi-temporal images, and a discriminator for changed and unchanged is proposed for modeling the semantic changes in weakly and regional supervised change detection task. the iterative optimization of segmentor and generator can build an end-to-end network for unsupervised change detection, the adversarial process between segmentor and discriminator can provide the solutions for weakly and regional supervised change detection, the segmentor itself can be trained for fully supervised task. the experiments indicate the effectiveness of the propsed framework in unsupervised, weakly supervised and regional supervised change detection. this article provides new theorical definitions for unsupervised, weakly supervised and regional supervised change detection tasks with the proposed framework, and shows great potentials in exploring end-to-end network for remote sensing change detection (https://github.com/cwuwhu/fcd-gan-pytorch).",AB_0344

AB,NO
"feature extraction neural networks are essential components of computer vision systems. as the most famous one, resnet has been widely used in engineering. although many modern networks have outperformed resnet, the costly pretraining and hyper-parameter optimization processes prevent their application of them in industrial computer vision systems. to avoid these costly processes, a stage recursive residual network (sreresnet) is proposed, which merely adjusts the forward propagation pipeline without changing the parameter architecture of resnet. thus, it can inherit existing model parameters of resnet and replace resnet through simple fine-tuning. moreover, sreresnet is the first network to improve accuracy by utilizing the semantic trend during feature extraction instead of well-designed modules. it models a series of cascaded modules as a semantic unit and feeds the high-level feature maps back to the low-level modules for further semantic redundancy suppression through one feedback connection within the unit based on the semantic trend and the mechanism of looking and thinking twice. for object detection tasks, a stage recursive feature pyramid network (srefpn) is also proposed to rethink and suppress semantic redundancy further. experiments demonstrate that sreresnet outperforms its counterparts in object detection and image classification tasks. on the ms coco 2017 dataset, sreresnet outperforms resnet with 1.2 box ap improvement, and sreresnet with srefpn further achieves 2.5 box ap improvement without bells and whistles. on the cifar-100 dataset, sreresnet outperforms its counterparts, such as resnet, densenet, and convnext, with at least 2.33% top-1 acc improvement. the code is available at https://github.com/unbelieboomboom/sreresnet.",AB_0156
"objective: to develop the wed-based system for predicting risk of (pre)frailty among community-dwelling older adults.materials and methods: (pre)frailty was determined by physical frailty phenotype scale. a total of 2802 robust older adults aged & ge;60 years from the china health and retirement longitudinal study (charls) 2013-2015 survey were randomly assigned to derivation or internal validation cohort at a ratio of 8:2. logistic regression, random forest, support vector machine and extreme gradient boosting (xgboost) were used to construct (pre) frailty prediction models. the grid search and 5-fold cross validation were combined to find the optimal parameters. all models were evaluated externally using the temporal validation method via the charls 2011-2013 survey. the (pre)frailty predictive system was web-based and built upon representational state transfer application program interfaces.results: the incidence of (pre)frailty was 34.2 % in derivation cohort, 34.8 % in internal validation cohort, and 32.4 % in external validation cohort. the xgboost model achieved better prediction performance in derivation and internal validation cohorts, and all models had similar performance in external validation cohort. for internal validation cohort, xgboost model showed acceptable discrimination (auc: 0.701, 95 % ci: [0.655-0.746]), calibration (p-value of hosmer-lemeshow test > 0.05; good agreement on calibration plot), overall performance (brier score: 0.200), and clinical usefulness (decision curve analysis: more net benefit than default strategies within the threshold of 0.15-0.80). the top 3 of 14 important predictors generally available in community were age, waist circumference and cognitive function. we embedded xgboost model into the server and this (pre)frailty predictive system is accessible at http://www.frailtyprediction.com.cn. a nomogram was also conducted to enhance the practical use.conclusions: a user-friendly web-based system was developed with good performance to assist healthcare providers to measure the probability of being (pre)frail among community-dwelling older adults in the next two years, facilitating the early identification of high-risk population of (pre)frailty. further research is needed to validate this preliminary system across more controlled cohorts.",AB_0156
"diabetes mellitus is a chronic metabolic disease, whichcausesan imbalance in blood glucose homeostasis and further leads to severecomplications. with the increasing population of diabetes, there isan urgent need to develop drugs to treat diabetes. the developmentof artificial intelligence provides a powerful tool for acceleratingthe discovery of antidiabetic drugs. this work aims to establish apredictor called ipadd for discovering potential antidiabetic drugs.in the predictor, we used four kinds of molecular fingerprints andtheir combinations to encode the drugs and then adopted minimum-redundancy-maximum-relevance(mrmr) combined with an incremental feature selection strategy toscreen optimal features. based on the optimal feature subset, eightmachine learning algorithms were applied to train models by using5-fold cross-validation. the best model could produce an accuracy(acc) of 0.983 with the area under the receiver operating characteristiccurve (auroc) value of 0.989 on an independent test set. to furthervalidate the performance of ipadd, we selected 65 natural productsfor case analysis, including 13 natural products in clinical trialsas positive samples and 52 natural products as negative samples. exceptfor abscisic acid, our model can give correct prediction results.molecular docking illustrated that quercetin and resveratrol stablybound with the diabetes target nr1i2. these results are consistentwith the model prediction results of ipadd, indicating that the machinelearning model has a strong generalization ability. the source codeof ipadd is available at https://github.com/llllxw/ipadd.",AB_0156
"sea ice concentration (sic) is the main geophysical variable for quantifying change in sea ice in the polar regions. a continuous sic product is key to informing climate and ecosystem studies in the polar regions. our study generates a new sic product covering the arctic and antarctic from november 2010 to december 2019. it is the first long-term sic product derived from the microwave radiation imager (mwri) sensors on board the chinese fengyun-3b, fengyun-3c, and fengyun-3d satellites, after a recent re-calibration of brightness temperature. we modified the previous arctic radiation and turbulence interaction study sea ice (asi) dynamic tie point algorithm mainly by changing input brightness temperature and initial tie points. the mwri-asi sic was compared to the existing asi sic products and validated using ship-based sic observations. results show that the mwri-asi sic mostly coincides with the asi sic obtained from the special sensor microwave imager series sensors, with overall biases of - 1 +/- 2 % in the arctic and 0.5 +/- 2 % in the antarctic, respectively. the overall mean absolute deviation between the mwri-asi sic and ship-based sic is 16 % and 17 % in the arctic and antarctic, respectively, which is close to the existing asi sic products. the trend of sea ice extent (sie) derived from the mwri-asi sic closely agrees with the trends of the sea ice index sies provided by the ocean and sea ice satellite application facility (osi saf) and the national snow and ice data center (nsidc). therefore, the mwri-asi sic is comparable with other sic products and may be applied alternatively. the mwri-asi sic dataset is available at https://doi.org/10.1594/pangaea.945188 (chen et al., 2022b).",AB_0156
"background and objective: medical hyperspectral images (mhsis) are used for a contact-free examination of patients without harmful radiation. however, high-dimensionality images contain large amounts of data that are sparsely distributed in a high-dimensional space, which leads to the curse of dimensionality (called hughes' phenomenon) and increases the complexity and cost of data processing and storage. hence, there is a need for spectral dimensionality reduction before the clinical application of mhsis. some dimensionality-reducing stra-tegies have been proposed; however, they distort the data within mhsis. methods: to compress dimensionality without destroying the original data structure, we propose a method that involves data gravitation and weak correlation-based ranking (dgwcr) for removing bands of noise from mhsis while clustering signal-containing bands. band clustering is done by using the connection centre evolution (cce) algorithm and selecting the most representative bands in each cluster based on the composite force. the bands within the clusters are ranked using the new entropy-containing matrix, and a global ranking of bands is obtained by applying an s-shaped strategy. the source code is available at https://www.github.com/zhangchenglong111 6/dgwcr. results: upon feeding the reduced-dimensional images into various classifiers, the experimental results demon-strated that the small number of bands selected by the proposed dgwcr consistently achieved higher classifi-cation accuracy than the original data. unlike other reference methods (e.g. the latest deep-learning-based strategies), dgwcr chooses the spectral bands with the least redundancy and greatest discrimination. conclusion: in this study, we present a method for efficient band selection for mhsis that alleviates the curse of dimensionality. experiments were validated with three mhsis in the human brain, and they outperformed several other band selection methods, demonstrating the clinical potential of dgwcr.",AB_0156
"high-quality, freely accessible, long-term precipitation estimates with fine spatiotemporal resolution play essential roles in hydrologic, climatic, and numerical modeling applications. however, the existing daily gridded precipitation datasets over china are either constructed with insufficient gauge observations or neglect topographic effects and boundary effects on interpolation. using daily observations from 2839 gauges located across china and nearby regions from 1961 to the present, this study compared eight different interpolation schemes that adjusted the climatology based on a monthly precipitation constraint and topographic characteristic correction, using an algorithm that combined the daily climatology field with a precipitation ratio field. results from these eight interpolation schemes were validated using 45 992 high-density daily gauge observations from 2015 to 2019 across china. of these eight schemes, the one with the best performance merges the parameter-elevation regression on independent slopes model (prism) in the daily climatology field and interpolates station observations into the ratio field using an inverse-distance weighting method. this scheme had median values of 0.78 for the correlation coefficient, 8.8mmd 1 for the root-mean-square deviation, and 0.69 for the kling-gupta efficiency for comparisons between the 45 992 high-density gauge observations and the best interpolation scheme for the 0.1 degrees latitude x longitude grid cells from 2015 to 2019. this scheme had the best overall performance, as it fully considers topographic effects in the daily climatology field and it balances local data fidelity and global fitting smoothness in the interpolation of the precipitation ratio field. therefore, this scheme was used to construct a new long-term, gauge-based gridded precipitation dataset for the chinese mainland (called chm_pre, as a member of the china hydro-meteorology dataset) with spatial resolutions of 0.5, 0.25, and 0.1 degrees from 1961 to the present. this precipitation dataset is expected to facilitate the advancement of drought monitoring, flood forecasting, and hydrological modeling. free access to the dataset can be found at https://doi.org/10.6084/m9.figshare.21432123.v4 (han and miao, 2022).",AB_0156
"in recent years, the optimization community has witnessed a surge in the popularity of population-based optimization methods. however, many of these methods suffer from various shortcomings, including unclear performance characteristics, incomplete validation, excessive reliance on metaphors, inadequate exploration and exploitation components, and compromised trade-offs between exploration and exploitation in real-world scenarios. as a result, users often find themselves needing to extensively modify and fine-tune these methods to achieve faster convergence, stable balance, and high-quality results. to shift the optimization community's focus towards performance rather than metaphorical changes, we propose a general population-based optimization technique called the great wall construction algorithm (gwca). this study presents gwca as a simple yet robust method with competitive performance for efficiently solving constrained and unconstrained problems. gwca draws inspiration from the competition and elimination mechanisms observed among workers during the construction of the ancient great wall. it introduces a mathematical model of the labor movement to simulate the algorithm's dynamics. unlike other methods that employ multiple models to generate new solutions, gwca randomly assigns a single predefined motion model to each worker in every iteration. this unique approach showcases gwca's dynamic nature, simple structure, high convergence performance, and ability to deliver satisfactory solution quality, thus outperforming existing optimization methods in terms of efficiency. to validate gwca, we conduct extensive comparisons with popular and advanced algorithms on the ieee cec 2017 benchmark suite across different dimensions (d = 10, 30, 50, 100). additionally, gwca is applied to solve 16 constrained engineering problems and 6 np-hard problems, demonstrating its applicability in handling constrained and complex nonlinear problems. finally, we compare gwca's optimized solutions with those obtained from 33 advanced meta-heuristic algorithms, including the winner of cec 2017. the results confirm the effectiveness of the proposed optimizer in solving a wide range of single-objective problems, surpassing popular base optimizers, advanced variants of existing methods, and several cec winners. we present gwca as an open-source population-based method that can serve as a standard optimization tool across various domains of artificial intelligence and machine learning. it exhibits a range of exploratory and exploitative features, offering high performance and optimization capabilities. the method is highly flexible, scalable, and can be further extended in terms of structure and application to accommodate diverse forms of optimization scenarios. https://github.com/guangian/great-wall-construction-algorithm-a-novel-meta-heuristic-algorithm-for-global-optimization.",AB_0156
"infrared small-target detection (istd) is an important computer vision task. istd aims at separating small targets from complex background clutter. the infrared radiation decays with distance, making the targets highly dim and prone to confusion with the background clutter, which makes the detector challenging to balance the precision and recall rates. to deal with this difficulty, this paper proposes a neural-network-based istd method called courtnet, which has three sub-networks: the prosecution network is designed to improve the recall rate; the defendant network is devoted to increasing the precision rate; the jury network weights their results to adaptively balance the precision and recall rates. courtnet takes the structure of transformers, whose feature resolution remains unchanged. furthermore, the prosecution network utilizes a densely connected structure, which can prevent small targets from disappearing in the forward propagation. in addition, a fine-grained attention module performs attention inside patches to accurately locate the small targets. this paper implements extensive experiments on two istd datasets, mfirst and sirst, and compares courtnet with ten other traditional and deep-learning-based methods. experimental results show that with the fast detection speed (60.61 fps), courtnet achieves the best f1 score, 0.62 (in mfirst) and 0.73 (in sirst), among the compared methods. the code and dataset will be available at https://github.com/pengjingchao/courtnet.",AB_0156
"recent developments in deep learning have brought many inspirations for the scientific computing community and it is perceived as a promising method in accelerating the computationally demanding reacting flow simulations. in this work, we introduce deepflame, an open-source c++ platform with the capabilities of utilising machine learning algorithms and offline-trained models to solve for reactive flows. we combine the individual strengths of the computational fluid dynamics library openfoam, machine learning framework torch, and chemical kinetics program cantera. the complexity of cross -library function and data interfacing (the core of deepflame) is minimised to achieve a simple and clear workflow for code maintenance, extension and upgrading. as a demonstration, we apply our recent work on deep learning for predicting chemical kinetics (zhang et al., 2022 [8]) to highlight the potential of machine learning in accelerating reacting flow simulation. a thorough code validation is conducted via a broad range of canonical cases to assess its accuracy and efficiency. the results demonstrate that the convection-diffusion-reaction algorithms implemented in deepflame are robust and accurate for both steady-state and transient processes. in addition, a number of methods aiming to further improve the computational efficiency, e.g. dynamic load balancing and adaptive mesh refinement, are explored. their performances are also evaluated and reported. with the deep learning method implemented in this work, a speed-up of two orders of magnitude is achieved in a simple hydrogen ignition case when performed on a medium-end graphics processing unit (gpu). further gain in computational efficiency is expected for hydrocarbon and other complex fuels. a similar level of acceleration is obtained on an ai-specific chip - deep computing unit (dcu), highlighting the potential of deepflame in leveraging the next-generation computing architecture and hardware.program summaryprogram title: deepflame cpc library link to program files: https://doi .org /10 .17632 /3pg9xmypp3 .1 developer's repository link: https://github .com /deepmodeling /deepflame-dev licensing provisions: gplv3 programming language: c++ nature of problem: solving chemically reacting flows with direct (quasi-direct) simulation methods is usually troubled by the following problems: 1. as the widely-used computational fluid dynamics (cfd) toolbox, openfoam features limited ode solvers for chemistry and oversimplified transport models, yielding non-negligible errors in simulation results; 2. the chemical source term evaluation is the most computationally expensive and usually accounts for more than 80% of total computing time. solution method: an open-source platform bringing together the individual strengths of openfoam, cantera and pytorch libraries is built in this study. in the present implementation, cvode solvers, detailed transport models and deep learning algorithms are all adopted to assist the simulation of reacting flow. note that here machine learning is introduced in combination with heterogeneous computing to accelerate the most demanding solving procedure for chemical source term evaluation.& copy; 2023 elsevier b.v. all rights reserved.",AB_0156
"accurately predicting compound-protein binding affinity is a crucial task in drug discovery. computational models offer the advantages of short time, low cost and safety compared to traditional drug development. pocket is the key binding region of the protein, which provides invaluable information for drug repositioning and drug design. in this study, we propose an ensemble learning model, called stackcpa, to predict the compound-protein binding affinity. the model integrates multi-scale features of protein pocket and compound through a transfer learning strategy. the protein pocket is described in a fine-grained way by atomic level, residue level and subdomain level. the proposed model stackcpa is evaluated on three binding affinity benchmark datasets. the experiment results show that stackcpa achieves the best performance on all the three datasets in comparison with other state-of-the-art deep learning models. the ablation study shows that the protein pocket can provide sufficient information for affinity prediction and its multi-scale features enable the model to further improve the prediction performance. in addition, the case study for epidermal growth factor receptor erbb1 (egfr) indicates that stackcpa could serve as an effective tool for drug repurposing. source codes and data of stackcpa are available at https://github.com/csubiogroup/stackcpa.",AB_0156

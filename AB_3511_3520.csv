AB,NO
"variational autoencoder (vae) and generative adversarial network (gan) are two classic generative models that generate realistic data from a predefined prior distribution, such as a gaussian distribution. one advantage of vae over gan is its ability to simultaneously generate high-dimensional data and learn latent representations that are useful for data manipulation. however, it has been observed that a tradeoff exists between reconstruction and generation in vae, as matching the prior distribution for the latent representations may destroy the geometric structure of the data manifold. to address this issue, we propose an autoencoder-based generative model that allows the prior to learn the embedding distribution, rather than imposing the latent variables to fit the prior. to preserve the geometric structure of the data manifold to the maximum, the embedding distribution is trained using a simple regularized autoencoder architecture. then an adversarial strategy is employed to achieve a latent mapping. we provide both theoretical and experimental support for the effectiveness of our method, which eliminates the contradiction between preserving the geometric structure of the data manifold and matching the distribution in latent space. the code is available at https://github.com/gengcong940126/gmiel. & copy; 2023 elsevier b.v. all rights reserved.",AB_0352
"multi-view subspace clustering has attracted great attention due to its ability to explore data structure by utilizing complementary information from different views. most of existing methods learn a sample representation coefficient matrix or an affinity graph for each single view, then the final clustering result is obtained from the spectral embedding of a consensus graph using certain traditional clustering techniques, such as k-means. however, clustering performance will be degenerated if the early fusion of partitions cannot fully exploit relationships between all samples. different from existing methods, we propose a multi-view subspace clustering method via adaptive graph learning and late fusion alignment (agllfa). for each view, agllfa learns an affinity graph adaptively to capture the similarity relationship among samples. moreover, a spectral embedding learning term is designed to exploit the latent feature space of different views. furthermore, we design a late fusion alignment mechanism to generate an optimal clustering partition by fusing view-specific partitions obtained from multiple views. an alternate updating algorithm with validated convergence is developed to solve the resultant optimization problem. extensive experiments on several benchmark datasets are conducted to illustrate the effectiveness of the proposed method when compared with other state-of-the-art methods. the demo code of this work is publicly available at https://github.com/tangchuan2000/ agllfa.& copy; 2023 elsevier ltd. all rights reserved.",AB_0352
"this paper presents fdnet: a focal decomposed network for efficient, robust and practical time series forecasting. we break away from conventional deep time series forecasting formulas which obtain prediction results from universal feature maps of input sequences. in contrary, fdnet neglects universal correlations of input elements and only extracts fine-grained local features from input sequence. we show that: (1) deep time series forecasting with only fine-grained local feature maps of input sequence is feasible upon theoretical basis. (2) by abandoning global coarse-grained feature maps, fdnet overcomes distribution shift problem caused by changing dynamics of time series which is common in real-world applications. (3) fdnet is not dependent on any inductive bias of time series except basic auto-regression, making it general and practical. moreover, we propose focal input sequence decomposition method which decomposes input sequence in a focal manner for efficient and robust forecasting when facing long sequence time series input (lsti) problem. fdnet achieves competitive forecasting performances on six real-world benchmarks and reduces prediction mse by 38.4% on average compared with other thirteen sota baselines. the source code is available at https://github.com/origamisl/fdnet.& copy; 2023 the author(s). published by elsevier b.v.this is an open access article under the cc by-nc-nd license ().",AB_0352
"existing multi-person pose estimators can be roughly divided into two-stage approaches (top-down and bottom-up approaches) and one-stage approaches. the two-stage methods either suffer high computa-tional redundancy for additional person detectors or group keypoints heuristically after predicting all the instance-free keypoints. the recently proposed single-stage methods do not rely on the above two extra stages but have lower performance than the latest bottom-up approaches. in this work, a novel single-stage multi-person pose regression, termed smpr, is presented. it follows the paradigm of dense predic-tion and predicts instance-aware keypoints from every location. besides feature aggregation, we propose better strategies to define positive pose hypotheses for training which all play an important role in dense pose estimation. the network also learns the scores of estimated poses. the pose scoring strategy further improves the pose estimation performance by prioritizing superior poses during non-maximum suppres-sion (nms). we show that our method not only outperforms existing single-stage methods but also be competitive with the latest bottom-up methods, with 70.2 ap and 77.5 ap75 on the coco test-dev pose benchmark. the code is available at https://github.com/cmdi-dlut/smpr .& copy; 2023 elsevier ltd. all rights reserved.",AB_0352
"analysis of primate behavior is crucial for neuroscience research and drug evaluation. although many methods of automatically recording animal behavior have been proposed, none of them can meet the requirements of both speed and accuracy. in order to implement real-time and high-precision automatic recording of primate behavior, we proposed a novel joint detection and classification (jdc) model to predict the location, identity and actions of monkeys simultaneously. different from the existing complex non-end-to-end models, our model is the first end-to-end method in this field. in order to explore how to efficiently fuse spatiotemporal information, we constructed the jdc model with a single frame or different fusion approaches. in addition, we collected a new dataset named spatiotemporal action localization of monkeys in a group (salmg), which is the first one containing the location, identity and actions of monkeys in a group. the jdc model with middle fusion approach (jdc-mf) on the salmg dataset outperforms all compared methods. the f1 score of the jdc-mf is 81.4%, which is 15.3% and 10.6% higher than the separate detection and classification model and the two-stage model, respectively. moreover, the jdc-mf achieves the highest accuracy of 99.1 % on public pig novelty preference behavior dataset, which is 4.1% higher than the second-best model. the jdc-mf only takes 0.027 s for a clip on a nvidia geforce rtx 2080 ti. therefore, the jdc-mf can realize real-time and high-precision spatiotemporal action localization of monkeys, and provide an effective reference scheme for automatic recording and analysis of animal behavior. code has been made available at: https://github.com/kewei-liang/jdc-mf.",AB_0352
"transformer-basedmodels have dominated many vision and language tasks, including image captioning. however, such models still suffer from the limitation of expressive ability and information loss during dimensionality reduction. in order to solve the above problems, this paper proposes a complementary shifted transformer (cst) for image captioning. we first introduce a complementary multi-branch bi-positional encoding self-attention (mbsa) module. it utilizes both absolute and relative positional encoding to learn precise positional representations. meanwhile, mbsa is equipped with multi-branch architecture, which replicates multiple branches for each head. to improve the expressive ability of the model, we utilize the drop branch technique, which trains the branches in a complementary way. furthermore, we propose a spatial shift augmented module, which takes advantage of both low-level and high-level features to enhance visual features with fewer parameters. to validate our model, we conduct extensive experiments on the mscoco benchmark dataset. compared to the state-of-the-art methods, the proposed cst achieves a competitive performance of 135.3% cider (+0.2%) on the karpathy split and 136.3% cider (+0.9%) on the official online test server. in addition, we also evaluate the inference performance of our model on a novel object dataset. the source codes and trained models are publicly available at https://github.com/noonisy/cst.",AB_0352
"in this article, we formulate the standard mixture learning problem as a markov decision process (mdp). we theoretically show that the objective value of the mdp is equivalent to the log-likelihood of the observed data with a slightly different parameter space constrained by the policy. different from some classic mixture learning methods such as expectation-maximization (em) algorithm, the proposed reinforced algorithm requires no distribution assumptions and can handle the non-convex clustered data by constructing a model-free reward to evaluate the mixture assignment based on the spectral graph theory and linear discriminant analysis (lda). extensive experiments on both synthetic and real examples demonstrate that the proposed method is comparable with the em algorithm when the gaussian mixture assumption is satisfied, and significantly outperforms it and other clustering methods in most scenarios when the model is misspecified. a python implementation of our proposed method is available at https://github.com/leyuanheart/reinforced-mixture-learning. & copy; 2023 elsevier ltd. all rights reserved.",AB_0352
"three-dimensional human pose and shape estimation is to compute a full human 3d mesh given a single image. the contamination of features caused by occlusion usually degrades its performance significantly. recent progress in this field typically addressed the occlusion problem implicitly. by contrast, in this paper, we address it explicitly using a simple yet effective de-occlusion multi-task learning network. our key insight is that feature for mesh parameter regression should be noiseless. thus, in the feature space, our method disentangles the occludee that represents the noiseless human feature from the occluder. specifically, a spatial regularization and an attention mechanism are imposed in the backbone of our network to disentangle the features into different channels. furthermore, two segmentation tasks are proposed to supervise the de-occlusion process. the final mesh model is regressed by the disentangled occlusion-aware features. experiments on both occlusion and non-occlusion datasets are conducted, and the results prove that our method is superior to the state-of-the-art methods on two occlusion datasets, while achieving competitive performance on a non-occlusion dataset. we also demonstrate that the proposed de-occlusion strategy is the main factor to improve the robustness against occlusion. the code is available at https://github.com/qihangran/de-occlusion_mtl_hmr. & copy; 2023 published by elsevier b.v.",AB_0352
"with the popularity of online shopping and the rise of various brands, logo detection is gradually coming to the forefront of researchers' minds. however, accurately detecting multiscale, similar, diverse and shape-shifting logos poses a challenge for this technology. the swin transformer has created milestone as a high-performance deep learning method across modalities, domains and tasks in various tasks of computer vision. we improve the swin transformer for better image feature extraction and enhance the robustness for its application to logo detection. in this paper, we propose the pmst as the backbone of logo detection, and design a bypass-parallelizable shift module and a miniature window tandem shift strategy to further enhance image feature fusion and transfer between windows. the pmst achieves a 79.2 box ap on the logodata dataset, surpassing most detection models. according to existing known methods, in logo detection, the pmst is the first backbone to put transformer to the detection. the results achieved state-of-the-art on the flickrlogos-32 and foodlogodet-1500 datasets. it also achieves excellent efficiency on the imagenet-1k, openbrands-80 and ms-coco datasets. the code is available at https://github.com/blowhen/pmst.& copy; 2023 elsevier inc. all rights reserved.",AB_0352
"federated learning achieves joint training of deep models by connecting decentralized datasources, which can significantly mitigate the risk of privacy leakage. however, in a more general case, the distributions of labels among clients are different, called label distribution skew. directly applying conventional federated learning without consideration of label distribution skew issue significantly hurts the performance of the global model. to this end, we propose a novel federated learning method, named fedmgd, to alleviate the performance degradation caused by the label distribution skew issue. it introduces a global generative adversarial network to model the global data distribution without access to local datasets, so the global model can be trained using the global information of data distribution without privacy leakage. the experimental results demonstrate that our proposed method significantly outperforms the state-ofthe-art on several public benchmarks. code is available at https://www.github.com/sheng-t/fedmgd .& copy; 2023 elsevier ltd. all rights reserved.",AB_0352

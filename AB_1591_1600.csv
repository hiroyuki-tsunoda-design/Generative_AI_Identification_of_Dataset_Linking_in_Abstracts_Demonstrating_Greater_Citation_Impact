AB,NO
"introduction: single-cell rna sequencing (scrna-seq) is a powerful tool for understanding cellular heterogeneity and identifying cell types in virus-related research. however, direct identification of sars-cov-2-infected cells at the single-cell level remains challenging, hindering the understanding of viral pathogenesis and the development of effective treatments. methods: in this study, we propose a deep learning framework, the single-cell virus detection network (scvdn), to predict the infection status of single cells. the scvdn is trained on scrna-seq data from multiple nasal swab samples obtained from several contributors with varying cell types. to objectively evaluate scvdn's performance, we establish a model evaluation framework suitable for real experimental data. results and discussion: our results demonstrate that scvdn outperforms four state-of-the-art machine learning models in identifying sars-cov-2-infected cells, even with extremely imbalanced labels in real data. specifically, scvdn achieves a perfect auc score of 1 in four cell types. our findings have important implications for advancing virus research and improving public health by enabling the identification of virus-infected cells at the single-cell level, which is critical for diagnosing and treating viral infections. the scvdn framework can be applied to other single-cell virus-related studies, and we make all source code and datasets publicly available on github at https://github.com/studentiz/scvdn.",AB_0160
"long-tailed classification with fine-grained appearance, e.g., in chest x-ray images, is very challenging due to the very similar appearance and imbalanced distribution between normal and abnormal samples, which extremely limits the ability of deep networks to learn powerful representations and discriminative classifiers. in this paper, we propose a novel joint representation and classifier learning (jrcl) framework to achieve the above purposes, simultaneously. in terms of representation learning, we propose a one-to-all supervised contrastive learning strategy to avoid the medium or tail classes mixing in the head classes. for the classifier cleaning, we propose a novel binary distribution consistency (bdc) loss to learn a discriminative classifier that could separate the normal and abnormal samples.the bdc loss measures the binary distribution consistency between the designed multi-class classifier and an auxiliary binary classifier. consequently, the jrcl framework is optimized with a supervised contrastive learning loss, a binary distribution consistency loss, and a multi-classification loss. we conduct experiments on large-scale, long-tail image datasets, nih-cxr-lt, mimic-cxr-lt, inaturalist 2018, and places-lt. experimental results demonstrate jrcl could improve the discriminate ability of the imbalanced data and thus obtain better classification performance. compared with the state-of-the-art methods, our proposed jrcl achieves comparable or even better performance. the source codes are available at https://github. com/guanqj932/jrcl.",AB_0160
"transformer-based methods have led to the revolutionizing of multiple computer vision tasks. inspired by this, we propose a transformer-based network with a channel-enhanced attention module to explore contextual and spatial information in non-contrast (nc) and contrast-enhanced (ce) computed tomography (ct) images for pulmonary vessel segmentation and artery-vein separation. our proposed network employs a 3d contextual transformer module in the encoder and decoder part and a double attention module in skip connection to effectively finish high-quality vessel and artery-vein segmentation. extensive experiments are conducted on the in-house dataset and the isicdm2021 challenge dataset. the in-house dataset includes 56 nc ct scans with vessel annotations and the challenge dataset consists of 14 nc and 14 ce ct scans with vessel and artery-vein annotations. for vessel segmentation, dice is 0.840 for ce ct and 0.867 for nc ct. for artery-vein separation, the proposed method achieves a dice of 0.758 of ce images and 0.602 of nc images. quantitative and qualitative results demonstrated that the proposed method achieved high accuracy for pulmonary vessel segmentation and artery-vein separation. it provides useful support for further research associated with the vascular system in ct images. the code is available at https://github.com/wuyanan513/pulmonary-vessel-segmentation-and-artery-vein-separation.",AB_0160
"despite the good results that have been achieved in unimodal segmentation, the inherent limitations of individual data increase the difficulty of achieving breakthroughs in performance. for that reason, multi-modal learning is increasingly being explored within the field of remote sensing. the present multi-modal methods usually map high-dimensional features to low-dimensional spaces as a preprocess before feature extraction to address the nonnegligible domain gap, which inevitably leads to information loss. to address this issue, in this paper we present our novel imbalance knowledge-driven multi-modal network (ikd-net) to extract features from multi-modal heterogeneous data of aerial images and lidar directly. ikd-net is capable of mining imbalance information across modalities while utilizing a strong modal to drive the feature map refinement of the weaker ones in the global and categorical perspectives by way of two sophisticated plug-and-play modules: the global knowledge-guided (gkg) and class knowledge-guided (ckg) gated modules. the whole network then is optimized using a joint loss function. while we were developing ikd-net, we also established a new dataset called the national agriculture imagery program and 3d elevation program combined dataset in california (n3c-california), which provides a particular benchmark for multi-modal joint segmentation tasks. in our experiments, ikd-net outperformed the benchmarks and state-of-the-art methods both in the n3c-california and the small-scale isprs vaihingen dataset. ikd-net has been ranked first on the real-time leaderboard for the grss dfc 2018 challenge evaluation until this paper's submission. our code and n3c-california dataset are available at https://github.com/wymqqq/ikdnet-pytorch.",AB_0160
"to adapt to the uncertainty of the real environment and solve the problem of high efficiency and high quality, this study comprehensively considers a variety of uncertainty factors, focusing on modeling and solving a hybrid flow-shop scheduling problem by two-stage stochastic programming (hfsp-tsp). first, this paper uses a twostage scenario tree to describe the uncertain factors, the probabilities and values are obtained under different discrete production scenarios, and stochastic programming theory is used to formulate a mixed-integer linear programming (milp) model for hfsp-tsp. second, based on a general discrete optimization algorithm framework, that is, pointer-based discrete differential evolution (pdde) algorithm, a novel variant (h-pdde) is proposed for effectively solving the hfsp-tsp. it adopts a permutation scheduling decoding method and introduces three new improvement strategies: the strategy of inconsistent code length of individuals in the population, adding local search in discrete mutation operation, using a heuristic algorithm to generate the initial population. finally, computational experiments were conducted to illustrate the proposed mathematical model and optimization algorithm. the computational results show that the h-pdde can solve the hfsp-tsp more effectively than existing algorithms and conventional pdde variants. the stochastic programming model is increasingly superior to the deterministic model in an uncertain environment. the source code of the h-pdde algorithm and its data files can be found at https://github.com/huangyiping-ai/h-pdde-algorithm.git, which is publicly available.",AB_0160
"identification of drug-target interactions (dtis) is an important step in drug discovery and drug repositioning. in recent years, graph-based methods have attracted great attention and show advantages on predicting potential dtis. however, these methods face the problem that the known dtis are very limited and expensive to obtain, which decreases the generalization ability of the methods. self-supervised contrastive learning is independent of labeled dtis, which can mitigate the impact of the problem. therefore, we propose a framework shgcl-dti for predicting dtis, which supplements the classical semi-supervised dti prediction task with an auxiliary graph contrastive learning module. specifically, we generate representations for the nodes through the neighbor view and meta-path view, and define positive and negative pairs to maximize the similarity between positive pairs from different views. subsequently, shgcl-dti reconstructs the original heterogeneous network to predict the potential dtis. the experiments on the public dataset show that shgcl-dti has significant improvement in different scenarios, compared with existing state-of-the-art methods. we also demonstrate that the contrastive learning module improves the prediction performance and generalization ability of shgcl-dti through ablation study. in addition, we have found several novel predicted dtis supported by the biological literature. the data and source code are available at: https://github.com/tojsse-idata/shgcl-dti.",AB_0160
"high-accuracy positioning and identification of transmission line components is the premise for their status detection and fault diagnosis. however, due to the limitations of imbalance object scale and distribution in aerial images, the problem of detecting dense-tiny objects still needs to be solved. considering the prior knowledge of fixed connection scenes, we proposed a novel method named scene iterative reasoning network (sirn) based on self-adaptive clustering and local scene knowledge. it consists of the coarse-grained detector (cgd), scene self-adaptive clustering (ssac) subnetwork, and scene structure iterative reasoning (ssir) subnetwork. the cgd was proposed to obtain global coarse detection results. then, the ssac subnetwork utilized unsupervised self-adaptive clustering to obtain accurate dense regions based on the cgd results. finally, the ssir subnetwork was designed to extract and fuse the scene semantic structure information of local regions for realizing accurate dense-tiny object detection. in summary, the sirn model utilizes an iterative inference strategy to detect dense regions accurately. by leveraging scene structure information, the model effectively transforms the challenge of detecting dense objects into an advantage, resulting in precise detection. the sirn model is compatible with single-stage and two-stage object detection models, achieving a notable mean average precision (map) improvement ranging from 4.4% to 12.2% compared to the baseline models. compared to other state-of-the-art object detection models, sirn demonstrates significant advantages in accuracy and error rate metrics. in addition, qualitative and quantitative experiments show that the sirn model considerably enhanced the detection of dense-tiny objects. the code is available at https://github.com/charmingwang/sirn.",AB_0160
"introduction: in metabolic engineering and synthetic biology applications, promoters with appropriate strengths are critical. however, it is time-consuming and laborious to annotate promoter strength by experiments. nowadays, constructing mutation-based synthetic promoter libraries that span multiple orders of magnitude of promoter strength is receiving increasing attention. a number of machine learning (ml) methods are applied to synthetic promoter strength prediction, but existing models are limited by the excessive proximity between synthetic promoters. methods: in order to enhance ml models to better predict the synthetic promoter strength, we propose evmp(extended visionmutant priority), a universal framework which utilize mutation information more effectively. in evmp, synthetic promoters are equivalently transformed into base promoter and corresponding k-mer mutations, which are input into baseencoder and varencoder, respectively. evmp also provides optional data augmentation, which generates multiple copies of the data by selecting different base promoters for the same synthetic promoter. results: in trc synthetic promoter library, evmp was applied to multiple ml models and the model effect was enhanced to varying extents, up to 61.30% (mae), while the sota(state-of-the-art) record was improved by 15.25% (mae) and 4.03% (r-2). data augmentation based on multiple base promoters further improved the model performance by 17.95% (mae) and 7.25% (r-2) compared with non-evmp sota record. discussion: in further study, extended vision (or k-mer) is shown to be essential for evmp. we also found that evmp can alleviate the over-smoothing phenomenon, which may contributes to its effectiveness. our work suggests that evmp can highlight the mutation information of synthetic promoters and significantly improve the prediction accuracy of strength. the source code is publicly available on github: https://github.com/tiny-snow/evmp.",AB_0160
"low-molecular-weight heparins (lmwhs) are important anticoagulants widely used in clinic. since they are comprised of complex and heterogenous glycan chains, liquid chromatography-tandem mass spec-trometry (lc-ms) is commonly used for structural analysis and quality control of lmwhs to ensure their safety and efficacy. yet, the structural complexity arising from the parent heparin macromolecules, as well as the different depolymerization methods used for preparing lmwhs, makes processing and assigning the lc-ms data of lwmhs very tedious and challenging. we therefore developed, and here report, an open-source and easy-to-use web application, msphep, to facilitate the lmwh analysis based on lc-ms data. msphep is compatible with various lmwhs and chromatographic separation methods. with the hepqual function, msphep is capable of annotating both the lmwh compound and its isotopic distri-bution from mass spectra. moreover, the hepquant function enables automatic quantification of lmwh compositions without prior knowledge or any database generation. to demonstrate the reliability and system stability of msphep, we tested various types of lmwhs that were analyzed with different chro-matographic methods coupled to ms. the results show that msphep has its own advantages compared to another public tool glycresoft for lmwh analysis, and it is available online under an open-source license at https://ngrc-glycan.shinyapps.io/msphep .& copy; 2023 elsevier b.v. all rights reserved.",AB_0160
"it is necessary to adequately extract scattering characteristics from polarimetric synthetic aperture radar (polsar) data for land-cover classification. current interpretation technologies, such as target decompositions, polarimetric signatures, and polarimetric coherence patterns, have been widely used to explore polarization information. however, because limited scattering models are used to characterize all ground targets, these methods are occasionally limited in the interpretation of polsar data. this may reduce the accuracy of the landcover classification. in this study, we attempted to extract the scattering characteristics through another novel method. we understand the polsar image interpretation as the projection of the scattering model on the measured matrix. current methods project only a limited series of scattering models onto a measured matrix. to complement current methods of polsar image interpretation, we propose a polarimetric projection-based scattering characteristics extraction (ppsce) method. it projects scattering models consisting of four changing independent polarization parameters onto the measured matrix. these scattering models, associated with the geometric and physical properties of the ground targets, correspond to the entire polarization space. the ppsce method, meanwhile, extracts polarization information sufficiently. l-band uavsar, c-band radarsat-2, and pband airsar images of classical experimental areas are used to validate the ppsce method. the results show that the proposed ppsce method can present polarization information that is difficult to investigate by the existing methods. in addition, the scattering features derived using the ppsce method are superior for land-cover classification. compared to the classification results based on the coherency matrix and wishart classifier, the proposed method improves the overall classification accuracy by 23.56% for uavsar data. compared to target decompositions and polarization signatures, the overall classification accuracy of the proposed method is increased by 29.32% (rf) and 22.63% (svm) for uavsar data, 7.96% (rf) and 4.36% (rf) for radarsat-2 and airsar datasets, respectively. furthermore, the proposed method has significant potential for soil moisture inversion. https://rgdoi.net/10.13140/rg.2.2.14091.26409.",AB_0160

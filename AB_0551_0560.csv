AB,NO
"the internet of musical things (iomust) refers to the extension of the internet of things paradigm to the musical domain. interoperability represents a central issue within this domain, where hetero-geneous musical things serving radically different purposes are envisioned to communicate between each other. automatic discovery of resources is also a desirable feature in iomust ecosystems. however, the existing musical protocols are not adequate to support discoverability and interoperability across the wide heterogeneity of musical things, as they are typically not flexible, lack high resolution, are not equipped with inference mechanisms that could exploit on board the information on the whole application environment. besides, they hardly ever support easy integration with the web. in addition, iomust applications are often characterized by strict requirements in terms of latency of the exchanged messages. semantic web of things technologies have the potential to overcome the limitations of existing musical protocols by enabling discoverability and interoperability across hetero-geneous musical things. in this paper we propose the musical semantic event processing architecture (musepa), a semantically-based architecture designed to meet the iomust requirements of low-latency communication, discoverability, interoperability, and automatic inference. the architecture is based on the coap protocol, a semantic publish/subscribe broker, and the adoption of shared ontologies for describing musical things and their interactions. the code implementing musepa can be accessed at: https://github.com/cimil/musepa/.(c) 2022 elsevier b.v. all rights reserved.",AB_0056
"aiiomaps 2 is an update of the allosteric mutation analysis and polymorphism of signalling database, which contains data on allosteric communication obtained for predicted structures in the alphafold database (afdb) and trrosetta-predicted pfam domains. the data update contains allosteric signalling maps (asms) and allosteric probing maps (apms) quantifying allosteric effects of mutations and of small probe binding, respectively. to ensure quality of the asms and apms, we performed careful and accurate selection of protein sets containing highquality predicted structures in both databases for each organism/structure, and the data is available for browsing and download. the data for remaining structures are available for download and should be used at user's discretion and responsibility. we believe these massive data can facilitate both diagnostics and drug design within the precision medicine paradigm. specifically, it can be instrumental in the analysis of allosteric effects of pathological and rescue mutations, providing starting points for fragment-based design of allosteric effectors. the exhaustive character of allosteric signalling and probing fingerprints will be also useful in future developments of corresponding machine learning applications. the database is freely available at: http://allomaps.bii.a-star.edu.sg. [graphics] .",AB_0056
"objective and subjective quality assessment is still a challenging problem in various image processing tasks. for instance, in the context of image compression, most of the conducted studies have focused on image datasets encoded using standard algorithms such as jpeg and jpeg2000. in this paper, we propose to further investigate the quality assessment issue in the presence of neural networks-based compressed images. more precisely, a new database of compressed images has been firstly built using jpeg2000 standard as well as four recent neural networks based coding schemes. then, subjective experiments are performed to obtain the mean opinion scores of the generated distorted images. finally, an extensive evaluation and analysis of objective image quality assessment metrics is achieved. for instance, in addition to conventional and machine learning metrics, we have considered different deep learning based models, which have been trained on our database. the new subjective database with its associated mean opinion scores as well as the learned models are publicly available at https://github.com/zakopz/nncd-iqa-database. the obtained results show the interest of deep learning based metrics in the context of neural networks-based compressed images.",AB_0056
"cohesin is a multifunctional protein responsible for transcriptional regulation and chromatin organization. cohesin binds to chromatin at tens of thousands of distinct sites in a conserved or tissue-specific manner, whereas the function of cohesin varies greatly depending on the epigenetic properties of specific chromatin loci. cohesin also extensively mediates cis-regulatory modules (crms) and chromatin loops. even though next-generation sequencing technologies have provided a wealth of information on different aspects of cohesin, the integration and exploration of the resultant massive cohesin datasets are not straightforward. here, we present cohesindb (https://cohesindb.iqb.u-tokyo.ac.jp ), a comprehensive multiomics cohesin database in human cells. cohesindb includes 2043 epigenomics, transcriptomics and 3d genomics datasets from 530 studies involving 176 cell types. by integrating these large-scale data, cohesindb summarizes three types of 'cohesin objects': 751 590 cohesin binding sites, 957 868 cohesin-related chromatin loops and 2 229 500 cohesin-related crms. each cohesin object is annotated with locus, cell type, classification, function, 3d genomics and cisregulatory information. cohesindb features a user-friendly interface for browsing, searching, analyzing, visualizing and downloading the desired information. cohesindb contributes a valuable resource for all researchers studying cohesin, epigenomics, transcriptional regulation and chromatin organization.",AB_0056
"rna g-quadruplexes (rg4s) are non-canonical, disease-associated post-transcriptional regulators of gene expression whose functions are driven by rna-binding proteins (rbps). being able to explore transcriptome-wide rg4 formation and interaction with rbps is thus paramount to understanding how they are regulated and exploiting them as potential therapeutic targets. towards this goal, we present quadratlas (https:// rg4db.cibio.unitn.it), a database of experimentally-derived and computationally predicted rg4s in the human transcriptome, enriched with biological function and disease associations. as rbps are key to their function, we mined known interactions of rg4s with such proteins, complemented with an extensive rbp binding sites dataset. users can thus intersect rg4s with their potential regulators and effectors, enabling the formulation of novel hypotheses on rg4 regulation, function and pathogenicity. to support this capability, we provide analysis tools for predicting whether an rbp can bind rg4s, rg4 enrichment in a gene set, and de novo rg4 prediction. genome-browser and table views allow exploring, filtering, and downloading the data quickly for individual genes and in batch. quadratlas is a significant step forward in our ability to understand the biology of rg4s, offering unmatched data content and enabling the integrated analysis of rg4s and their interactions with rbps.",AB_0056
"we present pyoecp, a python-based flexible open-source software for estimating and modeling the complex permittivity obtained from the open-ended coaxial probe (oecp) technique. the transformation of the measured reflection coefficient to complex permittivity is performed based on three different methods. the software library contains the dielectric spectra of common reference liquids, which can be used to transform the reflection coefficient into the dielectric spectra. several python routines that are commonly employed (e.g., scipy and numpy) in the field of science and engineering are required only so that the users can alter the software structure depending on their needs. the modeling algorithm exploits the markov chain monte carlo method for the data regression. the discrete relaxation models can be built by a proper combination of well-known relaxation models. in addition to these models, electrode polarization, a typical measurement artifact for interpreting dielectric spectra, can be incorporated into the modeling algorithm. a continuous relaxation model, which solves the fredholm integral equation of the first kind (a mathematically ill-posed problem), is also included. this open-source software enables users to freely adjust the physical parameters to obtain physical insight into their materials under test and will be consistently updated for more accurate measurement and interpretation of dielectric spectra in an automated manner. this work describes the theoretical and mathematical background of the software, lays out the workflow, and validates the software functionality based on both synthetic and empirical data included in the software. program summary program title: pyoecp 0.5 cpc library link to program files: https://doi .org /10 .17632 /vsh6vb9cbv.1 developer's repository link: https://github .com /tyoon124 code ocean capsule: https://codeocean .com /capsule /89645681 licensing provisions: bsd-3 clause license programming language: python3 external routines: numpy, scipy, and matplotlib nature of problem: estimate and interpret the frequency-dependent (complex) permittivity in fluid(s) and their mixtures based on the reflection coefficients obtained from the open-ended coaxial probe (oecp) technique. the obtained dielectric spectra can be useful for understanding the relaxation processes in an arbitrary fluid. solution method: the reflection coefficient data is obtained as a text format from a vector network analyzer (vna). this text data is parsed into a numpy array. three different modules (stuchly, marsland, and komarov) can be used to transform the parsed reflection coefficient data into complex permittivity as a function of the measurement frequency. the resultant dielectric spectra can be dissected and interpreted by fitting either discrete relaxation model(s) based on the markov chain monte carlo algorithm or a continuous relaxation model by applying the zasetsky-buchner method. (c) 2022 elsevier b.v. all rights reserved.",AB_0056
"we develop and release a photonic band dispersion solver based on the coupled dipole method called cdpds, which aims to provide an analytical computation of bulk and boundary dispersions and topological phases of a one-dimensional and two-dimensional photonic crystal consisting of an array of particles. the main advantages of cdpds include (i) a wide coverage of computation that spans the bulk dispersion of a unit cell, boundary dispersion of a supercell comprising one or two types of photonic crystals, and topological phases, (ii) the inclusion of a straightforward graphical user interface that facilitates high accessibility to users who have no expertise in computer programming, and (iii) the addition of built-in options that are useful in examining the photonic dispersions of several widely used systems. the basic principle and computational method incorporated into cdpds and its performance verification using two distinct photonic crystals are presented in this article. the results indicate that cdpds will serve as help-ful and accessible guidance for computing photonic band dispersions in the fields of conventional and topological photonics. program summary program title: cdpds cpc library link to program files: https://doi .org /10 .17632/865ntt8w7v.1 licensing provisions: lgpl programming language: python 3.9 supplementary material: user manual, tutorial movie, and supplementary material file containing the reproduction of three photonic systems. nature of problem: an analytical band dispersion analysis of a photonic crystal composed of an array of particles. the photonic dispersion and physics therein are important in investigating periodically arranged photonic systems. additionally, there is an increasing demand for free and accessible software based on an analytical framework for computing bulk and boundary dispersions, electromagnetic field distributions, and topological phases of one-dimensional and two-dimensional photonic crystals. solution method: cdpds provides portable software for fast and efficient computation of bulk and boundary dispersions and topological phases of 1d and 2d photonic crystals using the coupled dipole method incorporated with the bloch theorem. a particle that consists a photonic crystal is modeled as a point dipole with a prespecified polarizability tensor. cdpds is highly accessible, especially for users who have no expertise in computer programming. additional comments including restrictions and unusual features: the coupled dipole method models each sublattice of the photonic crystal of interest to a point dipole. thus, photonic systems with geometric complexity can only be examined using simplifications. (c) 2022 elsevier b.v. all rights reserved.",AB_0056
"we present an algorithm for simulating reverse monte carlo decays given an existing forward monte carlo decay engine. this algorithm is implemented in the alouette library, a tauola thin wrapper for simulating decays of tau-leptons. we provide a detailed description of alouette, as well as validation results. program summary program title: alouette cpc library link to program files: https://doi .org /10 .17632 /w2z5w546c5 .1 developer's repository link: https://github .com /niess /alouette code ocean capsule: https://codeocean.com /capsule /9167021 licensing provisions: lgpl-3.0 programming language: c, fortran and python nature of problem: perform reverse monte carlo decays. solution method: invert an existing forward monte carlo engine using the jacobian backward method. apply the algorithm to tau decays generated by tauola. (c) 2022 elsevier b.v. all rights reserved.",AB_0056
"few-shot learning (fsl) approaches, mostly neural network-based, assume that pre-trained knowledge can be obtained from base (seen) classes and transferred to novel (unseen) classes. however, the black-box nature of neural networks makes it difficult to understand what is actually transferred, which may hamper fsl application in some risk-sensitive areas. in this paper, we reveal a new way to perform fsl for image classification, using a visual representation from the backbone model and patterns generated by a self-attention based explainable module. the representation weighted by patterns only includes a minimum number of distinguishable features and the visualized patterns can serve as an informative hint on the transferred knowledge. on three mainstream datasets, experimental results prove that the proposed method can enable satisfying explainability and achieve high classification results. code is available at https://github.com/wbw520/mtunet.",AB_0056
"in the process of making a movie, directors constantly care about where the spectator will look on the screen. shot composition, framing, camera movements, or editing are tools commonly used to direct attention. in order to provide a quantitative analysis of the relationship between those tools and gaze patterns, we propose a new eye-tracking database, containing gaze-pattern information on movie sequences, as well as editing annotations, and we show how state-of-the-art computational saliency techniques behave on this dataset. in this work, we expose strong links between movie editing and spectators gaze distributions, and open several leads on how the knowledge of editing information could improve human visual attention modeling for cinematic content. the dataset generated and analyzed for this study is available at https://github.com/abruckert/eye_tracking_filmmaking",AB_0056

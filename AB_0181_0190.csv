AB,NO
"speech emotion recognition (ser) has become a crucial topic in the field of human-computer interactions. feature representation plays an important role in ser, but there are still many challenges in feature representation such as the inability to predict which features are most effective for ser and the cultural differences in emotion expression. most previous studies use a single type of feature for the recognition task or conduct early fusion of features. however, a single type of feature cannot well reflect the emotions of speech signals. also, different features contain different information, direct fusion cannot integrate the advantages of different features. to overcome these challenges, this paper proposes a parallel network for multi-scale ser based on a connection attention mechanism (amsnet). amsnet fuses fine-grained frame-level manual features with coarse-grained utterance-level deep features. meanwhile, it adopts different speech emotion feature extraction modules according to the temporal and spatial features of speech signals, which enriches features and improves feature characterization. the network consists of a frame-level representation learning module (frlm) based on the time structure and an utterance-level representation learning module (urlm) based on the global structure. besides, improved attention-based long short-term memory (lstm) is introduced into frlm to focus on the frames that contribute more to the final emotion recognition result. in urlm, a convolutional neural network with the squeeze-and-excitation block (scnn) is introduced to extract deep features. in addition, the connection attention mechanism is proposed for feature fusion, which applies different weights to different features. extensive experiments are conducted on the iemocap and emodb datasets, and the results demonstrate the effectiveness and performance superiority of amsnet. our code will be publicly available at https://codeocean.com/capsule/8636967/tree/v1.",AB_0019
"background early detection and prognosis prediction of colorectal cancer (crc) can significantly reduce crc-related mortality. recently, circulating tumour dna (ctdna) methylation has shown good application foreground in the early detection and prognosis prediction of multiple tumours. methods this multicentre cohort study evaluated ctdna methylation haplotype patterns based on archived plasma samples (collected between 2010 and 2018) from 1138 individuals at two medical centres: fudan university shanghai cancer center (shanghai, china) and southern medical university nanfang hospital (guangzhou, guangdong, china), including 366 healthy individuals, 182 patients with advanced adenoma (aa), and 590 patients with crc. samples were processed using the colones assay, a targeted bisulfite sequencing method that detects ctdna methylation haplotype patterns in 191 genomic regions. among these 1138 samples, 748 were used to develop a classification model, and 390 served as a blinded cohort for independent validation. the study is registered at https://register.clinicaltrials.gov with the unique identifier nct03737591. results the model obtained from unblinded samples discriminated patients with crc or aa from normal controls with high accuracy. in the blinded validation set, the colones assay achieved sensitivity values of 79.0% (95% confidence interval (ci), 66%-88%) in aa patients and 86.6% (95% ci, 81%-91%) in crc patients with a specificity of 88.1% (95% ci, 81%-93%) in healthy individuals. the model area under the curve (auc) for the blinded validation set was 0.903 for aa samples and 0.937 for crc samples. additionally, the prognosis of patients with high preoperative ctdna methylation levels was worse than that of patients with low ctdna methylation levels (p = 0.001 for relapse-free survival and p = 0.004 for overall survival). interpretation we successfully developed and validated an accurate, noninvasive detection method based on ctdna methylation haplotype patterns that may enable early detection and prognosis prediction for crc. copyright (c) 2022 the author(s). published by elsevier ltd.",AB_0019
"recently, a particular type of image-text retrieval task named ternary image-text retrieval (titr) has drawn increasing attention. in this task, the total inputs of query and target consist of three components, rather than two inputs in the widely-studied retrieval case. the typical titr scenarios include recipe retrieval (e.g., ingredients text, instructions text and food images) and fashion search (e.g., original images, text and modified images). a few recently proposed titr methods mainly focus on learning the semantic correlations of two modality data by projecting them to the same embedding space to capture the alignment between image and text modalities. nevertheless, two limitations still exist in these methods: 1) the underlying difference between data in the same modality (e.g., ingredients and instructions) is neglected; and 2) the trilinear interaction among the three inputs is implicitly captured. to this end, we propose a novel fusion framework named trilinear fusion network (tfun) to utilize high-level associations between these three inputs simultaneously and learn an accurate cross-modal similarity function via bi-directional triplet loss explicitly, which is generic for the titr task. to reduce the model complexity, we introduce the advanced method of tensor decomposition to ensure computational efficiency and accessibility. we also develop a three-stage hard triplet sampling scheme to ensure fast convergence. extensive experiments on three large-scale titr datasets recipe1m, fashion200k and fashioniq demonstrate the superiority of our proposed tfun model compared to the state-of-the-art approaches. the implementation code and additional instructions are provided at https://github.com/cfm-msg/code_tfun.",AB_0019
"nonlinear model predictive control (nmpc) solves a series of optimization problems online during the entire operational time of the controlled plant, and the performance of nmpc depends on the superiority of the solver embedded in nmpc. traditionally, gradient-based deterministic methods are used as nmpc solvers, but meta -heuristics are now becoming more and more popular for its ability to find the global optimal solution. in order to verify the superiorities of different algorithms to be nmpc solvers, a novel nmpc problem generator named nmpc-based gkls generator (n-gkls) is proposed. with the help of optimal-replace method (orm), a reliable comparison of the closed-loop performances result from receding horizon strategy in nmpc is guaranteed. in addition, comparison techniques named accumulated operational characteristic and accumulated operational zone are proposed to directly compare different optimization algorithms for solving various nmpc problems generated by n-gkls. an auxiliary comparison table is also proposed to report numerical comparative results. in this way, n-gkls is not only an nmpc problem generator, but also a test platform for verifying the superiorities of different algorithms as nmpc solvers. finally, simulation results based on 8 metaheuristics and 3 deterministic methods are used to illustrate the effectiveness of the proposed n-gkls. a corresponding matlab app demo is designed and is available online: https://github.com/jiahongxu123/n-gkls.",AB_0019
"covid-19 is pervasive and threatens the safety of people around the world. therefore, now, a method is needed to diagnose covid-19 accurately. the identification of covid-19 by x-ray images is a common method. the target area is extracted from the x-ray images by image segmentation to improve classification efficiency and help doctors make a diagnosis. in this paper, we propose an improved crow search algorithm (csa) based on variable neighborhood descent (vnd) and information exchange mutation (iem) strategies, called vmcsa. the original csa quickly falls into the local optimum, and the possibility of finding the best solution is significantly reduced. therefore, to help the algorithm avoid falling into local optimality and improve the global search capability of the algorithm, we introduce vnd and iem into csa. comparative experiments are conducted at cec2014 and cec'21 to demonstrate the better performance of the proposed algorithm in optimization. we also apply the proposed algorithm to multi-level thresholding image segmentation using renyi's entropy as the objective function to find the optimal threshold, where we construct 2-d histograms with grayscale images and non-local mean images and maximize the renyi's entropy on top of the 2-d histogram. the proposed segmen-tation method is evaluated on x-ray images of covid-19 and compared with some algorithms. vmcsa has a significant advantage in segmentation results and obtains better robustness than other algorithms. the available extra info can be found at https://github.com/1234zsw/vmcsa.",AB_0019
"text. in this paper we will consider the kohnen plus space for hilbert-siegel-jacobi forms of half-integral weight and certain type of matrix index. as in the case of classical modular forms, the jacobi forms in the kohnen plus space are characterized by some restrictions on their fourier coefficients. we will show that a jacobi form of half-integral weight is in the kohnen plus space if and only if the representation, which is generated by the form, of the adelic metaplectic double covering of the jacobi group is equivalent to the weil representation and use this equivalence condition to give an isomorphism of the kohnen plus space with the space of jacobi forms of certain corresponding integral weight and matrix index. finally, we will see that the given isomorphism is a hecke isomorphism with respect to the odd places of the underlying totally real number field. video. for a video summary of this paper, please visit https://youtu .be /j88aholr0gi.(c) 2022 published by elsevier inc.",AB_0019
"amflow is a mathematica package to numerically compute dimensionally regularized feynman integrals via the recently proposed auxiliary mass flow method. in this framework, integrals are treated as functions of an auxiliary mass parameter and their results can be obtained by constructing and solving linear differential systems with respect to this parameter, in an automatic way. the usage of this package is described in detail through an explicit example of double-box family involved in two-loop tt hadroproduction. program summary program title: amflow cpc library link to program files: https://doi.org/10.17632/nrkrw83bw5.1 developer's repository link: https://gitlab.com/multiloop-pku/amflow licensing provisions: mit programming language: wolfram mathematica 11.3 or higher external routines: wolfram mathematica[1], finiteflow[2], litered[3], kira[4], fire[5] nature of problem: automatically obtaining high-precision numerical results for dimensionally regularized feynman integrals at arbitrary points in phase-space. solution method: the program implements recently proposed auxiliary mass flow method, which introduces an auxiliary mass parameter to feynman integrals and solves differential equations with respect to this parameter to obtain physical results. references [1] http://www.wolfram.com/mathematica, commercial algebraic software. [2] https://github.com/peraro/finiteflow, open source. [3] http://www.inp.nsk.su/similar to lee/programs/litered, open source. [4] https://gitlab.com/kira-pyred/kira, open source. [5] https://bitbucket.org/feynmanintegrals/fire, open source. (c) 2022 the author(s). published by elsevier b.v.",AB_0019
"the sine cosine algorithm (sca) is a well-known meta-heuristic optimization algorithm. sca has received much attention in various optimization fields due to its simple structure and excellent optimization capabilities. however, the dimension of objective function also increases with the increasing complexity of optimization tasks. this makes the original sca appear to have insufficient optimization capability and likely to fall into premature convergence. a multi-mechanism acting variant of sca, called arsca, is proposed to address the above deficiencies. arsca is an enhanced sca algorithm based on the adaptive quadratic interpolation mechanism (aqim) and rounding mechanism (rm). rm enables a more balanced state between exploration and exploitation of the arsca. aqim enhances local exploitation capabilities. to verify the performance of arsca, we compared arsca with some advanced traditional optimization algorithms and variants of algorithms for 30 consecutive benchmark functions of ieee cec2014. in addition, arsca was applied to 6 constrained engineering optimization problems. these six algorithms include the tension-compression spring design problem, the welded beam design problem, the pressure vessel design problem, the i-beam design problem, the speed reducer design problem, and the three-bar design problem. experimental results show that arsca outperforms its competitors in both the solution quality and the ability to jump out of the local optimum. the relevant codes for the paper are publicly available at https://github.com/yangxiao9799/paper_arsca.",AB_0019
"conversational recommender systems (crs) aim to provide high-quality recommendations through fewer multiturn conversations. however, because short conversation histories lack sufficient item information, crss not only struggle to make accurate recommendations but also lack diversity in the generated responses. existing crss mainly alleviate these problems by introducing external information (e.g., reviews) while ignoring information inside the conversations (e.g., potential category preferences in user utterances). besides, item introduction is a kind of external information that is more objective and contains more entities than reviews. therefore, we propose a multi-information augmented conversational recommender (macr), which improves the performance of recommendation and response generation by mining the underlying category preferences in users' utterances and incorporating item introductions. specifically, we enhance the category associations among entities by constructing a knowledge graph dbmg with category nodes, extracting and encoding the item categories that match the user preferences into the user representation. for item introductions, we extract the entities in them and fuse them into the conversation using an introduction-attentive encoder-decoder. extensive experiments on the dataset redial show that our macr significantly outperforms previous state-of-the-art approaches. the source code will be available at https://github.com/zcy-cqut/macr.",AB_0019
"most existing methods mainly input images into a cnn backbone to obtain image features. however, compared with convolutional features, the recently emerging transformer features can more accurately express the meaningful features of images. in this paper, we use a transformer backbone to capture multiple feature layers of an image, and design an object localization and edge refinement (oler) network for saliency detection. our network is divided into two stages, the first stage for object positioning and the second stage for refining their boundaries. in the first stage, we directly apply multiple feature layers to identify salient regions, where we design an information multiple selection (ims) module to capture saliency cues for each feature layer. the ims module contains multiple pathways, each of which is a judgment of the location of saliency information. after the input feature layer is processed by the ims module, its potential salient object information is mined. the second stage consists of two modules, namely the edge generation module and the edge refinement module. the edge generation module takes the original image and saliency map as inputs, and then outputs two edge maps focusing on different edge ranges. to make the object edges sharp, the original image, initial saliency map and two edge maps are fed into the edge refinement module, and the final saliency map is output. our network as a whole is relatively simple and easy to build without involving complex components. experimental results on five public datasets demonstrate that our method has tremendous advantages in terms of not only significantly improving detection accuracy, but also achieving better detection efficiency. the code is available at https://github.com/ckyiu/oler.",AB_0019

AB,NO
"in recent days, due to the emergence of communicable infectious diseases, healthcare, and medical technologies are expected to play a critical role. the advancement of communication and sensor network technologies has accelerated mass screening systems to combat the disease. human temperature detection is one of the measurements for crowd screening in public places. nevertheless, it is challenging to design a fast, lightweight, and easy-to-deploy contact-less crowd screening system in the outdoor environment due to several factors, such as environmental effect, background temperature, deployment cost, and remote operation. the state-of-the-art is mainly based on either hand-held devices or high-cost infrared cameras in only designated places. this article presents an end-to-end contactless assistive method for human body temperature screening systems, starting from collecting raw temperature data using a thermal camera to identify the suspected individual for combating communicable infectious diseases. we leverage the computing, storage, and communication resources offered by edge computing. in particular, we deploy a lightweight version of mobilenet v2 in resource-constrained raspberry pi 4b to detect the human's head and body from the thermal image and use a classifier to determine the temperature from the raw temperature data. moreover, we leverage a low-power and long-range wireless network for the exchange of model parameters between raspberry pi and the remote server. the experiments show that although the detection accuracy is not very high, we can reduce the bottleneck from screening time and reduce the exposure for the individuals because of the reduced bottleneck. our proposed solution is implemented in python and is available under the open-source mit license at https://github.com/mitunhub/hawk-i.",AB_0321
"deep semantic matching aims at discriminating the relationship between documents based on deep neural networks. in recent years, it becomes increasingly popular to organize documents with a graph structure, then leverage both the intrinsic document features and the extrinsic neighbor features to derive discrimination. most of the existing works mainly care about how to utilize the presented neighbors, whereas limited effort is made to filter appropriate neighbors. we argue that the neighbor features could be highly noisy and partially useful. thus, a lack of effective neighbor selection will not only incur a great deal of unnecessary computation cost but also restrict the matching accuracy severely. in this work, we propose a novel framework, cascaded deep semantic matching (cdsm), for accurate and efficient semantic matching on textual graphs. cdsm is highlighted for its two-stage workflow. in the first stage, a lightweight cnn-based ad-hod neighbor selector is deployed to filter useful neighbors for the matching task with a small computation cost. we design both one-step and multi-step selection methods. in the second stage, a high-capacity graph-based matching network is employed to compute fine-grained relevance scores based on the well-selected neighbors. it is worth noting that cdsm is a generic framework which accommodates most of the mainstream graph-based semantic matching networks. the major challenge is how the selector can learn to discriminate the neighbors' usefulness which has no explicit labels. to cope with this problem, we design a weak-supervision strategy for optimization, where we train the graph-based matching network at first and then the ad-hoc neighbor selector is learned on top of the annotations from the matching network. we conduct extensive experiments with three large-scale datasets, showing that cdsm notably improves the semantic matching accuracy and efficiency thanks to the selection of high-quality neighbors. the source code is released at https://github.com/jingjyyao/cdsm.",AB_0321
"unsupervised domain adaptation (uda) enables knowledge transfer from a labeled source domain to an unlabeled target domain by reducing the cross-domain distribution discrepancy, and the adversarial learning based paradigm has achieved remarkable success. on top of the derived domain-invariant feature representations, a promising stream of recent works seeks to further regularize the classification decision boundary via self-training to learn target adaptive classifier with pseudo-labeled target samples. however, since the pseudo labels are inevitably noisy, most of prior methods focus on manually designing elaborate target selection algorithms or optimization objectives to combat the negative effect caused by the incorrect pseudo labels. different from them, in this paper, we propose a simple and powerful meta-learning based target-reweighting regularization algorithm, called metareg, which regularizes the model training by learning to reweight the noisy pseudo-labeled target samples. specifically, metareg is motivated by the intuition that an ideal target classifier trained on correct target pseudo labels should make small classification errors on target-like source samples. therefore, we explicitly define a meta reweighting problem that aims to find the optimal weights for different target pseudo labels by minimizing the classification loss on a designed validation set, a class-balanced set consisting of source samples that are most similar to target ones. note that the optimization problem can be solved efficiently with a simplified approximation technique. as a result, the automatically learned optimal weights are utilized to reweight pseudo-labeled target samples, and regularize the model learning by target supervision with the learned different importance. comprehensive experiments on several cross-domain image and text datasets verify that metareg could outperform the non-regularized uda counterparts with state-of-the-art performance. code is available at https://github.com/bit-da/metareg.",AB_0321
"bundle recommendation aims to recommend a bundle of items for a user to consume as a whole. related work can be divided into two categories: 1) to recommend the platform's prebuilt bundles to users; 2) generate personalized bundles for users. in this work, we propose two graph neural network models, a bgcn model (short for bundle graph convolutional network) for prebuilt bundle recommendation, and a bggn model (short for bundle graph generation network) for personalized bundle generation. first, bgcn unifies the user-item interaction, the user-bundle interaction and the bundle-item affiliation into a heterogeneous graph. with item nodes as the bridge, graph convolutional propagation between user and bundle nodes makes the learned representations capture the item-level semantics. second, bggn re-constructs bundles into graphs based on the item co-occurrence pattern and the user's supervision signal. the complex and high-order item-item relationships in the bundle graph are explicitly modeled through graph generation. empirical results demonstrate the substantial performance gains of bgcn and bggn, which outperforms the state-of-the-art baselines by 10.77% to 23.18% and 20.90% to 64.52%, respectively. we have released the datasets and codes at this link: https://github.com/cjx0525/bgcn.",AB_0321
"motorcycles are one of the most important means of transportation. for traffic safety, most countries require drivers to pass the motorcycle driving license test (mdlt). the traditional mdlt relies on manual assessment, leading to expensive labor costs, inconsistent test standards, and unsupervised processes. therefore, the intelligent mdlt for automatic assessment becomes an urgent need. this paper proposes a collision recognition method using semantic segmentation for motorcycle slalom through poles in the intelligent mdlt. the method identifies the pole and calculates the pole angle change according to the real-time video provided by the on-site camera. a collision between the motorcycle and the pole is recognized when the pole angle change is larger than the preset value. specifically, we propose a fast flow alignment module (ffam) to improve the efficiency of the semantic segmentation network. then we build a lightweight semantic segmentation network using ffam. finally, we design a post-processing method to calculate the angle change value of the poles. extensive experiments on a newly collected dataset of slalom poles demonstrate that our proposed network achieves a state-of-the-art trade-off between segmentation accuracy and inference speed: 77.6% miou and 167 fps. moreover, our post-processing method can accurately identify the pole angle with an error within +/- 0.1 degrees. our method is an essential component of the intelligent mdlt, which is fast, accurate, and has been successfully applied in many cities. our video demo is shown at https://www.youtube.com/watch?v=gje3imne240.",AB_0321
"estimating the number of fries plays a critical role in the maintenance of fish breeding, transportation, and the preservation of marine resources in aquaculture. generally speaking, statistics are recorded manually by fishers and government units. manual recording is time-consuming and increases the workload of fishers. compared with traditional physical shunt devices, visual-based algorithms have benefits such as non-restriction of labors, minimal equipment installation, and maintenance costs. however, these methods generally come with massive calculations and model parameters, or poor abilities of aggregation handles and counting precision. this paper proposes a fry counting method named msenet for portable fry counting devices. firstly, the lightweight network is designed with simpler parameters (params: 139.46 kb) for portable embedding. the visualized single-channel fry density maps are predicted by feeding the original images and the number of fries is calculated through integration. then, the squeeze-and-excitation block is utilized to strengthen the features of weighty channels. the model training is refined by hyperparameter studies, the shortened preparation stage enhances the portability. what is more, a fry counting dataset ncauf and an extra set ncauf-ex are built for verifications of network generalization. the results demonstrate that the lightweight msenet outperforms in fry counting with higher precision and competently solves the issue of fry aggregation (mae: 3.33). the source code and pre-trained models are available at: https://github.com/vranlee/msenet. (c) 2023 elsevier b.v. all rights reserved.",AB_0321
"background: long non-coding rna (lncrna) is one of the most essential forms of transcripts, playing crucial regulatory roles in the development of cancers and diseases without protein-coding ability. it was assumed that short orfs (sorfs) in lncrna were weak to translate proteins. however, recent research has shown that sorfs can encode peptides, which increases the difficulty to identify lncrna. therefore, identifying lncrnas with sorfs facilitates finding novel regulatory factors. results: in this paper, we propose lnccat for identifying lncrna based on category boosting (catboost) and orf-attention features. lnccat combines five types of features to encode transcript sequences and employs catboost to build a prediction model. in addition, the visualization comparison reveals that the orf-at-tention features between lncrnas and protein-coding transcripts are significantly distinct. the comparison results show that lnccat outperforms competing methods on several benchmark datasets. for matthew's correlation coefficient (mcc), lnccat achieves 0.9503, 0.9219, 0.8591, 0.8672, and 0.9047 on the human, mouse, zebrafish, wheat, and chicken datasets, with improvements ranging from 1.90% to 7.82%, 1.49-17.63%, 6.11-21.50%, 3.02-51.64% and 5.35-26.90%, respectively. moreover, lnccat dramatically im-proves the mcc by at least 11.90%, 12.96% and 42.61% on sorf test datasets of human, mouse, and zebrafish, respectively. conclusions: experiments indicate that lnccat performs better both on long orf and sorf datasets, and orf-attention features show positive effects on predicting lncrna. in brief, lnccat is a reliable method for identifying lncrna. additionally, a user-friendly web server is developed for academics at http://cczu-bio.top/lnccat. (c) 2023 the author(s). published by elsevier b.v. on behalf of research network of computational and structural biotechnology. this is an open access article under the cc by-nc-nd license ().",AB_0321
"identifying the potential associations between microbes and diseases is the first step for revealing the pa-thological mechanisms of microbe-associated diseases. however, traditional culture-based microbial experi-ments are expensive and time-consuming. thus, it is critical to prioritize disease-associated microbes by computational methods for further experimental validation. in this study, we proposed a novel method called mnnmda, to predict microbe-disease associations (mdas) by applying a matrix nuclear norm method into known microbe and disease data. specifically, we first calculated gaussian interaction profile kernel similarity and functional similarity for diseases and microbes. then we constructed a heterogeneous information net -work by combining the integrated disease similarity network, the integrated microbe similarity network and the known microbe-disease bipartite network. finally, we formulated the microbe-disease association pre-diction problem as a low-rank matrix completion problem, which was solved by minimizing the nuclear norm of a matrix with a few regularization terms. we tested the performances of mnnmda in three datasets in-cluding hmdad, disbiome, and combined data with small, medium and large sizes respectively. we also compared mnnmda with 5 state-of-the-art methods including katzhmda, lrlshmda, ntshmda, gatmda, and kgnmda, respectively. mnnmda achieved area under the roc curves (auroc) of 0.9536 and 0.9364 respectively on hdmad and disbiome, better than the aucs of compared methods under the 5-fold cross-validation for all microbe-disease associations. it also obtained a relatively good performance with auroc 0.8858 in the combined data. in addition, mnnmda was also better than other methods in area under pre-cision and recall curve (aupr) under the 5-fold cross-validation for all associations, and in both auroc and aupr under the 5-fold cross-validation for diseases and the 5-fold cross-validation for microbes. finally, the case studies on colon cancer and inflammatory bowel disease (ibd) also validated the effectiveness of mnnmda. in conclusion, mnnmda is an effective method in predicting microbe-disease associations. availability: the codes and data for this paper are freely available at github https://github.com/haiyan-liu666/mnnmda.(c) 2022 published by elsevier b.v. on behalf of research network of computational and structural biotechnology. this is an open access article under the cc by-nc-nd license ( licenses/by-nc-nd/4.0/).",AB_0321
"feature engineering is an effective method for solving classification problems. many existing feature engineering studies have focused on image or video data and not on structured data. this study proposes evagonet, which refines the decoder module of the gaussian mixture variational autoencoder using the wasserstein generative adversarial network with gradient penalty (wgangp) and embeds the top-ranked original features to update the latent features based on their discriminative powers. comprehensive experiments show that evagonet-encoded features outperform existing classifiers on 12 benchmark datasets, particularly on the small, imbalanced datasets col (accuracy = 0.8581), spe (accuracy = 1.0000), and leu (accuracy = 0.8021). evagonet-engineered features improve binary classification task outcomes on six high -dimensional, imbalanced bioomic datasets. evagonet achieves a medium-ranked training speed among the compared algorithms and considerably fast prediction speeds in the predictions of the testing samples. therefore, evagonet can be a candidate feature engineering framework for many practical applications that require one training procedure and many prediction tasks of the testing samples. evagonet is implemented in python tensorflow and is available at https:// healthinformaticslab.org/supp/resources.php.",AB_0321
"many variant generative adversarial networks (gans) have been proposed to address the problem that models are difficult to be trained, such as a network-based model, loss-based method, and training-based technique. however, these models rarely improve training stability by reducing the instability of the generator and discriminator simultaneously. for this purpose, inspired by the idea of network regulation, we design an auxiliary adversarial example regulator and propose a new training framework of gans. in this method, to reduce the instability of the generator and discriminator simultaneously, we design a penalty to constrain directly and guide the generator to generate images, and gradually adjust the training of the discriminator by the auxiliary adversarial example regulator. with the designed constraint and discriminator, the generated image gets closer to the real image. finally, experimental results demonstrate that the proposed method outperforms the baseline models. the code is available at https://github.com/adleygan/gan-ae-p.(c) 2023 elsevier b.v. all rights reserved.",AB_0321

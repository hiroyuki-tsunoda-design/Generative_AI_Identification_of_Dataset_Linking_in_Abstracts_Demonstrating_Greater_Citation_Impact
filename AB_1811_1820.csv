AB,NO
"for image forensics, convolutional neural networks (cnns) tend to learn image content features rather than subtle manipulation traces, which constrains detection performance. existing works usually address this issue by following a common pipeline, namely subtracting the original pixel value from the predicted pixel value to enforce cnns to learn more features from the manipulation traces. however, due to the complicated learning mechanism, they might still have some unnecessary performance losses. in this work, we rethink the advantages of image gradient operator in exposing ai-enabled face forgeries, and design two plug-and-play modules, namely tensor pre-processing (tp) and manipulation trace attention (mta), by combining the gradient operator with cnns. specifically, the tp module refines the feature tensor of each channel in the network by the gradient operator to highlight manipulation traces and improve feature representation. moreover, the mta module considers two dimensions, namely channel and manipulation traces, to enforce the network to learn the distribution of the manipulation traces. both modules can be seamlessly integrated into existing cnns for end-to-end training. experiments show that the proposed expert system achieves better results than prior works on five public image datasets. the code is available at: https://github.com/ericgzq/gocnet-pytorch.",AB_0182
"the n-octanol/buffer solution distribution coefficient at ph = 7.4 (log d7.4) is an indicator of lipophilicity, and it influences a wide variety of absorption, distribution, metabolism, excretion, and toxicity (admet) properties and druggability of compounds. in log d7.4 prediction, graph neural networks (gnns) can uncover subtle structure-property relationships (sprs) by automatically extracting features from molecular graphs that facilitate the learning of sprs, but their performances are often limited by the small size of available datasets. herein, we present a transfer learning strategy called pretraining on computational data and then fine-tuning on experimental data (pcfe) to fully exploit the predictive potential of gnns. pcfe works by pretraining a gnn model on 1.71 million computational log d data (low-fidelity data) and then fine-tuning it on 19,155 experimental log d7.4 data (high-fidelity data). the experiments for three gnn architectures (graph convolutional network (gcn), graph attention network (gat), and attentive fp) demonstrated the effectiveness of pcfe in improving gnns for log d7.4 predictions. moreover, the optimal pcfe-trained gnn model (cx-attentive fp, rtest2 = 0.909) outperformed four excellent descriptor-based models (random forest (rf), gradient boosting (gb), support vector machine (svm), and extreme gradient boosting (xgboost)). the robustness of the cx-attentive fp model was also confirmed by evaluating the models with different training data sizes and dataset splitting strategies. therefore, we developed a webserver and defined the applicability domain for this model. the webserver (http://tools.scbdd.com/chemlogd/) provides free log d7.4 prediction services. in addition, the important descriptors for log d7.4 were detected by the shapley additive explanations (shap) method, and the most relevant substructures of log d7.4 were identified by the attention mechanism. finally, the matched molecular pair analysis (mmpa) was performed to summarize the contributions of common chemical substituents to log d7.4, including a variety of hydrocarbon groups, halogen groups, heteroatoms, and polar groups. in conclusion, we believe that the cx-attentive fp model can serve as a reliable tool to predict log d7.4 and hope that pretraining on low-fidelity data can help gnns make accurate predictions of other endpoints in drug discovery.",AB_0182
"alzheimer's disease (ad) is currently one of the mainstream senile diseases in the world. it is a key problem predicting the early stage of ad. low accuracy recognition of ad and high redundancy brain lesions are the main obstacles. traditionally, group lasso method can achieve good sparseness. but, redundancy inside group is ignored. this paper proposes an improved smooth classification framework which combines the weighted smooth gl112 (wsgl112) as feature selection method and a calibrated support vector machine (csvm) as the classifier. wsgl112 can make intra-group and inner-group features sparse, in which the group weights can further improve the efficiency of the model. csvm can enhance the speed and stability of model by adding calibrated hinge function. before feature selecting, an anatomical boundary-based clustering, called as ac-slic-aal, is designed to make adjacent similar voxels into one group for accommodating the overall differences of all data. the csvm model is fast convergence speed, high accuracy and good interpretability on ad classification, ad early diagnosis and mci transition prediction. in experiments, all steps are tested respectively, including classifiers' comparison, feature selection verification, generalization verification and comparing with state-of-the-art methods. the results are supportive and satisfactory. the superior of the proposed model are verified globally. at the same time, the algorithm can point out the important brain areas in the mri, which has important reference value for the doctor's predictive work. the source code and data is available at http://github.com/hu-s-h/c-svmformri.",AB_0182
"more than 95% of colorectal cancers are gradually transformed from polyps, so regular colonoscopy polyp examination plays an important role in cancer prevention and early treatment. however, automatic polyp segmentation remains a challenging task due to the low-contrast tissue environment and the small size and variety (e.g., shape, color, texture) of polyps. in this case, the rich context information in colonoscopy images is worth exploring to address the above issues. on the one hand, the image-level context with a global receptive field can be used to enhance the discrimination between the foreground and the background to alleviate the occult and indistinguishability of polyps in colonoscopy images. on the other hand, the surrounding-level context focused on the surrounding pathological region of the polyp has more detailed features that are beneficial for polyp segmentation. therefore, we propose a novel network named iscnet that aims to fuse image-level and surrounding-level context information for polyp segmentation. specifically, we first introduce the global-guided context aggregation (ggca) module to explicitly model the foreground and background of polyp segmentation through image-level context, thereby flexibly enhancing polyp-related features and suppressing background-related features. then, we design the diverse surrounding context focus (dscf) module to focus on the surrounding area of the polyp to extract diverse local contexts to refine the segmentation results. finally, we fuse the feature maps derived from these two modules so that our iscnet can enjoy the facilitation of both the image-level and surrounding-level context information. to verify the effectiveness of our method, we conduct comprehensive experimental evaluations on three challenging datasets. the quantitative and qualitative experimental results confirm that our iscnet outperforms current state-of-the-art methods by a large margin. our code is available at https://github.com/vvmedical/iscnet.",AB_0182
"breast dynamic contrast-enhanced magnetic resonance imaging (dce-mri) plays an important role in the screening and treatment evaluation of high-risk breast cancer. the segmentation of cancerous regions is an essential step for the comprehensive analysis of breast mri. nevertheless, automatic and robust segmentation is still very challenging because of the large differences of cancers in size, morphology, and intensity appearance. to alleviate these issues, we propose a simple yet effective two-stage approach, which simultaneously exploits pre-and post-contrast enhanced information to segment the breast cancer. in particular, we first offer a breast segmentation network to predict the breast region of interest (roi) and therefore excluding confounding information from thorax region in the whole mri scans. moreover, inspired by the radiologists' examination routine which takes full advantage of the mri sequences to make the diagnosis, we suggest a joint-phase attention network in order to mine both pre-and post-contrast representations for the segmentation of cancerous regions. the accuracy and generalizability of the proposed network is validated on our collected dce-mri dataset containing 550 subjects (with 748 biopsy-proven breast cancers) from 3 different centers (one as internal dataset and two as external datasets). the primary evaluation metrics are dice similarity coefficient (dice), jaccard index (jaccard), and average symmetric surface distance (assd). our network consistently achieves satisfactory segmentation results, by generating an average dice of 88.77%/82.77%/83.03%, jaccard of 81.27%/71.89%/73.23%, and assd of 2.21/3.63/2.69, on one internal and two external datasets, respec-tively. our method offers an effective cancer segmentation approach for the breast dce-mri examination. the code is publicly available at https://github.com/ryandok/jpa.",AB_0182
"this paper studies the problem of the polygonal mapping of buildings by tackling the issue of mask reversibility, which leads to a notable performance gap between the predicted masks and polygons from the learning-based methods. we addressed such an issue by exploiting the hierarchical supervision (of bottom-level vertices, mid-level line segments, and high-level regional masks) and proposed a novel interaction mechanism of feature embedding sourced from different levels of supervision signals to obtain reversible building masks for polygonal mapping of buildings. as a result, we show that the learned reversible building masks take all the merits of the advances of deep convolutional neural networks for high-performing polygonal mapping of buildings. in the experiments, we evaluated our method on four public benchmarks, including the aicrowd, open cities, shanghai, and inria datasets. on the aicrowd, open cities, and shanghai datasets, our proposed method obtains unanimous improvements on the metrics of ap, apboundary and polis by large margins. for the inria dataset, our proposed method also obtains very competitive results on the metrics of iou and accuracy. the models and source code are available at https://github.com/sarahwxu/hisup.",AB_0182
"every year, influenza spreads worldwide and burdens people's health substantially. we need a reliable model to help hospitals, pharmaceutical companies, and governments better prepare for influenza outbreaks in a timely manner. however, the domain knowledge for such public health events, such as the variable influenza seasonality and occasional pandemics, poses significant challenges in predicting influenza outbreaks. the existing methods use current and historical values in a user-defined time window as input to predict future values but lack considering the situations outside the window. to address these limitations, we proposed dynamic virtual graph significance networks (dvgsn). the graph-based algorithm can supervisedly and dynamically learn the implied knowledge from similar infection situationsin all the historical timepoints without the limitation of time window. furthermore, representation learning on the dynamic virtual graph can tackle the varied seasonality with pandemic-awareness without requiring domain knowledge input. the extensive experiments on real-world influenza data demonstrate that dvgsn significantly outperforms the state-of-the-art methods. to the best of our knowledge, this is the first attempt to supervisedly learn a dynamic virtual graph for time-series prediction tasks. moreover, the proposed method has rich interpretabilities, which makes the method more acceptable in the fields of public health, life sciences, and so on. our source code and dataset are available at https://github.com/ai-area/dvgsn.",AB_0182
"amyloid fibrils formed by the mis-aggregation of amyloid proteins can lead to neuronal degenerations in the alzheimer's disease. predicting amyloid proteins not only contributes to understanding physicochemical prop-erties and formation mechanism of amyloid proteins, but also has significant implications in the amyloid disease treatment and the development of a new purpose for amyloid materials. in this study, an ensemble learning model with sequence-derived features, ecamyloid, is proposed to identify amyloids. the sequence-derived features including pseudo position specificity score matrix (pse-pssm), split amino acid composition (saac), solvent accessibility (sa), and secondary structure information (ssi) are employed to incorporate sequence composition, evolutionary and structural information. the individual learners of the ensemble learning model are selected by an increment classifier selection strategy. the final prediction results are determined by voting of prediction results of multiple individual learners. in view of the imbalanced benchmark dataset, the synthetic minority over-sampling technique (smote) is adopted to generate positive samples. to eliminate irrelevant features and redundant features, correlation-based feature subset (cfs) selection combined with a heuristic search strategy is performed to obtain the optimal feature subset. experimental results indicate that the ensemble classifier achieves an accuracy of 98.29%, a sensitivity of 0.992, a specificity of 0.974 on the training dataset using the 10-fold cross validation, far higher than the results obtained by its individual learners. compared with the original feature set, the accuracy, sensitivity, specificity, mcc, f1-score, g-mean of the ensemble method trained by the optimal feature subset are improved by 1.05%, 0.012, 0.01, 0.021, 0.011 and 0.011, respectively. moreover, the comparison results with existing methods on two same independent test datasets demonstrate that the proposed method is an effective and promising predictor for large-scale deter-mination of amyloid proteins. the data and code used to develop ecamyloid has been shared to github, and can be freely downloaded at https://github.com/koala-l/ecamyloid.git.",AB_0182
"protein phosphorylation plays a vital role in signal transduction pathways and diverse cellular processes. to date, a tremendous number of in silico tools have been designed for phosphorylation site identification, but few of them are suitable for the identification of fungal phosphorylation sites. this largely hampers the functional investigation of fungal phosphorylation. in this paper, we present scerephosite, a machine learning method for fungal phosphorylation site identification. the sequence fragments are represented by hybrid physicochemical features, and then lgb-based feature importance combined with the sequential forward search method is used to choose the optimal feature subset. as a result, scerephosite surpasses current available tools and shown a more robust and balanced performance. furthermore, the impact and contribution of specific features on the model performance were investigated by shap values. we expect scerephosite to be a useful bioinformatics tool that complements hands-on experiments for the pre-screening of possible phosphorylation sites and facilitates our functional understanding of phosphorylation modification in fungi. the source code and datasets are accessible at https://github.com/wangchao-malab/scerephosite/.",AB_0182
"brain lesion segmentation provides a valuable tool for clinical diagnosis and research, and convolutional neural networks (cnns) have achieved unprecedented success in the segmentation task. data augmentation is a widely used strategy to improve the training of cnns. in particular, data augmentation approaches that mix pairs of an-notated training images have been developed. these methods are easy to implement and have achieved promising results in various image processing tasks. however, existing data augmentation approaches based on image mix-ing are not designed for brain lesions and may not perform well for brain lesion segmentation. thus, the design of this type of simple data augmentation method for brain lesion segmentation is still an open problem. in this work, we propose a simple yet effective data augmentation approach, dubbed as carvemix, for cnn-based brain lesion segmentation. like other mixing-based methods, carvemix stochastically combines two existing annotated images (annotated for brain lesions only) to obtain new labeled samples. to make our method more suitable for brain lesion segmentation, carvemix is lesion-aware, where the image combination is performed with a focus on the lesions and preserves the lesion information. specifically, from one annotated image we carve a region of in-terest (roi) according to the lesion location and geometry with a variable roi size. the carved roi then replaces the corresponding voxels in a second annotated image to synthesize new labeled images for network training, and additional harmonization steps are applied for heterogeneous data where the two annotated images can originate from different sources. besides, we further propose to model the mass effect that is unique to whole brain tumor segmentation during image mixing. to evaluate the proposed method, experiments were performed on multiple publicly available or private datasets, and the results show that our method improves the accuracy of brain lesion segmentation. the code of the proposed method is available at https://github.com/zhangxinrubit/carvemix.git .",AB_0182

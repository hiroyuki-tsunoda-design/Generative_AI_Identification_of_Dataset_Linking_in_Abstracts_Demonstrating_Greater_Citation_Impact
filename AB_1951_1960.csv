AB,NO
"accurate classification of surface defects is one of the most important factors in achieving quality inspection for strip steel. most existing methods are based on fully-supervised learning, which requires a large number of labeled training data samples. in the manufacturing process, collecting defective samples is time-consuming and laborious. so it is very difficult to train a fully supervised model based on few labeled samples. in this paper, we propose a feature-aware network (fanet) for a few shot defect classification, which can effectively distinguish new classes with a small number of labeled samples. in our proposed fanet, we use resnet12 as our baseline. the feature-attention convolution module (fac) is applied to extract the comprehensive feature information from the base classes, as well as to fuse semantic information by capturing the long-range feature relationships between the upper and lower layers. meanwhile, during the test phase, an online feature-enhance integration module (fei) is adopted to average the noise from the support set and query set defect images, further enhancing image features among the different tasks. in addition, we construct a large-scale strip steel surface defects few shot classification dataset (fsc-20) with 20 different types. experimental results show that the proposed method achieves the best performance compared to state-of-the-art methods for the 5-way 1-shot and 5-way 5-shot tasks. the dataset and code are available at: https://github.com/vdt-2048/fsc-20.",AB_0196
"modern gas chromatography-mass spectrometry (gc-ms) is the workhorse for the high-throughput profiling of volatile compounds in complex samples. it can produce a considerable amount of two-dimensional data, and automatic methods are required to distill chemical information from raw gc -ms data efficiently. in this study, we proposed an automatic resolution method (autores) based on pseudo-siamese convolutional neural networks (pscnn) to extract the meaningful features swamped by the noises, baseline drifts, retention time shifts, and overlapped peaks. two pscnn models were trained with 40 0,0 0 0 augmented spectral pairs, respectively. they can predict the selective region (pscnn1) and elution region (pscnn2) of compounds in an untargeted manner. the accuracies of the pscnn1 model and the pscnn2 model on their test sets are 99.9% and 92.6%, respectively. then, the chromatographic profile of each component was automatically resolved by full rank resolution (frr) based on the pre-dicted regions by these models. the performance of autores was evaluated on the simulated and plant essential oil datasets. compared to amdis and mzmine, autores resolves more reasonable mass spec-tra, chromatograms, and peak areas to identify and quantify compounds. the average match scores of autores (925 and 936) outperformed amdis (909 and 925) and mzmine (888 and 916) when resolving mass spectra from overlapped peaks on the set i and set ii of plant essential oil dataset and matching them against the nist17 library. it extracted peak areas and mass spectra automatically from 10 gc-ms files of plant essential oils, and the entire process was completed in 8 min without any prior informa-tion or manual intervention. it is implemented in python and is available as an open-source package at https://github.com/dyjfan/autores .(c) 2022 elsevier b.v. all rights reserved.",AB_0196
"oriented object detection in aerial images has received extensive attention due to its wide range of application scenarios. although great success has been achieved, current methods still suffer from inferior high-precision detection performance. firstly, the classification scores cannot truly represent the localization accuracy of the predictions. secondly, the orientation prediction in these detectors is not accurate enough for high-precision object detection. in this paper, we propose a task interleaving and orientation estimation detector (tioe-det) for high-quality oriented object detection in aerial images. specifically, a posterior hierarchical alignment (pha) label is proposed to optimize the detection pipeline. tioe-det adopts pha label to integrate fine-grained posterior localization guidance into classification task to address the misalignment between classification and localization subtasks. then, a balanced alignment loss is developed to solve the imbalance localization loss contribution in pha prediction. moreover, we propose a progressive orientation estimation (poe) strategy to approximate the orientation of objects with n-ary codes. on this basis, an angular deviation weighting strategy is proposed to achieve accurate evaluation of angle deviation in poe strategy. tioe-det achieves significant gains on high-precision detection performance. extensive experiments on multiple datasets prove the superiority of our approach. codes are available at https://github.com/ming71/tioe.",AB_0196
"with the rapid acquisition of remote sensing (rs) data, new categories of objects continue to emerge, and some categories can only obtain a few training samples. thus, few-shot class-incremental learning (fscil) has received intense attention in recent years. nevertheless, the existing fscil methods are difficult to adapt to rs characteristics with high inter-class similarity, large intra-class differences, and complex backgrounds. in this paper, we propose the fscil method called continual prototype calibration (cpc), which applies the decoupled learning strategy to cope with the demand to retrain the model when new few-shot categories appear. it can also address the tedious problems in fine-grained rs images by calibrating inter-class and intra-class prototypes. concretely, considering the severe issue of inter-class confusion, we introduce a prototype separability module (psm) to update the distribution of inter-class prototypes. in this way, we can distinguish different categories more clearly by weakening their similarities, and the phenomenon of catastrophic forgetting can also be effectively mitigated. furthermore, to generate more representative and accurate intra-class prototypes, we design a meta-network based on foreground enhancement mechanism (fem). the meta-network can boost the learning ability of the model for few-shot data and suppress the occurrence of overfitting by training on task-based data. and the fem enhances the object features by filtering out redundant background information, facilitating fine-grained classification. our cpc method is the first fscil method applied to optical rs images, and we verify its effectiveness on three datasets. extensive experiments illustrate that our method achieves state-of-the-art performance in fscil of fine-grained rs images. the code is available at https://github.com/ningerhhh/cpc.",AB_0196
"background this meta-analysis aimed to assess the efficacy of radiomics using non-enhanced computed tomography (ncct) for predicting hematoma expansion in patients with spontaneous intracerebral hemorrhage. methods throughout the inception of the project to april 11, 2022, a comprehensive search was conducted on pubmed, embase, and cochrane central register of controlled trials. the methodological quality of studies in this analysis was assessed by the radiomics quality scoring system (rqs). a meta-analysis of radiomic studies based on ncct for predicting hematoma expansion in patients with intracerebral hemorrhage was performed. the efficacy of the radiomics approach and non-contrast ct markers was compared using network meta-analysis (nma). results ten articles comprising a total of 1525 patients were quantitatively analyzed for hematoma expansion after cerebral hemorrhage using radiomics. based on the included studies, the mean rqs was 14.4. the auc value (95% confidence interval) of the radiomics model was 0.80 (0.76-0.83). five articles comprising 846 patients were included in the nma. the results synthesized according to bayesian nma revealed that the predictive ability of the radiomics model outperformed most of the ncct biomarkers. conclusions the ncct-based radiomics approach has the potential to predict hematoma expansion. compared to ncct biomarkers, we recommend a radiomics approach. standardization of the radiomics approach is required for further clinical implementation. systematic review registration https://www.crd.york.ac.uk/prospero/display_record.php?recordid=324034, identifier [crd42022324034].",AB_0196
"underwater images captured by an underwater camera normally suffer from visual degradation issues, such as color deviations, low contrasts, and detail blurs. existing studies tend to address these issues separately by individual techniques, such that underwater image visibility can hardly be improved in an overall, consistent manner. to address this limitation, we present a smart protocol for underwater image enhancement. the protocol comprises a comprehensive cascade of seven image enhancement techniques, i.e., attenuated channel compensation, white balance, tone mapping, hue-saturation-lightness (hsl) model-based saturation adjustment, contrast stretching, gamma correction, and high-pass fusion. the protocol is smartly configured by reinforcement learning. specifically, a set of underwater image multi-color space features are considered as a state, a set of parameter values for the protocol as an action, and an increment of a non-reference visual preference score as a reward. by the reinforcement learning strategy, the parameter values for the seven techniques in the protocol are optimally configured as a whole, resulting in optimal underwater image enhancement results. we refer to the functionality of the smart protocol as a meta underwater camera (muc) methodology because it operates behind an underwater camera's operation of capturing underwater images but provides underwater images of high visibility beyond those of low visibility originally obtained from the underwater camera. qualitative and quantitative empirical results validate that our muc methodology outperforms state-of-the-art underwater image enhancement methods. we release the reproducible code at https://gitee.com/wanghaoupc/muc_underwaterimageenhancement for public evaluations.",AB_0196
"this study focuses on the determination and validation of a new global mean sea surface (mss) model, named the shandong university of science and technology 2020 (sdust2020), with a grid size of 1 ' x1 '. this new model was established with a 19-year moving average method and fused multi-satellite altimetry data over a 27-year period (from january 1993 to december 2019). the data of haiyang-2a, jason-3, and sentinel-3a were first ingested in the sdust2020 mss but not in any other global mss model, such as the cls15 and dtu18 mss models. validations, including comparisons with the cls15 and dtu18 mss models, gps-leveled tide gauges, and altimeter data, were performed to evaluate the quality of the sdust2020 mss model, all of which showed that the sdust2020 mss model is accurate and reliable. the sdust2020 mss dataset is freely available at the site (data doi: https://doi.org/10.5281/zenodo.6555990, yuan et al., 2022).",AB_0196
"introduction: the value approximation bias is known to lead to suboptimal policies or catastrophic overestimation bias accumulation that prevent the agent from making the right decisions between exploration and exploitation. algorithms have been proposed to mitigate the above contradiction. however, we still lack an understanding of how the value bias impact performance and a method for efficient exploration while keeping stable updates. this study aims to clarify the effect of the value bias and improve the reinforcement learning algorithms to enhance sample efficiency. methods: this study designs a simple episodic tabular mdp to research value underestimation and overestimation in actor-critic methods. this study proposes a unified framework called realistic actor-critic (rac), which employs universal value function approximators (uvfa) to simultaneously learn policies with different value confidence-bound with the same neural network, each with a different under overestimation trade-off. results: this study highlights that agents could over-explore low-value states due to inflexible under-overestimation trade-off in the fixed hyperparameters setting, which is a particular form of the exploration-exploitation dilemma. and rac performs directed exploration without over-exploration using the upper bounds while still avoiding overestimation using the lower bounds. through carefully designed experiments, this study empirically verifies that rac achieves 10x sample efficiency and 25% performance improvement compared to soft actor-critic in the most challenging humanoid environment. all the source codes are available at https://github.com/ihuhuhu/rac. discussion: this research not only provides valuable insights for research on the exploration-exploitation trade-off by studying the frequency of policies access to low-value states under different value confidence-bounds guidance, but also proposes a new unified framework that can be combined with current actor-critic methods to improve sample efficiency in the continuous control domain.",AB_0196
"rna n4-acetylcytidine (ac4c) is the acetylation of cytidine at the nitrogen-4 position, which is a highly conserved rna modification and involves a variety of biological processes. hence, accurate identification of genome-wide ac4c sites is vital for understanding regulation mechanism of gene expression. in this work, a novel predictor, named irna-ac4c, was established to identify ac4c sites in human mrna based on three feature extraction methods, including nucleotide composition, nucleotide chemical property, and accumulated nucleo-tide frequency. subsequently, minimum-redundancy-maximum-relevance combined with incremental feature selection strategies was utilized to select the optimal feature subset. according to the optimal feature subset, the best ac4c classification model was trained by gradient boosting decision tree with 10-fold cross-validation. the results of independent testing set indicated that our proposed method could produce encouraging generalization capabilities. for the convenience of other researchers, we established a user-friendly web server which is freely available at http://lin-group.cn/server/irna-ac4c/. we hope that the tool could provide guide for wet-experimental scholars.",AB_0196
"fault diagnosis of the bearing is vital for the safe and reliable operation of rotating machines in the manufacturing industry. convolutional neural networks (cnns) have been popular in bearing fault diagnosis by right of robust and reliable feature extraction ability. however, the collected vibrational signals from machines are usually corrupted by unrelated noises due to complicated transfer path modulations and component coupling. as traditional cnn lacks the denoising structure, its capability of extracting features from vibrational features is restrained by noise disturbances. in response to the above issue, this paper first proposes a simple but efficient gramian-based noise reduction strategy called gramian noise reduction (gnr) based on the periodic self-similarity of vibrational signals. second, for the problem of lacking denoising structure in traditional cnns, a novel end-to-end gnr-based cnn model, termed as gramian time frequency enhancement network (gtfe-net), is presented for bearing fault diagnosis. the gtfe-net has three branches to parallelly process the raw original signal, the gnr denoised signal, and the frequency spectrums, respectively. gnr is integrated into the gtfe-net, prompting the network to pay more attention to feature extraction rather than noise suppression. three case studies using test rig and real engineering datasets are performed to verify the effectiveness of the proposed method for bearing fault diagnosis. the experimental results show that the gtfe-net can reduce the useless noises in vibrational signals and deliver a remarkable improvement in classification performance compared with the six state-of-the-art methods. the source code is available at https://github.com/shanespace/myresearchworkspublic/tree/main/my_own_publications",AB_0196

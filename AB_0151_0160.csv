AB,NO
"multi-focus image fusion (mff) is an effective way to eliminate the out-of-focus blur generated in the imaging process. the difficulties in distinguishing different blur levels and the lack of real supervised data make multi-focus image fusion remain a challenging task after decades of research. according to deep image prior (dip) (ulyanov et al., 2018), a neural network itself can capture the low-level statistics of a single image and is successfully used as a prior for solving many inverse problems without the need for handmade priors or priors learned from large-scale datasets. motivated by this idea, we propose a novel multi-focus image fusion framework named zmff comprised of a deep image prior network to model the deep prior of the fused image and a deep mask prior network to model the deep prior of the focus map corresponding to each source image. without the labor-intensive training pair collection, our method achieves zero-shot learning and avoids the domain shifting problem due to the inconsistency between the manually degraded multi-focus images and the real ones. as far as we know, it is the first unsupervised and untrained deep model for the mff task. extensive experiments on both synthetic and real-world datasets demonstrate the promising performance, generalization and flexibility of our approach. source code is available at https://github.com/junjun-jiang/zmff.",AB_0016
"remote sensing (rs) image scene classification has obtained increasing attention for its broad application prospects. conventional fully-supervised approaches usually require a large amount of manually-labeled data. as more and more rs images becoming available, how to make full use of these unlabeled data is becoming an urgent topic. semi-supervised learning, which uses a few labeled data to guide the self-training of numerous unlabeled data, is an intuitive strategy. however, it is hard to apply it to cross-dataset (i.e., cross-domain) scene classification due to the significant domain shift among different datasets. to this end, semi-supervised domain adaptation (ssda), which can reduce the domain shift and further transfer knowledge from a fully -labeled rs scene dataset (source domain) to a limited-labeled rs scene dataset (target domain), would be a feasible solution. in this paper, we propose an ssda method termed bidirectional sample-class alignment (bsca) for rs cross-domain scene classification. bsca consists of two alignment strategies, unsupervised alignment (ua) and supervised alignment (sa), both of which can contribute to decreasing domain shift. ua concentrates on reducing the distance of maximum mean discrepancy across domains, with no demand for class labels. in contrast, sa aims to achieve the distribution alignment both from source samples to the associate target class centers and from target samples to the associate source class centers, with awareness of their classes. to validate the effectiveness of the proposed method, extensive ablation, comparison, and visualization experiments are conducted on an rs-ssda benchmark built upon four widely-used rs scene classification datasets. experimental results indicate that in comparison with some state-of-the-art methods, our bsca achieves the superior cross-domain classification performance with compact feature representation and low-entropy classification boundary. our code will be available at https://github.com/hw2hwei/bsca.",AB_0016
"semantic face editing has achieved substantial progress in recent years. however, existing face editing methods, which often encode the entire image into a single code, still have difficulty in enabling flexible editing while keeping high-fidelity reconstruction. the one-code scheme also brings entangled face manipulations and limited flexibility in editing face components. in this paper, we present ia-faces, a bidirectional method for disentangled face attribute manipulation as well as flexible, controllable component editing. we propose to embed images onto two branches: one branch computes high-dimensional component-invariant content embedding for capturing face details, and the other provides low-dimensional component-specific embeddings for component manipulations. the two-branch scheme naturally enables high-quality facial component-level editing while keeping faithful reconstruction with details. moreover, we devise a component adaptive modulation (cam) module, which integrates component-specific guidance into the decoder and successfully disentangles highly-correlated face components. the single-eye editing is developed for the first time without editing face masks or sketches. according to the experimental results, ia-faces establishes a good balance between maintaining image details and performing flexible face manipulation. both quanti-tative and qualitative results indicate that the proposed method outperforms the existing methods in reconstruction, face attribute manipulation, and component transfer. we release the code and weights at: https://github.com/cmach508/ia-faces.(c) 2022 elsevier ltd. all rights reserved.",AB_0016
"liver segmentation is a critical step in liver cancer diagnosis and surgical planning. the u-net's architecture is one of the most efficient deep networks for medical image segmentation. however, the continuous down -sampling operators in u-net causes the loss of spatial information. to solve these problems, we propose a global context and hybrid attention network, called gcha-net, to adaptive capture the structural and detailed features. to capture the global features, a global attention module (gam) is designed to model the channel and positional dimensions of the interdependencies. to capture the local features, a feature aggregation module (fam) is designed, where a local attention module (lam) is proposed to capture the spatial information. lam can make our model focus on the local liver regions and suppress irrelevant information. the experimental results on the dataset lits2017 show that the dice per case (dpc) value and dice global (dg) value of liver were 96.5% and 96.9%, respectively. compared with the state-of-the-art models, our model has superior performance in liver segmentation. meanwhile, we test the experiment results on the 3dircadb dataset, and it shows our model can obtain the highest accuracy compared with the closely related models. from these results, it can been seen that the proposed model can effectively capture the global context information and build the correlation between different convolutional layers. the code is available at the website: https://github.com/huaxiangliu/gcau-net.",AB_0016
"motivation: protein structure prediction has been greatly improved by deep learning, but the contribution of different information is yet to be fully understood. this article studies the impacts of two kinds of information for structure prediction: template and multiple sequence alignment (msa) embedding. templates have been used by some methods before, such as alphafold2, rosettafold and raptorx. alphafold2 and rosetttafold only used templates detected by hhsearch, which may not perform very well on some targets. in addition, sequence embedding generated by pre-trained protein language models has not been fully explored for structure prediction. in this article, we study the impact of templates (including the number of templates, the template quality and how the templates are generated) on protein structure prediction accuracy, especially when the templates are detected by methods other than hhsearch. we also study the impact of sequence embedding (generated by msatransformer and esm-1b) on structure prediction. results: we have implemented a deep learning method for protein structure prediction that may take templates and msa embedding as extra inputs. we study the contribution of templates and msa embedding to structure prediction accuracy. our experimental results show that templates can improve structure prediction on 71 of 110 casp13 (13th critical assessment of structure prediction) targets and 47 of 91 casp14 targets, and templates are particularly useful for targets with similar templates. msa embedding can improve structure prediction on 63 of 91 casp14 (14th critical assessment of structure prediction) targets and 87 of 183 cameo targets and is particularly useful for proteins with shallow msas. when both templates and msa embedding are used, our method can predict correct folds (tmscore>0.5) for 16 of 23 casp14 fm targets and 14 of 18 continuous automated model evaluation (cameo) targets, outperforming rosettafold by 5% and 7%, respectively. availability and implementation : available at https://github.com/xluo233/raptorxfold. supplementary information: supplementary data are available at bioinformatics online.",AB_0016
"particle swarm optimization (pso) is a very simple and effective metaheuristic algorithm. search operators with similar behavior may lead to the loss of diversity in the search space. all particles in pso have the same and single search strategy. therefore, pso may suffer from premature convergence in solving complex multimodal problems. to improve the global search ability of pso, this paper reports an elite archives-driven particle swarm optimization (eapso). note that, eapso only needs population size and terminal condition for performing the search task, which can distinguish eapso over the other reported variants of pso. in addition, eapso has a clear structure, which first builds three types of elite archives to save three different hierarchical particles. then, six learning strategies for updating the positions of particles are designed by reusing these particles of the three elite archives. to verify the performance of eapso, eapso is employed to solve cec 2013 test suite with dimensions 30-100 and three constrained engineering problems. experimental results show that eapso outperforms the compared seven powerful variants of pso on more than half of test functions and offers highly competitive optimal solutions on the considered engineering problems. that is, experimental results support the validity of the improved strategies and prove the superiority of eapso in solving complex multimodal problems. the source code of eapso can be found by the following website: https://github.com/jsuzyy/eapso.",AB_0016
"image-based indoor localization provides fundamental support for applications such as indoor navigation, virtual reality, and location-based services. most research focuses on developing methods in good lighting conditions via rgb images; while for low lighting situations, especially at night, rgb-based methods cannot perform well. depth images are promising alternative in such conditions as they record geometrical information instead of texture information, making it possible to work in low lighting scenarios. current depth image -based methods, either retrieval-based methods or 3d registration-based methods, are inefficient due to its high computation overhead, preventing the wide applications. to address this issue, we propose a fast coarse -to-fine localization framework for dark environment via deep learning and keypoint-based geometry alignment. in the coarse localization phase, we jointly perform the depth completion and pose regression to relieve the occlusion caused appearance variance in depth images. in the refinement phase, keypoints are used instead of whole depth image points under the icp alignment framework to increase the localization efficiency. the keypoints are detected on depth feature maps weakly supervised with pose regression. the experiments on the open available 7scenes dataset show that the proposed method obtain positional accuracy of 0.143 m and orientational accuracy of 5.275 degrees in average and only cost 0.8s for a single depth image. the code for the proposed work is available at https://github.com/lqing900205/keypointdepthlocalization",AB_0016
"in this paper, we study the problem of traffic forecasting, which aims to predict the future traffic state of the road network. one key challenge is that the previous approaches lack discussion of capturing temporal dependencies, as well as spatial dependencies among locations in the traffic network. in addition, the long-term traffic prediction is not satisfied. in this paper, we propose a traffic dynamic graph model - tyre - which is composed of a graph convolutional network with gated and attention mechanisms. tyre can learn the 'importance' of all adjacent and distant locations, control the aggregation of adjacent and distant neighbourhood information, and learn the temporal dependencies to support long effective historical sizes. we demonstrate the validity and effectiveness of our approach on two different traffic datasets (i.e., pemsd4 and pemsd8). the result shows that compared to the related approaches, our model that captures temporal and spatial dependence yields substantially improved performance. when predicting traffic conditions for the next 120 min, on pemsd8 dataset, our model shows almost 6.6% rmse improvement, 10.9% mae improvement, and 2.1% mape improvement over the previous state of the art. all source codes of this work will be publicly available at https://github.com/wzhtxy/traffic-dynamic-graph-model",AB_0016
"the accurate extraction of building damage after destructive natural disasters is critical for disaster rescue and assessment. to achieve a rapid disaster response, training a model from scratch using enough ground-truth data collected in situ is not feasible. often, in disaster situations, it is ineffective to directly apply an existing model due to the vast diversity among buildings worldwide, the limited number of label samples for training, and the different sources of remote sensing images between the pre- and post-disaster. to solve this problem, we present an incremental learning framework for the rapid identification of collapsed buildings triggered by sudden natural disasters. specifically, end-to-end gradient boosting networks are improved into an incremental learning framework for an emergency response, where the historical natural disaster data are transferred into the same style of images that were captured shortly after a disaster event by using cycle-consistent generative adversarial networks. the proposed method is tested on two cases, i.e., the haiti earthquake in january 2010 and the nepal earthquake in april 2015, achieving kappa accuracies of 0.70 and 0.68, respectively. the optimization of building damage extraction can be completed within 8 h after the disaster using the transferred data. the experimental results show that the proposed method is an effective way to evaluate the building damage triggered by natural disasters with different source remote sensing images. the code of this work and the data of the test cases are available at https://github.com/gjy-ari/incre-trans.",AB_0016
"autonomous exploration is a technical challenge in the field of mobile robots. in this paper, the problem of autonomous unmanned ground vehicle (ugv) exploration is formulated as a continuous action planning process and a novel method to achieve real-time action planning in 3d spaces is proposed. first, a traversability map and reduced approximated generalized voronoi graph (ragvg) are introduced as grid and topological map models, respectively. then, an efficient and robust algorithm is presented for constructing ragvgs, and a three-stage approach for fast path search is proposed. furthermore, a fuzzy decision-making approach is employed to evaluate candidates and create action plans. the proposed method is tested in synthetic and real-world scenarios. the results of static experiments suggest that the ragvg can achieve almost full coverage with significantly less redundancy (50 % less vertexes and 23 % less edges); moreover, collision-free action plans can be created in real time (less than 330 ms). furthermore, the results of dynamic experiments indicate that the proposed method achieves effective, efficient, and stable performance with two exploration tasks in 3d spaces with static and moving obstacles, and it saves at least 10 % of the time required for full coverage exploration. the code related to this project is open-source and available at https://gitee.com/xinkaized/my_exploration.",AB_0016

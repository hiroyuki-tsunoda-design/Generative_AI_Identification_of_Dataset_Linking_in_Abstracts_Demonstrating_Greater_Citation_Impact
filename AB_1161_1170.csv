AB,NO
"a wireless sensor network assisted by multiple autonomous unmanned aerial vehicles (uavs) is a promising solution for harvesting data and monitoring the circumstance in various applications. however, the complicated path planning problem of each uav is still problematic. in this paper, we propose an optimal operation strategy based on multi-agent reinforcement learning (marl) to tackle these hurdles. various parameters such as the number of deployed uavs, charging start capacity, and charging complete capacity define a multi-uav system. this approach is applicable without a time-consuming and costly policy control. we also describe how to balance multiple objectives, such as data harvesting, charging, and collision avoidance, using transfer learning. finally, learning a policy control that generalizes multiple scenario parameters allows us to analyze the performance of individual parameters in a specific scenario, which helps find the macro-level optimal parameter within a particular scenario. videos are available at https://github.com/mincheolseong/ uav-trajectory-optimizer.",AB_0117
"weakly supervised object detection (wsod) has become a growing trend in remote sensing images (rsis) analysis, which aims to train an object detector given only image-level annotations (i.e., categories of existing objects in the given image), reducing the dependency on expensive object-level annotations. however, an object detector trained on such weak annotations is susceptible to the issues of background interference and missing detection due to the complex backgrounds and densely arranged objects of rsis. in this paper, we develop a novel multi-view noisy learning framework, named mol, to tackle the abovementioned problems, which consists of two sequential stages: reliable object discovery and progressive object mining. (i) in reliable object discovery, we formulate wsod as a multiple instance learning problem to discover potential objects in the given image, which process inevitably suffers background interference due to a lack of accurate supervision signal. to this end, we take inspiration from noisy learning theory and propose a temporal consistency -based instance selection strategy for discovering reliable foreground objects, reducing the risk of background interference. (ii) in progressive object mining, we serve the observed reliable objects as the initial pseudo -labels for building an object detector and propose a novel multi-view object mining strategy to progressively mine neglected objects from multiple distinct views, alleviating the missing detection issue. in this way, a well-trained object detector is obtained, which can achieve satisfactory performance in rsis. experimental results on two public benchmarks demonstrate that our method outperforms previous state-of-the-art methods by a large margin of 13.97% map and 1.69% map on nwpu vhr-10.v2 and dior, respectively. the code is available at: https://github.com/gc-wsl/mol.",AB_0117
"seung-hwa lee5,6,8,9* & kwangmo yang4,7,9* myocardial injury after non-cardiac surgery (mins) is strongly associated with postoperative outcomes. we developed a prediction model for mins and have provided it online. between january 2010 and june 2019, a total of 6811 patients underwent non-cardiac surgery with normal preoperative level of cardiac troponin (ctn). we used machine learning techniques with an extreme gradient boosting algorithm to evaluate the effects of variables on mins development. we generated two prediction models based on the top 12 and 6 variables. mins was observed in 1499 (22.0%) patients. the top 12 variables in descending order according to the effects on mins are preoperative ctn level, intraoperative inotropic drug infusion, operation duration, emergency operation, operation type, age, high-risk surgery, body mass index, chronic kidney disease, coronary artery disease, intraoperative red blood cell transfusion, and current alcoholic use. the prediction models are available at https:// sjshin. shiny apps. io/ mins_ occur_ predi ction/. the estimated thresholds were 0.47 in 12-variable models and 0.53 in 6-variable models. the areas under the receiver operating characteristic curves are 0.78 (95% confidence interval [ci] 0.77-0.78) and 0.77 (95% ci 0.77-0.78), respectively, with an accuracy of 0.97 for both models. using machine learning techniques, we demonstrated prediction models for mins. these models require further verification in other populations.",AB_0117
"training deep learning models on medical images heavily depends on experts' expensive and laborious manual labels. in addition, these images, labels, and even models themselves are not widely publicly accessible and suffer from various kinds of bias and imbalances. in this paper, chest x-ray pre-trained model via self-supervised contrastive learning (chess) was proposed to learn models with various representations in chest radiographs (cxrs). our contribution is a publicly accessible pretrained model trained with a 4.8-m cxr dataset using self-supervised learning with a contrastive learning and its validation with various kinds of downstream tasks including classification on the 6-class diseases in internal dataset, diseases classification in chexpert, bone suppression, and nodule generation. when compared to a scratch model, on the 6-class classification test dataset, we achieved 28.5% increase in accuracy. on the chexpert dataset, we achieved 1.3% increase in mean area under the receiver operating characteristic curve on the full dataset and 11.4% increase only using 1% data in stress test manner. on bone suppression with perceptual loss, we achieved improvement in peak signal to noise ratio from 34.99 to 37.77, structural similarity index measure from 0.976 to 0.977, and root-square-mean error from 4.410 to 3.301 when compared to imagenet pretrained model. finally, on nodule generation, we achieved improvement in frechet inception distance from 24.06 to 17.07. our study showed the decent transferability of chess weights. chess weights can help researchers overcome data imbalance, data shortage, and inaccessibility of medical image datasets. chess weight is available at https:// github. com/ mi2rl/ chess.",AB_0117
"the echo state network (esn) is a representative model for reservoir computing, which is capable of high-speed model training for machine learning tasks with time series data. extended models of the esn, such as multi-reservoir esns (mresns), have been intensively studied for performance improvement in recent years. in this study, we propose a new model called an hp-mresn by combining an mresn with the hodrick-prescott (hp) filter for nonlinear time series prediction. the proposed hp-mresn comprises three basic components: a time series decomposer, a reservoir state extractor, and an ensemble decoder. in the time series decomposer, we recursively leverage the hp filter to decompose original time-series data into multiple trend and cycle components. in the reservoir state extractor, each time series component is fed into a corresponding reservoir-state encoder for generating a reservoir state which is extracted as it is or through the principal component analysis. in the ensemble decoder, the states of multiple reservoirs are collected and processed to produce model outputs. moreover, we propose a greedy algorithm to automatically find the best model architectures under designated hyperparameters for different prediction tasks. experimental results on a total of 24 nonlinear time-series prediction tasks with 6 real-world datasets demonstrate that our proposed hp-mresn not only can outperform some existing representative mresn models and fully-trained rnn models but also can have relatively low training time. in addition, performance comparisons between the hp-mresn and related mresn models with other prepossessing methods show the benefit of time series decompositions using the hp filter. the codes of the proposed method are publicly available on https://github.com/ziqiang- ircn/hp-mresn. (c) 2023 the author(s). published by elsevier b.v. this is an open access article under the cc by license ().",AB_0117
"in this work, we investigate image registration in a variational framework and focus on regularization generality and solver efficiency. we first propose a variational model combining the state-of-the-art sum of absolute differences (sad) and a new arbitrary order total variation regularization term. the main advantage is that this variational model preserves discontinuities in the resultant deformation while be-ing robust to outlier noise. it is however non-trivial to optimize the model due to its non-convexity, non-differentiabilities, and generality in the derivative order. to tackle these, we propose to first apply linearization to the model to formulate a convex objective function and then break down the resultant convex optimization into several point-wise, closed-form subproblems using a fast, over-relaxed alternat-ing direction method of multipliers (admm). with this proposed algorithm, we show that solving higher -order variational formulations is similar to solving their lower-order counterparts. extensive experiments show that our admm is significantly more efficient than both the subgradient and primal-dual algorithms particularly when higher-order derivatives are used, and that our new models outperform state-of-the-art methods based on deep learning and free-form deformation. our code implemented in both matlab and pytorch is publicly available at https://github.com/j-duan/aotv.(c) 2023 the author(s). published by elsevier ltd. this is an open access article under the cc by license (  )",AB_0117
"metastatic progression and tumor evolution complicates the clinical management of cancer patients. circulating tumor cell (ctc) characterization is a growing discipline that aims to elucidate tumor metastasis and evolution processes. ctcs offer the clinical potential to monitor cancer patients for therapy response, disease relapse, and screen 'at risk' groups for the onset of malignancy. however, such clinical utility is currently limited to breast, prostate, and colorectal cancer patients. further understanding of the basic ctc biology of other malignancies is required to progress them towards clinical utility. unfortunately, such basic clinical research is often limited by restrictive characterization methods and high-cost barrier to entry for ctc isolation and imaging infrastructure. as experimental clinical results on applications of ctc are accumulating, it is becoming clear that a two-tier system of ctc isolation and characterization is required. the first tier is to facilitate basic research into ctc characterization. this basic research then informs a second tier specialised in clinical prognostic and diagnostic testing.this study presented in this manuscript describes the development and application of a lowcost, ctc isolation and characterization pipeline; ctc-5. this approach uses an established 'isolation by size' approach (screencell cyto) and combines histochemical morphology stains and multiparametric immunofluorescence on the same isolated ctcs. this enables capture and characterization of ctcs independent of biomarker-based pre-selection and accommodates both single ctcs and clusters of ctcs. additionally, the developed open-source software is provided to facilitate the synchronization of microscopy data from multiple sources (https://github.com/ ctc5/). this enables high parameter histochemical and immunofluorescent analysis of ctcs with existing microscopy infrastructure without investment in ctc specific imaging hardware.our approach confirmed by the number of successful tests represents a potential major advance towards highly accessible low-cost technology aiming at the basic research tier of ctc isolation and characterization. the biomarker independent approach facilitates closing the gap between malignancies with poorly, and well-defined ctc phenotypes. as is currently the case for some of the most commonly occurring breast, prostate and colorectal cancers, such advances will ulti-mately benefit the patient, as early detection of relapse or onset of malignancy strongly correlates with their prognosis.",AB_0117
"background: single-cell rna sequencing (scrna-seq) methods have been advantageous for quantifying cell-to-cell variation by profiling the transcriptomes of individual cells. for scrna-seq data, variability in gene expression reflects the degree of variation in gene expression from one cell to another. analyses that focus on cell-cell variability therefore are useful for going beyond changes based on average expression and, instead, identifying genes with homogeneous expression versus those that vary widely from cell to cell. results: we present a novel statistical framework, scshapes, for identifying differential distributions in single-cell rna-sequencing data using generalized linear models. most approaches for differential gene expression detect shifts in the mean value. however, as single-cell data are driven by overdispersion and dropouts, moving beyond means and using distributions that can handle excess zeros is critical. scshapes quantifies gene-specific cell-to-cell variability by testing for differences in the expression distribution while flexibly adjusting for covariates if required. we demonstrate that scshapes identifies subtle variations that are independent of altered mean expression and detects biologically relevant genes that were not discovered through standard approaches. conclusions: this analysis also draws attention to genes that switch distribution shapes from a unimodal distribution to a zero-inflated distribution and raises open questions about the plausible biological mechanisms that may give rise to this, such as transcriptional bursting. overall, the results from scshapes help to expand our understanding of the role that gene expression plays in the transcriptional regulation of a specific perturbation or cellular phenotype. our framework scshapes is incorporated into a bioconductor r package (https://www.bioconductor.org/packages/release/bioc/html/scshapes.html).",AB_0117
"objectives: the primary endpoint of the pivotal phase iii study of infliximab (ifx) s.c. demonstrated non-inferiority of s.c. to i.v. ifx, based on 28joint das-crp (das28-crp) improvement at week (w) 22 (nct03147248). this post-hoc analysis investigated whether numerical differences in efficacy outcomes at w30/54 were statistically significant, using conservative imputation methods. methods: patients with active ra and inadequate response to mtx received ifx i.v. 3 mg/kg at w0 and w2 (induction) and were randomized (1:1) to ifx s.c. 120mg every 2 weeks or i.v. 3 mg/kg every 8 weeks thereafter (maintenance). patients randomized to ifx i.v. switched to ifx s.c. from w30-54. this post-hoc analysis compared efficacy outcomes for s.c. and i.v. groups pre-switch (w30) and post-switch (w54) using last observation carried forward (locf) and non-responder imputation (nri) methods. results: of 343 randomized patients, 165 (ifx s.c.) and 174 (ifx i.v.) were analysed. at w30, significantly improved outcomes were identified with s.c. vs i.v. ifx for das28-crp/das28-esr/clinical disease activity index (cdai)/simplified disease activity index (sdai) scores (locf); acr/good eular responses, das28-crp/boolean remission, and das28-crp/das28-esr/cdai/sdai low disease activity and remission (locf and/or nri); and minimal clinically important difference in haq score (locf and nri). after switching to ifx s.c. from ifx i.v., fewer significant between-group differences were identified at w54. conclusion: ifx s.c. showed improved efficacy at w30 compared with ifx i.v., and the reduced between-group difference in efficacy outcomes at w54 after switching supports the results suggesting benefits of ifx s.c. compared with ifx i.v. at w30. trial registration: clincialtrials.gov, http://clinicaltrials.gov, nct03147248, https://clinicaltrials.gov/ct2/show/nct03147248.",AB_0117
"motivation: samstat is an efficient program to extract quality control metrics from fastq and sam/bam files. a distinguishing feature is that it displays sequence composition, base quality composition and mapping error profiles split by mapping quality. this allows users to rapidly identify reasons for poor mapping including the presence of untrimmed adapters or poor sequencing quality at individual read positions. results: here, we present a major update to samstat. the new version now supports paired-end and long-read data. quality control plots are drawn using the ploty javascript library. availability and implementation: the source code of samstat and code to reproduce the results are found here: https://github.com/timolassmann/samstat. contact: timolassmann@icloud.com",AB_0117

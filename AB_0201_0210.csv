AB,NO
"the super-resolution task about the single facial image is the specific task in single image super-resolution (sisr), which has attracted much attention from researchers. various facial sisr methods based on deep learning have achieved excellent performance. unfortunately, most existing methods perform poorly for generating the sr image with large upsampling factors when the input image has a lower resolution. to break the above limitations, we propose a two-stage cascade network (tscnet) under an end-to-end manner to reconstruct sr face image with large upsampling factors. the coarse sr facial image with middle magnification is generated at the first stage while the final sr facial image is obtained at the second stage by concatenating the coarse sr image and the upsampling result of the input image. in particular, inspired by the physical model of image restoration, the blurry kernel predicted (bkp) module within the improved residual block (imrb) is designed to transform useful intermediate features during each stage by combining the edge feature extracted from the coarse face image. furthermore, we also design a self-attention u-net (saunet) to extract the correct edge feature of the coarse face image. compared with the state-of-the-art methods, the proposed method improves the visual value by about 1.4% lpips on the test data. expanded experiments demonstrate that the proposed method performs well in quantitative and qualitative evaluations when generating the facial sr image with size 256 x 256 from the lr image with size 16 x 16. the code is released in . https://github.com/andyyu001/mtap_sr.",AB_0021
"we propose a manager-worker framework (the implementation of our model is publically available at: https://github.com/zcaicaros/manager-worker-mtsptwr) based on deep reinforcement learning to tackle a hard yet nontrivial variant of travelling salesman problem (tsp), i.e. multiple-vehicle tsp with time window and rejections (mtsptwr), where customers who cannot be served before the deadline are subject to rejections. particularly, in the proposed framework, a manager agent learns to divide mtsptwr into sub-routing tasks by assigning customers to each vehicle via a graph isomorphism network (gin) based policy network. a worker agent learns to solve sub-routing tasks by minimizing the cost in terms of both tour length and rejection rate for each vehicle, the maximum of which is then fed back to the manager agent to learn better assignments. experimental results demonstrate that the proposed framework outperforms strong baselines in terms of higher solution quality and shorter computation time. more importantly, the trained agents also achieve competitive performance for solving unseen larger instances.",AB_0021
"in medical image segmentation tasks, fully-supervised learning has been a huge success by using abundant labeled data. however, it is time-consuming and expensive for technicians to label medical images. in this paper, we propose a novel framework for semi-supervised medical image segmentation, named uncertainty -aware pseudo-label and consistency. our framework is made up of the student-teacher models. the supervised loss on labeled data and the consistency loss on both labeled and unlabeled data are weighted and combined to optimize the models. our method combines the recent state-of-the-art semi-supervised methods, which are consistency regularization and pseudo-labeling. more importantly, we calculate the kullback-leibler variance between the student model's prediction and the teacher model's prediction as uncertainty estimation, and directly use the uncertainty to rectify the learning of noisy pseudo-labels, instead of setting a fixed threshold to filter the pseudo-labels. experiments on the left atrium dataset show that our method can efficiently utilize unlabeled data to achieve high performance and outperform other state-of-the-art semi-supervised methods. in addition, we have also analyzed its difference from conventional methods of consistency regularization and pseudo-labeling in semi-supervised medical image segmentation. code is available in https://github.com/gxu-gmu-miccai/upc-pytorch.",AB_0021
"we introduce deepks-kit, an open-source software package for developing machine learning based energy and density functional models. deepks-kit is interfaced with pytorch, an open-source machine learning library, and pyscf, an ab initio computational chemistry program that provides simple and customized tools for developing quantum chemistry codes. it supports the deephf and deepks methods. in addition to explaining the details in the methodology and the software, we also provide an example of developing a chemically accurate model for water clusters. program summary program title: deepks-kit cpc library link to program files: https://doi .org /10 .17632 /x54bnz5vxk.1 developer's repository link: https://github .com /deepmodeling /deepks-kit licensing provisions: lgpl programming language: python nature of problem: modeling the energy and density functional in electronic structure problems with high accuracy by neural network models. solving electronic ground state energy and charge density using the learned model. solution method: deephs and deepks methods are implemented, interfaced with pytorch and pyscf for neural network training and self-consistent field calculations. an iterative learning procedure is included to train the model self-consistently. (c) 2022 published by elsevier b.v.",AB_0021
"large dof (depth-of-field) imaging with high snr (signal-noise-ratio) is useful for applications such as machine vision and medical imaging. in traditional optical systems, dof extension is always implemented at the cost of snr. in this paper, we present a mpcam (multi-psf camera) system highly integrated with af (auto-focus) function to realize both large dof and high snr imaging. mpcam based on mpgan (multi-psf generative adversarial network) is first proposed to automatically extract multiple psfs (point spread functions) and realize high fidelity image reconstruction by features fusion. the proposed end-to-end generative image fusion network is flexible and can be designed with different input dimensions for a given af application, which is vital to circumvent the trade-off between dof and snr. we build a dataset containing 5000 raw images tailored to the proposed network by an off-the-shelf camera. results show that our mpcam system can produce images with average higher values than raw images over 4.625, and 0.061 in pnsr (peak signal to noise ratio), and ssim (structure similarity) metrics, respectively. moreover, compared to the classic and latest image fusion methods, the results also verify that our method has achieved comparable or even better performance. due to its advance in high snr and large dof imaging, this novel, portable and inexpensive system is suitable for computational applications such as microscopic pathological diagnosis, domain-specific computational imaging and smartphone photography. the implementation code of mpgan and dataset are available from https://www.kaggle. com/datasets/ktd970903/multi-psf-camera.",AB_0021
"a single infrared image or visible image cannot clearly present texture details and infrared information of the scene in poor illumination, bad weather, or other complex conditions. thus, it is necessary to fuse the infrared and visible images into one image. in this paper, we propose a novel deep fusion architecture for fusing visible and infrared images without any reference ground-truth. different from existing deep image fusion methods which directly output the fused images, a weight score corresponding to each pixel is estimated by our network to determine the contributions of two source images. this strategy transfers the valuable information in source images to the fused image. considering the salient thermal radiation information in the infrared image, a mask of the infrared image is generated and used to preserve valuable contents in the infrared and visible images for the fused image. furthermore, a hybrid loss is designed to make the fused image consistent with two source images. on account of the weight estimation, the mask strategy, and the hybrid loss, the images fused by our proposed method jointly maintain the thermal radiation and texture details, achieving state-of-the-art performance compared with existing fusion approaches. our code is publicly available at https://github.com/nlcxg/mdfn.",AB_0021
"massive open online courses (moocs) are dedicated to providing learners with large-scale and open-access boutique courses. recently, the course recommendation algorithm in moocs has attracted many researchers' attention. compared with ordinary recommendation scenarios, course interaction density in moocs is more tenuous, since it demands lots of time and gumption of learners. meanwhile, the connections and semantic information among courses are much more diversiform and plentiful. therefore, knowledge graph enhanced recommendation algorithms are appropriate for addressing the course recommendation problem in moocs scenario. according to relevant research on kg-based algorithms, utilization efficiency of edge information seems to be the key to boosting model effectiveness. in this paper, we propose a high-performance course recommendation model named knowledge grouping aggregation network (kgan), which uses the course graph (a heterogeneous graph for describing the relations between courses and facts) to estimate learners' potential interests automatically and iteratively. more precisely, kgan constructs an end-to-end recommendation model, which projects the learner's behavior and course graph into a unified space naturally, which alleviates difficulties in course recommendation such as interaction tenuous, course relevance, and intention diversity. in addition, we proposed intra-group and inter-group attention operator, which packages the propagation set according to the relation-links and obtains the corresponding attention priorities of different entities under different paths for constructing a reasonable and explicit encoding of users. we apply the proposed model on the real-world datasets, and the empirical results demonstrate that kgan outperforms compelling state-of-the-art baselines. our implementations are available at https://github.com/stzhy/kgan.",AB_0021
"clinically, retinal vessel segmentation is a significant step in the diagnosis of fundus diseases. however, recent methods generally neglect the difference of semantic information between deep and shallow features, which fail to capture the global and local characterizations in fundus images simultaneously, resulting in the limited segmentation performance for fine vessels. in this article, a global transformer (gt) and dual local attention (dla) network via deep-shallow hierarchical feature fusion (gt-dla-dshff) are investigated to solve the above limitations. first, the gt is developed to integrate the global information in the retinal image, which effectively captures the long-distance dependence between pixels, alleviating the discontinuity of blood vessels in the segmentation results. second, dla, which is constructed using dilated convolutions with varied dilation rates, unsupervised edge detection, and squeeze-excitation block, is proposed to extract local vessel information, consolidating the edge details in the segmentation result. finally, a novel deep-shallow hierarchical feature fusion (dshff) algorithm is studied to fuse the features in different scales in the deep learning framework, respectively, which can mitigate the attenuation of valid information in the process of feature fusion. we verified the gt-dla-dshff on four typical fundus image datasets. the experimental results demonstrate our gt-dla-dshff achieves superior performance against the current methods and detailed discussions verify the efficacy of the proposed three modules. segmentation results of diseased images show the robustness of our proposed gt-dla-dshff. implementation codes will be available on https://github.com/yanglibuaa/gt-dla-dshff.",AB_0021
"accurate traffic prediction is a challenging task in intelligent transportation systems because of the complex spatio-temporal dependencies in transportation networks. many existing works utilize sophisticated temporal modeling approaches to incorporate with graph convolution networks (gcns) for capturing short-term and long-term spatio-temporal dependencies. however, these separated modules with complicated designs could restrict effectiveness and efficiency of spatio-temporal representation learning. furthermore, most previous works adopt the fixed graph construction methods to characterize the global spatio-temporal relations, which limits the learning capability of the model for different time periods and even different data scenarios. to overcome these limitations, we propose an automated dilated spatio-temporal synchronous graph network, named auto-dstsgn for traffic prediction. specifically, we design an automated dilated spatio-temporal synchronous graph (auto-dstsg) module to capture the short-term and long-term spatio-temporal correlations by stacking deeper layers with dilation factors in an increasing order. further, we propose a graph structure search approach to automatically construct the spatio-temporal synchronous graph that can adapt to different data scenarios. extensive experiments on four real-world datasets demonstrate that our model can achieve about 10% improvements compared with the state-of-art methods. source codes are available at https://github.com/jinguangyin/auto-dstsgn.",AB_0021
"in this paper, we propose an outlined attention u-network (oau-net) with bypass branching strategy to solve biomedical image segmentation tasks, which is capable of sensing shallow and deep features. unlike previous studies, we use residual convolution and res2convolution as encoders. in particular, the outline filter and attention module are embedded in the skip connection part, respectively. shallow features will enhance the edge information after being processed by the outline filter. meanwhile, in the depths of the network, to better realize feature fusion, our attention module will simultaneously emphasize the independence between feature map channels (channel attention module) and each position information (spatial attention module), that is, the hybrid domain attention module. finally, we conducted ablation experiments and comparative experiments according to three public data sets (pulmonary ct lesions, kaggle 2018 data science bowl, skin lesions), and analyzed them with classical evaluation indexes. experimental results show that our proposed method improves segmentation accuracy effectively. our code is public at https://github.com/yf-w/oau-net.",AB_0021

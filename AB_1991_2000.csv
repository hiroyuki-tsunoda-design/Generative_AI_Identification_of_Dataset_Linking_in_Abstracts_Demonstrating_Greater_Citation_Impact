AB,NO
"place recognition (pr) is an important problem in environment perception, which can help simultaneous localization and mapping (slam), as well as scene understanding of mobile robots. for pr, feature aggregation plays an important role in the representation of environments. in this article, an adaptive soft encoding (ase) method is proposed for aggregating numerous features into low-dimensional feature vectors, which includes a training phase and an encoding phase. for the training phase, the information along each dimension of the features is evaluated, which is further employed to assign all dimensions into different subdimensional intervals. after that, subdimensional gaussian mixture models (sd-gmms) are fit by features in the subdimensional intervals and organized into an ase tree, of which the tree nodes hierarchically store the parameters of the sd-gmms to reflect the distribution of the features. for the encoding phase, features are fed into the root node of the ase tree. the weight of each node is calculated from top to bottom to generate multiple aggregated feature vectors with different description capabilities. in addition, an ase-based framework for pr is proposed, in which local descriptors are extracted from sensor data (e.g., images or lidar data), and then aggregated into global descriptors by ase. finally, owing to the hierarchical structure of the ase tree, a hierarchical matching strategy of the global descriptors is designed to recognize places efficiently. experimental results demonstrate that feature vectors aggregated by ase have strong distinguishability, and the ase-based pr method achieves good accuracy and efficiency. the code of ase can be accessed at https://github.com/wdyiwdwd/ase-encoder.",AB_0200
"tanystropheidae is a clade of early archosauromorphs with high morphological disparity and a wide geographical distribution. the origin and early radiation of tanystropheidae are still incompletely understood. here we report luxisaurus terrestris gen. et sp. nov., a new archosauromorph collected from the marine upper member of guanling formation (pelsonian substage, anisian, middle triassic) in luxi county, yunnan province, china, and phylogenetically recovered as a tanystropheid. the morphology of luxisaurus is consistent with a terrestrial lifestyle. this is the first occurrence of a tanystropheid found from the anisian guanling formation in sw china and also the earliest tanystropheid from the eastern tethys. phylogenetic analysis shows that dinocephalosauridae forms the sister group of tanystropheidae, fuyuansaurus occupies the most basal position in tanystropheidae, and luxisaurus forms the sister group to a clade consisting of all other tanystropheids. considering that fuyuansaurus and luxisaurus are found exclusively in south china, we hypothesize that tanystropheidae originated in the early triassic of south china and then dispersed globally. the discovery of early triassic tanystropheids in south china is needed to further support this hypothesis. the discovery of luxisaurus expands the stratigraphical and geographical distribution of tanystropheidae, and provides new insights into the origin and early radiation of the clade.http://zoobank.org/urn:lsid:zoobank.org:pub:07de12ac-8ae7-48f0-8bad-0b73f04c0858",AB_0200
"deep learning (dl)-based surface defect detectors play a crucial role in ensuring product quality during inspection processes. however, accurately and efficiently detecting defects remain challenging due to specific characteristics inherent in defective images, involving a high degree of foreground-background similarity, scale variation, and shape variation. to address this challenge, we propose an efficient transformer-based detection network, etdnet, consisting of three novel designs to achieve superior performance. first, etdnet takes a lightweight vision transformer (vit) to extract representative global features. this approach ensures an accurate feature characterization of defects even with similar backgrounds. second, a channel-modulated feature pyramid network (cm-fpn) is devised to fuse multilevel features and maintain critical information from corresponding levels. finally, a novel task-oriented decoupled (tod) head is introduced to tackle inconsistent representation between classification and regression tasks. the tod head employs a local feature representation (lfr) module to learn object-aware local features and introduces a global feature representation (gfr) module, based on the attention mechanism, to learn content-aware global features. by integrating these two modules into the head, etdnet can effectively classify and perceive defects with varying shapes and scales. extensive experiments on various defect detection datasets demonstrate the effectiveness of the proposed etdnet. for instance, it achieves ap 46.7% (versus 45.9%) and ap50 80.2% (versus 79.1%) with 49 frames/s on neu-det. the code is available at https://github.com/zht8506/etdnet.",AB_0200
"seizure prediction of epileptic preictal period through electroencephalogram (eeg) signals is important for clinical epilepsy diagnosis. however, recent deep learning-based methods commonly employ intra-subject training strategy and need sufficient data, which are laborious and time-consuming for a practical system and pose a great challenge for seizure predicting. besides, multi-domain characterizations, including spatio-temporal-spectral dependencies in an epileptic brain are generally neglected or not considered simultaneously in current approaches, and this insufficiency commonly leads to suboptimal seizure prediction performance. to tackle the above issues, in this paper, we propose contrastive learning for epileptic seizure prediction (clep) using a spatio-temporal-spectral network (sts-net). specifically, the clep learns intrinsic epileptic eeg patterns across subjects by contrastive learning. the sts-net extracts multi-scale temporal and spectral representations under different rhythms from raw eeg signals. then, a novel triple attention layer (tal) is employed to construct inter-dimensional interaction among multi-domain features. moreover, a spatio dynamic graph convolution network (sdgcn) is proposed to dynamically model the spatial relationships between electrodes and aggregate spatial information. the proposed clep-sts-net achieves a sensitivity of 96.7% and a false prediction rate of 0.072/h on the chb-mit scalp eeg database. we also validate the proposed method on clinical intracranial eeg (ieeg) database from our xuanwu hospital of capital medical university, and the predicting system yielded a sensitivity of 95%, a false prediction rate of 0.087/h. the experimental results outperform the state-of-the-art studies which validate the efficacy of our method. our code is available at https://github.com/lianghuiguo/clep-sts-net.",AB_0200
"single object tracking (sot) in light detection and ranging (lidar) point clouds is a challenging problem in computer vision. compared to object-level point clouds, scene-level point clouds for tracking are more complex, requiring long-range semantic awareness and local shape context. however, previous methods directly filter candidates under limited matched features without systematically considering these two factors. inspired by transformer to establish long-distance dependence and convolution to capture local high-frequency information, we propose a point-tracking inception transformer (ptit), which efficiently predicts high-quality 3-d tracking results in a coarse-to-fine manner with the support of spatio-temporal point clouds. ptit consists of three novel designs as follows. 1) we design instance-guided sampling (igs) to help identify and preserve the relevant points of the given template and the foreground points of the search area. 2) we propose a point inception transformer (pit), which consists of a multifrequency attention and cross-attention module, where the former captures both remote dependency and local detail and the latter matches template and search area features. 3) after generating coarse tracking results from cross-attention, we locate the target by motion transformation in the spatio-temporal point cloud to generate a fine-grained 3-d bounding box (bbox). in addition, we perform feature augmentation on the points and boxes to mitigate the negative effects of lidar point clouds without texture and incompleteness. ptit performs significantly better than previous state-of-the-art methods on kitti and nuscenes datasets. our further analysis confirms the effectiveness of each component and shows the great potential of the inception transformer-centric paradigm when combined with spatio-temporal point clouds. our code is available at https://github.com/ywu0912/teamcode.git.",AB_0200
"electroencephalogram (eeg) based seizure prediction plays an important role in the closed-loop neuromodulation system. however, most existing seizure prediction methods based on graph convolution network only focused on constructing the static graph, ignoring multi-domain dynamic changes in deep graph structure. moreover, the existing feature fusion strategies generally concatenated coarse-grained epileptic eeg features directly, leading to the suboptimal seizure prediction performance. to address these issues, we propose a novel multi-branch dynamic multi-graph convolution based channel-weighted transformer feature fusion network (mb-dmgc-cwtffnet) for the patient-specific seizure prediction with the superior performance. specifically, a multi-branch (mb) feature extractor is first applied to capture the temporal, spatial and spectral representations fromthe epileptic eeg jointly. then, we design a point-wise dynamic multi-graph convolution network (dmgcn) to dynamically learn deep graph structures, which can effectively extract high-level features from the multi-domain graph. finally, by integrating the local and global channel-weighted strategies with the multi-head self-attention mechanism, a channel-weighted transformer feature fusion network (cwtffnet) is adopted to efficiently fuse the multi-domain graph features. the proposed mb-dmgc-cwtffnet is evaluated on the public chb-mit eeg and a private intracranial seeg datasets, and the experimental results demonstrate that our proposed method achieves outstanding prediction performance compared with the state-of-the-art methods, indicating an effective tool for patient-specific seizure warning. our code will be available at: https://github.com/rockingsnow/mb-dmgc-cwtffnet.",AB_0200
"electroencephalography-to-text generation (eeg-to-text), which aims to directly generate natural text from eeg signals has drawn increasing attention in recent years due to the enormous potential for brain-computer interfaces. however, the remarkable discrepancy between the subject-dependent eeg representation and the semantic-dependent text representation poses a great challenge to this task. to mitigate this, we devise a curriculum semantic-aware contrastive learning strategy (c- scl), which effectively recalibrates the subject-dependent eeg representation to the semantic-dependent eeg representation, thereby reducing the discrepancy. specifically, our c- scl pulls semantically similar eeg representations together while pushing apart dissimilar ones. besides, in order to introduce more meaningful contrastive pairs, we carefully employ curriculum learning to not only craft meaningful contrastive pairs but also make the learning progressively. we conduct extensive experiments on the zuco benchmark and our method combined with diverse models and architectures shows stable improvements across three types of metrics while achieving the new state-of-the-art. further investigation proves not only its superiority in both the single-subject and low-resource settings but also its robust generalizability in the zero-shot setting. our codes are available at: https://github.com/xcfcode/contrastive_eeg2text.",AB_0200
"as a kind of network structure increasingly studied in compressive sensing (cs), deep unfolding networks (duns), which unroll the iterative reconstruction procedure as deep neural networks (dnns) for end-to-end training, have high interpretability and remarkable performance. every phase of the dun corresponds to one iteration. the input and output of each phase in most duns are inherently images, which heavily restricts information transmission. besides, existing duns unfolded by l(1)-regularized optimization usually utilize fixed thresholds for soft-shrinkage operation, which lacks adaptability. to solve these issues, a novel side-information-aided deep adaptive shrinkage network (sodas-net) is designed for cs. utilizing the side information (si) allows sodas-net to send large volumes of information between adjacent phases, substantially augmenting the network representation capacity and optimizing network performance. furthermore, an effective adaptive soft-shrinkage strategy is developed, which enables our sodas-net to solve l(1)-regularized proximal mapping with content-aware thresholds. the results from extensive experiments on various testing datasets demonstrate that sodas-net achieves superior performance. codes are available at https://github.com/songjiechong/sodas-net.",AB_0200
"image super-resolution (sr) is the process of restoring high-resolution (hr) images from low-resolution (lr) ones. recent transformer-based sr methods have achieved impressive results by utilizing the self-attention (sa) mechanism, which allows modeling long-range dependencies among input features in spatial dimensions. however, the computational complexity of sa increases quadratically with respect to the feature size, which makes transformer-based methods inefficient. additionally, despite the success of dense connections in convolutional neural network (cnn)-based methods, they have not been fully explored in transformer-based methods. in this article, we propose a novel approach for lightweight sr, called densely connected transformer with linear sa (dctlsa) network. our method addresses the efficiency issue of sa by designing a new linear sa (lsa), which calculates the similarities in spatial dimension with linear complexity. moreover, we leverage dense connections to integrate multiple levels of features and provide rich information for sr. our experimental results demonstrate that dctlsa outperforms state-of-the-art lightweight sr methods in terms of sr performance, model complexity, and inference speed. the code of the proposed method is available at https://github.com/zengkun301/dctlsa.",AB_0200
"in a broad sense, camouflaged objects generally refer to objects that have a high degree of similarity to the background. therefore, camouflaged object segmentation (cos) is more challenging than traditional object segmentation. current cos networks have high segmentation precision on datasets. however, the problems of object miss detection and false alarm still occur, mainly due to different camouflage levels of the objects. in this article, we propose a joint comparative network (jcnet) for cos based on joint salient object for contrastive learning to overcome the widespread challenges in cos. specifically, the main innovation of jcnet is the contrastive network (cnet) design, which generates a unique feature representation of the camouflaged object different from others. in terms of details, we design an edge guidance module to enhance the edge extraction capability. moreover, a global relationship capture module is proposed to improve the confidence level of the feature representation. finally, we set positive and negative samples and loss functions in conjunction with sample types. we conducted comprehensive experiments using four cos datasets, and the results demonstrate its suitability for cos when compared with other state-of-the-art segmentation models. jcnet achieves optimal results on five evaluation metrics, including an average improvement of 1.93% and 2.7% on f-m and f-m(w), respectively. in summary, it has lower miss and false alarm rates, and better generalization in the cos task. in addition, the experiments demonstrate that jcnet also has strong segmentation capability in salient object segmentation, achieving a win-w in situ ation for both tasks. the code will be available at https://github.com/jiangxinhao2020/jcnet.",AB_0200

AB,NO
"fuzzy information granulation is an important mathematical model in the theory of granular computing that can effectively handle fuzzy or uncertain information. to address the deficiencies of existing anomaly detection techniques that are mainly suitable for certainty data, this study proposes an anomaly detection method based on fuzzy granules. this method uses the fuzzy information granulation model as a unified framework to gradually develop a fuzzy granular anomaly detection method for calculating the anomaly score of each sample. first, the fuzzy granular distance is defined by fusing single-attribute fuzzy granules to represent the dissimilarity between two samples. second, a matrix is constructed using the fuzzy granular distance between the samples as the state transition matrix of the markov random walk. anomalies in the dataset are then detected using the stationary distribution generated by iterative calculations. finally, the fuzzy granular anomaly score for each object is obtained by normalizing the stationary distribution. experiments are conducted on public datasets to compare the proposed method with some state-of-the-art anomaly detection methods. the results indicate that the proposed method is effective. the code is publicly available online at https://github .com /belloney /fgas.",AB_0312
"thermal pedestrian detection is a core problem in computer vision. usually, the corresponding visual image knowledge is used to improve the performance in thermal domain. however, existing methods always assume the same resolution between visible and thermal images. but in reality, there is a problem with this setting. since thermal imaging acquisition equipment is expensive, the resolution of thermal images is always lower than visible images. to address this issue, we propose a new method, named as disentanglement then restoration (dtr). the key idea is to disentangle the features into content features and modal features and restore the complete content features of thermal images by learning the changes of content features caused by different resolutions. specifically, we first train an object detector such as yolo to initialize our model. then, a feature disentanglement network is trained, which can disentangle the features from the backbone as content features and modal features. in the end, the feature disentanglement network is frozen. by forcing the content feature consistency between visual image and upsampled thermal image, the complete content features of low-resolution thermal images are restored. experiment results on public datasets show that our method performs very well. code is available at https://github.com/ hameow-lst1/dtr.",AB_0312
"precise wind speed forecasting contributes to wind power consumption and power grid schedule as well as promotes the implementation of global carbon neutrality policy. however, in existing research, the negative impact of outliers on forecasting models is ignored and the inherent shortcomings of the single predictors have not been taken seriously. moreover, the intrinsic parameters of predictors are set by manual and empirical methods in some research, leading to difficulties in achieving optimal forecasting performance. to solve the shortcomings of existing research, a multi-step short-term wind speed forecasting framework is proposed by incorporating boxplot-medcouple (mc), variational mode decomposition (vmd), phase space reconstruction (psr), weight-based stacked generalization with enhanced differential evolution slime mold algorithm (desma). firstly, boxplot-mc is employed to achieve outlier detection and correction for preprocessing original wind speed data by analyzing values and trends. then, the modified data is further adaptively decomposed into multiple subsequences by vmd, after which each subsequence is constructed into feature matrices through psr. subsequently, weight-based multi-model fusion strategy in layer-1 of stacked generalization is proposed to integrate the predicting values acquired by three primary learners, of which the weight coefficients are calculated with the error between actual values and predicting values. after that, kernel extreme learning machine (kelm) in layer-2 of stacked generalization is applied to predict the fusion result to obtain forecasting value corresponding to each subsequence. meanwhile, an enhanced desma based on slime mold algorithm (sma) and differential evolution (de) is proposed to calibrate the parameters of kelm. eventually, the final wind speed forecasting results are attained by summing the prediction values of all subsequences. furthermore, comparative experiments from different aspects are undertaken on real datasets to ascertain the availability of the proposed framework. the experimental results are clarified as follows: (1) outlier detection and correction employing boxplot-mc is dedicated to analyzing values and trends effectively, with which the negative impact of outliers can be weakened while retaining valid data significantly; (2) vmd can prominently reduce the non-smoothness and volatility of wind speed data; (3) weight-based stacked generalization is conducive to exploiting the advantages of individual primary learners, contributing to compensating for instability; (4) desma enhances prediction accuracy by optimizing the parameters of kelm. additionally, the code has been made available at https://github.com/ fyc233/a-multi-step-short-term-wind-speed-forecasting-framework.git.",AB_0312
"graph pattern matching is a fundamental operation for exploring and analyzing large graphs, which are widely used to represent entities and their relationships in a plethora of applications. however, existing algorithms do not perform satisfactorily as they generate a large number of intermediate results. in this paper, we introduce a novel framework to address the problem of efficiently finding homomorphic matches of hybrid tree-patterns over large graphs. these are patterns that can include two types of edges: child edges (which are mapped to edges in the data graph) and/or descendant edges (which are mapped to paths in the data graph), thus allowing for higher expressiveness and flexibility in query formulation. we introduce the concept of answer graph to compactly represent the query results and exploit computation sharing. leveraging the answer graph, our approach is able to avoid the generation of intermediate results not participating in the query answer, and can produce the query answer in time linear on the size of the input data graph and the output. moreover, the answer graph allows query counting without explicitly enumerating query results. we design a bottom-up algorithm (bup) and a simulation-based algorithm (sim) for building the answer graph, each having their own strengths in different cases. we also present two algorithms for enumerating the results using the answer graph. our extensive experimental evaluation on real and synthetic datasets shows that our proposed techniques greatly outperform the state-of-the-art graph matching algorithms as well as a popular graph dbms on evaluating various hybrid tree-pattern queries. our source code, datasets and queries are publicly available at https://github.com/wuxyng/twigmatchongraph. & copy; 2023 elsevier ltd. all rights reserved.",AB_0312
"we propose precancell, a novel algorithm for predicting malignant and non-malignant cells from single-cell transcriptomes. precancell first identifies the differentially expressed genes (degs) between malignant and non-malignant cells commonly in five common cancer types-associated single-cell transcriptome datasets. the five common cancer types include renal cell carcinoma (rcc), head and neck squamous cell carcinoma (hnscc), melanoma, lung adenocarcinoma (luad), and breast cancer (bc). with each of the five datasets as the training set and the degs as the features, a single cell is classified as malignant or non-malignant by k-nn (k = 5). finally, the single cell is determined as malignant or non-malignant by the majority vote of the five k-nn classification results. we tested the predictive performance of precancell in 19 single-cell datasets, and reported classification accuracy, sensitivity, specificity, balanced accuracy (the average of sensitivity and specificity) and the area under the receiver operating characteristic curve (auroc). in all these datasets, precancell achieved above 0.8 accuracy, sensitivity, specificity, balanced accuracy and auroc. finally, we compared the predictive performance of precancell with that of seven other algorithms, including chetah, scibet, scina, scmap-cell, scmap-cluster, singler, and ikarus. compared to these algorithms, precancell displays the advantages of higher accuracy and simpler implementation. we have developed an r package for the precancell algorithm, which is available at https://github.com/wangx-lab/precancell.",AB_0312
"enhancer promoter interaction (epi) involves most of gene transcriptional regulation in the high eukaryotes. predicting the epis from given genomic loci or dna sequences is not a trivial task. the benchmarking work so far for epi predictors is more or less empirical and lacks quantitative model-based comparisons, posing challenges for molecular biologists to obtain reliable epi predictions. here, we present an epi prediction platform, namely delta.epi. based on a statistic model of the data integration, delta.epi is capable of comprehensively assessing the predictions from four state-of-the-art epi predictors. equipped with a user-friendly interface and visualization platform, delta.epi presents the sorted results with the confidence of epi relevance, which may guide the molecular biologists who lack the pre-knowledge of the algorithms of epi prediction. last, we showcase the utility of delta.epi with a case study. delta.epi provides a powerful tool to fuel the gene regulation and 3d genome studies by ease-to-access epi predictions. delta.epi can be freely accessed at https://ngdc.cncb.ac.cn/deltaepi/.copyright & copy; 2023, institute of genetics and developmental biology, chinese academy of sciences, and genetics society of china. published by elsevier limited and science press. all rights reserved.",AB_0312
"the eye-tracking and electroencephalogram data, as physiological information, have been viewed as effective supplements to subjective reporting for guiding the product appearance design. in this context, how to combine heterogeneous information is a challenging question. this study proposes different methods to determine sub-jective and objective weights of criteria regarding the self-reporting, eye-tracking, and electroencephalogram data for the evaluation of product appearance design. we introduce the probabilistic linguistic term set with interval uncertainty (iuplts) to represent complex self-reporting data, and develop a method to aggregate iupltss. an algorithm is proposed to fuse physiological data on the data layer and feature layer. to combine the obtained heterogeneous information, we define an objective weighting method that examines the differences in indicator data and the correlation between indicators, and then use a level difference maximization model to fuse subjective and objective weights. to ensure the stability of decision-making results for the problem involving a large number of indicators, we use the measurement of alternatives and ranking according to the compromise solution (marcos) to rank alternatives. an example regarding the evaluation of automobile appearance design schemes is presented to show the validity and practicality of the proposed method. the prototype support system of the proposed method has been developed and is freely available at https://github.com/bitsecret/daqqso.",AB_0312
"the wide spread of fake news is increasingly threatening both individuals and society. great efforts have been made for automatic fake news detection on a single domain (e.g., politics). however, correlations exist commonly across multiple news domains, and thus it is promising to simultaneously detect fake news of multiple domains. based on our analysis, we pose two challenges in multi-domain fake news detection: 1) domain shift, caused by the discrepancy among domains in terms of words, emotions, styles, etc. 2) domain labeling incompleteness, stemming from the real-world categorization that only outputs one single domain label, regardless of topic diversity of a news piece. in this paper, we propose a memory-guided multi-view multi-domain fake news detection framework (m3 fend) to address these two challenges. we model news pieces from a multi-view perspective, including semantics, emotion, and style. specifically, we propose a domain memory bank to enrich domain information which could discover potential domain labels based on seen news pieces and model domain characteristics. then, with enriched domain information as input, a domain adapter could adaptively aggregate discriminative information from multiple views for news in various domains. extensive offline experiments on english and chinese datasets demonstrate the effectiveness of m3 fend, and online tests verify its superiority in practice. our code is available at https://github.com/ictmcg/m3fend.",AB_0312
"the attention mechanism enables graph neural networks (gnns) to learn the attention weights between the target node and its one-hop neighbors, thereby improving the performance further. however, most existing gnns are oriented toward homogeneous graphs, and in which each layer can only aggregate the information of one-hop neighbors. stacking multilayer networks introduces considerable noise and easily leads to over smoothing. we propose here a multihop heterogeneous neighborhood information fusion graph representation learning method (mhnf). specifically, we propose a hybrid metapath autonomous extraction model to efficiently extract multihop hybrid neighbors. then, we formulate a hop-level heterogeneous information aggregation model, which selectively aggregates different-hop neighborhood information within the same hybrid metapath. finally, a hierarchical semantic attention fusion model (hsaf) is constructed, which can efficiently integrate different-hop and different-path neighborhood information. in this fashion, this paper solves the problem of aggregating multihop neighborhood information and learning hybrid metapaths for target tasks. this mitigates the limitation of manually specifying metapaths. in addition, hsaf can extract the internal node information of the metapaths and better integrate the semantic information present at different levels. experimental results on real datasets show that mhnf achieves the best or competitive performance against state-of-the-art baselines with only a fraction of 1/10 similar to 1/100 parameters and computational budgets. our code is publicly available at https://github.com/phd-lanyu/mhnf.",AB_0312
"with the development of booming automl systems, modeling processes have become more automatic for researchers. however, automl systems may struggle to identify the optimal surrogate type, find the best combination of the hyper-parameters or establish a high-fidelity ensembled surrogate model for certain datasets. to address these issues and further improve the warm-start procedure of automl, a ranking prediction strategy assisted automatic model selection (rps-ams) method is proposed. in the suggested method, an integration of evolutionary algorithms (ea-based) and feature-based driven model selection strategy selects the best or the best combination models for prediction. based on the proposed criteria, an xgboost regression model is trained to determine the rankings from the candidate surrogate models and then build an ensembled surrogate model to further enhance accuracy. we evaluate rps-ams using 13 mathematical functions, 14 public datasets, and a real engineering problem. compared with the popular modeling tools, such as auto-sklearn and evalml, the rpsams outperforms in term of accuracy while maintaining the performances of ergodic methods of all surrogate models. the accuracies of rps-ams rival evalml in most tested datasets, although rps-ams may be slightly less efficient. given that evalml is a masterpiece of the automl systems, the performances of rps-ams are promising. this code is available at: https://github.com/hnuaisimopt/rps-ams.",AB_0312

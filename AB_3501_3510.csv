AB,NO
"this article explores how to harvest precise object segmentation masks while minimizing the human interaction cost. to achieve this, we propose a simple yet effective interaction scheme, named inside-outside guidance (iog). concretely, we leverage an inside point that is clicked near the object center and two outside points at the symmetrical corner locations (top-left and bottom-right or top-right and bottom-left) of an almost-tight bounding box that encloses the target object. the interaction results in a total of one foreground click and four background clicks for segmentation. the advantages of our iog are four-fold: 1) the two outside points can help remove distractions from other objects or background; 2) the inside point can help eliminate the unrelated regions inside the bounding box; 3) the inside and outside points are easily identified, reducing the confusion raised by the state-of-the-art dextr maninis et al. 2018, in labeling some extreme samples; 4) it naturally supports additional click annotations for further correction. despite its simplicity, our iog not only achieves state-of-the-art performance on several popular benchmarks such as grabcut rother et al. 2004, pascal everingham et al. 2010 and ms coco russakovsky et al. 2015, but also demonstrates strong generalization capability across different domains such as street scenes (cityscapes cordts et al. 2016), aerial imagery (rooftop sun et al. 2014 and agriculture-vision chiu et al. 2020) and medical images (sstem gerhard et al. 2013). code is available at https://github.com/shiyinzhang/inside-outside-guidancehttps://github.com/shiyinzhang/inside-outside-guidance.",AB_0351
"the attention mechanism empowers deep learning to a broader range of applications, but the contribution of the attention module is highly controversial. research on modern hopfield networks indicates that the attention mechanism can also be used in shallow networks. its automatic sample filtering facilitates instance extraction in multiple instances learning tasks. since the attention mechanism has a clear contribution and intuitive performance in shallow networks, this paper further investigates its optimization method based on the recurrent neural network. through comprehensive comparison, we find that the synergetic neural network has the advantage of more accurate and controllable convergences and revertible converging steps. therefore, we design the syn layer based on the synergetic neural network and propose the novel invertible activation function as the forward and backward update formula for attention weights concentration or distraction. experimental results show that our method outperforms other methods in all multiple instances learning benchmark datasets. concentration improves the robustness of the results, while distraction expands the instance observing space and yields better results. codes available at https://github.com/wzh134/syn.",AB_0351
"efficient image super-resolution (sr), being preferred in the resource-constrained scenarios, aims at not only higher super-resolving accuracy but also lower computational complexity. taking the perception capability of deep networks into account, efficiently and effectively obtaining the large receptive field is a key principle for this task. thus, in this paper, we integrate the multi-scale receptive field design with information distillation structure and attention mechanism, and develop a lightweight multi-scale information distillation (msid) network. in detail, we design a multi-scale feature distillation (msfd) block by employing multi-scale convolutions with different kernels into feature distillation connection, which effectively distills information from multiple receptive fields with low computational cost for better feature refinement. moreover, we construct a scalable large kernel attention (slka) block via scaling attentive fields across network layers, that possesses large and scalable receptive field in attention to discriminatively enhance the distilled features. extensive quantitative and qualitative evaluations on benchmark datasets validate the effectiveness of each proposed component and also demonstrate the superiority of our msid network over state-of-the-art efficient sr methods. the code is available at https://github.com/yuanfeihuang/msid. (c) 2023 published by elsevier b.v.",AB_0351
"river ice semantic segmentation is a crucial task, which can provide us with information for river monitoring, disaster forecasting, and transportation management. previous works mainly focus on higher accuracy acquirement, while efficiency is also important for reality usage. in this paper, a real-time and accurate river ice semantic segmentation network is proposed, named fasticenet. the general architecture consists of two branches, i.e., a shallow high-resolution spatial branch and a deep context semantic branch, which are carefully designed for the scale diversity and irregular shape of river ice in remote sensing images. then, a novel downsampling module and a dense connection block based on a lightweight ghost module are adopted in the context branch to reduce the computation cost. furthermore, a learnable upsampling strategy dupsampling is utilized to replace the commonly used bilinear interpolation to improve the segmentation accuracy. we deploy detailed experiments on three publicly available datasets, named nwpu_yrcc_ex, nwpu_yrcc2, and alberta river ice segmentation dataset. the experimental results demonstrate that our method achieves state-of-the-art performance with competing methods, on the nwpu_yrcc_ex dataset, we can achieve the segmentation speed as 90.84fps and the segmentation accuracy as 90.770 % miou, which also illustrates the good leverage between accuracy and speed. our code is available at https://github.com/nwpulab113/fasticenet & copy; 2023 elsevier b.v. all rights reserved.",AB_0351
"anomaly detection on multivariate time series (mts) is of great importance in both data mining research and industrial applications. while a handful of anomaly detection models are developed for mts data, most of them either ignore the potential correlations between different variables or overlook the different importance of variables at each time period in mts, which leads to poor accuracy in anomaly detection. in this paper, we propose a novel unsupervised multivariate time series anomaly detection framework (mutant), which simultaneously models the correlations between variables and the importance of variables at each time period. specifically, we construct a feature graph for variables in each time window and perform graph convolutional network (gcn) to learn embeddings for all variables, which effectively captures the time-varying correlations between variables in mts. then, we propose an attention-based reconstruction model to learn robust latent representations to capture normal patterns of mts by modeling the importance of variables based on time dependencies along with time dimension. our evaluation experiments are conducted on four real-life datasets from different industrial domains. experimental results show that mutant significantly outperforms stateof-the-art mts anomaly detection methods, achieving an average anomaly detection f1-score higher than 0.96. the source code is available at https://github.com/coac-syf/mutant.& copy; 2023 elsevier b.v. all rights reserved.",AB_0351
"recently clustering for datasets with different shapes, densities and noises has attracted more and more attention from scholars. however, most current clustering algorithms improve the clustering performance at the expense of the simplicity, and cannot balance well between the clustering quality and the operability for the users. to solve this problem, we propose a new algorithm called stratification clustering based on density, hierarchy and partition (sdhp) by effectively integrating the advantages of the density-based, hierarchical-based and partition-based clustering. first, a new parameter-free local density estimation strategy based on the bidirectional natural neighbor relationship named local density based on natural neighbor (nn-ld) is proposed to identify the core part of each sub-cluster. then, a new stratification strategy based on the nn-ld stratification-nn-ld (s-nn-ld) is proposed to divide the entire dataset into two layers, the core layer and the edge layer, to simplify the dataset structure and make the algorithm robust to noises. next, the hierarchical-based single-linkage algorithm is adopted in the core layer to obtain the initial clustering result since it has advantages on clustering the datasets with various shapes and densities. finally, to improve the clustering accuracy of samples in the edge layer, a combination of a new local inter-cluster distance measure based on the average of neighbor distances and the partitioning clustering is adopted to match these samples to the sub-clusters in the initial clustering result. the experiments on twenty datasets show that the sdhp has better clustering accuracy, and can be applied in practice well compared with four popular hierarchical clustering algorithms, four recent density-based clustering algorithms, and a state-of-the-art partitioning clustering algorithm. the source code can be downloaded from https:// github.com/qi111678/sdhp.",AB_0351
"the emergence of the transformer optimizes the interactive modeling of multimodal information in visual question answering (vqa) tasks, helping machines better understand multimodal information. the existing transformer-based end-to-end methods have made some achievements in applying the encoder-decoder (e-d) mode or realizing complete interaction. however, almost no methods combine the advantages of the two well and give full play to them. thus, this paper designs a complete language-vision interaction network (clvin) for vqa based on the implementation of the quadratic e-d mode. based on the core framework of the modular co-attention network (mcan), clvin achieves the complete interaction of multimodal information by using the e-d mode again, realizing the rational distribution of the question words' weight information. in addition, to reduce the additional consumption of time and memory caused by introducing the quadratic e-d mode, this paper proposes a compact method called clvin-c through optimizing the underlying implementation of the scaled dot-product attention in transformer. finally, a series of experimental results based on the dataset vqa-v2.0 and clevr show that clvin has a significant performance improvement, and clvin-c achieves further optimizations in model size and performance. code is available at https://github.com/rainymoo/myvqa.& copy; 2023 elsevier b.v. all rights reserved.",AB_0351
"the deep convolutional neural networks (cnns) using attention mechanism have achieved great suc-cess for dynamic scene deblurring. in most of these networks, only the features refined by the attention maps can be passed to the next layer and the attention maps of different layers are separated from each other, which does not make full use of the attention information from different layers in the cnn. to address this problem, we introduce a new continuous cross-layer attention transmission (cclat) mech-anism that can exploit hierarchical attention information from all the convolutional layers. based on the cclat mechanism, we use a very simple attention module to construct a novel residual dense attention fusion block (rdafb). in rdafb, the attention maps inferred from the outputs of the preceding rdafb and each layer are directly connected to the subsequent ones, leading to a cclat mechanism. taking rdafb as the building block, we design an effective architecture for dynamic scene deblurring named rdafnet. the experiments on benchmark datasets show that the proposed model outperforms the state-of-the-art deblurring approaches, and demonstrate the effectiveness of cclat mechanism. the source code is available on: https://github.com/xjmz6/rdafnet.& copy; 2023 published by elsevier ltd.",AB_0351
"interdisciplinary concept association discovery is a fundamental task in interdisciplinary knowledge organization. unlike general concept association, interdisciplinary concept association mainly manifests in the correlation between fine-grained concept properties, which requires that interdisciplinary concept association discovery be explored through a fine-grained semantic association discovery tool. existing concept association discovery methods are limited in their ability to identify interdisciplinary concept associations at fine-grained conceptual properties because they can only identify which two concepts are associated at the coarse level. to bridge this gap, we propose a method we called interdisciplinary concept association discovery based on metaphor interpretation (icad-mi). first, we explored the mechanism of interdisciplinary conceptual metaphor on both the cognitive and language layers, which provides a solid foundation for our method. second, we introduced the four-step icad-mi method, which integrates deep learning techniques with word semantics and multidimensional contexts. we tested the icad-mi framework using a dataset comprising a total of 1,915 data points of interdisciplinary metaphorical expressions (imes) on a typical interdisciplinary conceptual metaphor computer is a brain. our model achieved a precision of 94.4%, a recall of 73.9%, and an f1 score of 82.9%, which outperforms the four baseline methods. additionally, we conducted parameter analysis to further validate the effectiveness of our proposed method. the code and datasets are publicly available at: https://github.com/haihua0913/icadmi. & copy; 2023 elsevier b.v. all rights reserved.",AB_0351
"heterogeneous graph neural networks (hgnns) can effectively model multiple node types and complex interactions in real networks and solve problems in various practical applications. self-supervised learning-based hgnns (sl-hgnns) have become the current research focus in this field because they can solve the problem of difficult label acquisition in practical scenarios. these methods usually split heterogeneous graphs into multiple subgraphs based on meta-paths for separate study. however, they ignore the complex interactions between the different semantics of the graphs. in addition, they use node features as auxiliary information for heterogeneous graph representation learning and ignore the importance of features. to solve the above problems, we propose a self-supervised learning on heterogeneous graph neural network via semantic strength and feature similarity (hetgnn-sf) model. this model innovatively implements a feature-and topology-based comparative optimization (ftc) method to generate weights for different meta-paths and then splits the original heterogeneous graph into different semantic subgraphs based on meta-paths. thereafter, the different subgraphs are fused by the ftc to generate semantic fusion graphs that capture the interactions between different semantics. semantic strength and feature similarity perspectives generate node embeddings from the semantic fusion graphs. finally, the ftc positive and negative samples are used for contrastive learning from the two perspectives to yield the final node embeddings. extensive experiments are conducted on three real datasets using the proposed hetgnn-sf model; the results reveal that hetgnn-sf outperforms state-of-the-art models. our data and code are available on github (https://github.com/liuxmaa/hetgnn-sf-.git).",AB_0351

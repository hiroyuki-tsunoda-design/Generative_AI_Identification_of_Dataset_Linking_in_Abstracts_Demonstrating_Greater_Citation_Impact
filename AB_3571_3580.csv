AB,NO
"despite significant progress, estimating 3d human poses from monocular videos remains a challenging task due to depth ambiguity and self-occlusion. most existing works attempt to solve both issues by ex-ploiting spatial and temporal relationships. however, those works ignore the fact that it is an inverse problem where multiple feasible solutions (i.e., hypotheses) exist. to relieve this limitation, we propose a multi-hypothesis transformer that learns spatio-temporal representations of multiple plausible pose hypotheses. in order to effectively model multi-hypothesis dependencies and build strong relationships across hypothesis features, we introduce a one-to-many-to-one three-stage framework: (i) generate mul-tiple initial hypothesis representations; (ii) model self-hypothesis communication, merge multiple hy-potheses into a single converged representation and then partition it into several diverged hypotheses; (iii) learn cross-hypothesis communication and aggregate the multi-hypothesis features to synthesize the final 3d pose. through the above processes, the final representation is enhanced and the synthesized pose is much more accurate. extensive experiments show that the proposed method achieves state-of -the-art results on two challenging datasets: human3.6m and mpi-inf-3dhp. the code and models are available at https://github.com/vegetebird/mhformer .(c) 2023 elsevier ltd. all rights reserved.",AB_0358
"link prediction in attributed networks has attracted increasing attention recently due to its valuable real-world applications. various related methods have been proposed, but most of them cannot effectively utilize community structure, neither can they well fuse attribute information and link information to improve the performance. inspired by our empirical observations on how community structure affects the generation of links, we propose a novel community preserving adaptive graph convolutional networks (cpagcn) method to tackle the link prediction task in attributed networks. specifically, cpagcn is composed of two core modules: network embedding and link prediction. net -work embedding module utilizes agcn to seamlessly fuse link information and attribute information to obtain node representations, which are simultaneously driven to preserve community structure via an appropriate community detection model. taking these node representations as the input, link prediction module applies multilayer perception (mlp) to directly learn the prediction scores for potential links. through combining the graph reconstruction loss with the prediction loss to train agcn and mlp jointly, cpagcn can learn node representations that are more beneficial to predicting links. to verify the effectiveness of cpagcn, we conduct extensive experiments on six real-world attributed networks. the results demonstrate that cpagcn performs better than several strong competitors in link prediction. the source code is available at https://github.com/gdm-scnu/cpagcn.(c) 2023 elsevier b.v. all rights reserved.",AB_0358
"as the number of long short-term memory (lstm) layers increases, vanishing/exploding gradient problems exacerbate and have a negative impact on the performance of the lstm. in addition, the ill-conditioned problem occurs in the training process of lstm and adversely affects its convergence. in this work, a simple and effective method of the gradient activation is applied to the lstm, while empirical criteria for choosing gradient activation hyperparameters are found. activating the gradient refers to modifying the gradient with a specific function named the gradient activation function. moreover, different activation functions and different gradient operations are compared to prove that the gradient activation is effective on lstm. furthermore, comparative experiments are conducted, and their results show that the gradient activation alleviates the above problems and accelerates the convergence of the lstm. the source code is publicly available at https://github.com/longjin-lab/act-in-nlp. & copy; 2023 elsevier ltd. all rights reserved.",AB_0358
"class-incremental learning (cil) aims to recognize classes that emerged in different phases. the joint -training (jt), which trains the model jointly with all classes, is often considered as the upper bound of cil. in this paper, we thoroughly analyze the difference between cil and jt in feature space and weight space. motivated by the comparative analysis, we propose two types of calibration: feature calibration and weight calibration to imitate the oracle (ito), i.e., jt. specifically, on the one hand, feature calibration introduces deviation compensation to maintain the class decision boundary of old classes in feature space. on the other hand, weight calibration leverages forgetting-aware weight perturbation to increase transferability and reduce forgetting in parameter space. with those two calibration strategies, the model is forced to imitate the properties of joint-training at each incremental learning stage, thus yielding better cil performance. our ito is a plug-and-play method and can be implemented into existing methods easily. extensive experiments on several benchmark datasets demonstrate that ito can significantly and consistently improve the performance of existing state-of-the-art methods. our code is publicly available at https://github.com/impression2805/ito4cil.(c) 2023 elsevier ltd. all rights reserved.",AB_0358
"recent online knowledge distillation (okd) methods focus on capturing rich and useful intermediate information by performing multi-layer feature learning. existing works only consider intermediate layer feature maps between the same layers and ignore valuable information across layers, which results in the lack of appropriate cross-layer supervision in detail and the process of learning. besides, this manner provides insufficient supervision information to supervise the learning of student, since it fails to construct a qualified teacher. in this work, we propose a deep cross-layer collaborative learning network (dccl) for okd, which efficiently exploits fruitful knowledge of peer student models by keeping appropriate intermediate cross-layer supervision. specifically, each student gradually integrates its own features at different layers for feature matching, so as to effectively utilize features in low and high levels for learning more composite knowledge. moreover, we assign a collaborative knowledge learning strategy, in which a qualified teacher is established via fusing the features of last convolution layers for enhancing high-level representation. in this way, all student models continuously transfer the rich teacher's internal representation as well as capture its dynamic growth process, and in turn assist the learning of the fusion teacher to further supervise students. in the experiments, our proposed dccl has shown great generalization ability with various backbone models on cifar-100, tiny imagenet and imagenet, and also demonstrated superior performance against mainstream okd works. our code is available here: https://github.com/nanxiaotong/dccl.",AB_0358
"deep learning (dl) methods have recently captured much attention for image classification. however, such methods may lead to a suboptimal solution for small-scale data since the lack of training samples. sparse representation stands out with its efficiency and interpretability, but its precision is not so competitive. we develop a multi-level cascade sparse representation (ml-csr) learning method to combine both advantages when processing small-scale data. ml-csr is proposed using a pyramid structure to expand the training data size. it adopts two core modules, the error-to-feature (etf) module, and the generate-adaptive-weight (gaw) module, to further improve the precision. ml-csr calculates the inter-layer differences by the etf module to increase the diversity of samples and obtains adaptive weights based on the layer accuracy in the gaw module. this helps ml-csr learn more discriminative features. state-of-the-art results on the benchmark face databases validate the effectiveness of the proposed ml-csr. ablation experiments demonstrate that the proposed pyramid structure, etf, and gaw module can improve the performance of ml-csr. the code is available at https://github.com/zhongwenyuan98/ml-csr.",AB_0358
"data augmentation, which improves the diversity of datasets by applying image transformations, has become one of the most effective techniques in visual representation learning. usually, the design of augmentation policies faces a diversity-difficulty trade-off. on the one hand, a simple augmentation leads to a low training set diversity, which can not improve model performance significantly. on the other hand, an excessively hard augmentation has an overlarge regularization effect which harms model performance. recently, automatic augmentation methods have been proposed to address this issue by searching the optimal data augmentation policy from a predefined searching space. however, these methods still suffer from heavy searching overhead or complex optimization objectives. in this paper, instead of searching the optimal augmentation policy, we propose to break the diversity-difficulty trade-off from a multi-task learning perspective. by formulating model learning on the augmented images and the original images as the auxiliary task and the primary task in multi-task learning respectively, the hard augmentation does not directly influence the training of the primary branch and thus its negative influence can be alleviated. hence, neural networks can learn valuable semantic information even with a totally random augmentation policy. experimental results on ten datasets for four tasks demonstrate the superiority of our method over the other twelve methods. codes have been released in https://github.com/archiplab-linfengzhang/data-augmentation-multi-task.",AB_0358
"adaptive inference with multiple networks has attracted much attention for resource-limited image classification. it assumes that a large portion of test samples can be correctly classified by small networks with fewer layers or channels, which poses a great challenge for them. in this paper, we argue that large networks have abilities to help the small ones address this challenge if fully explored. to this end, we propose a multi-resolution synergistic network (msnet) using two different kinds of fusion modules. the first one is a cross-branch aggregation module, which aims to transfer the high-resolution features to the low-resolution ones between neighboring branches. the other one is an adaptive distillation module, whose purpose is feeding the discriminative ability of the large network to the other ones. via these two modules, the small networks will be powerful enough to correctly classify large numbers of test samples, thus improving the classification accuracy and inference efficiency. we evaluate msnet on three benchmark datasets: cifar-10, cifar-100, and imagenet. experimental results show that our network can obtain better results than several state-of-the-art networks in both anytime classification and budgeted batch classification settings. the code is available at https://github.com/bigdata-qian/msnet-pytorch.",AB_0358
"in this paper, we consider the task of space-time video super-resolution (st-vsr), which can increase the spatial resolution and frame rate for a given video simultaneously. despite the remarkable progress of recent methods, most of them still suffer from high computational costs and inefficient long-range information usage. to alleviate these problems, we propose a bidirectional recurrence network (brn) with the optical-flow-reuse strategy to better use temporal knowledge from long-range neighboring frames for high-efficiency reconstruction. specifically, an efficient and memory-saving multi-frame motion utilization strategy is proposed by reusing the intermediate flow of adjacent frames, which considerably reduces the computation burden of frame alignment compared with traditional lstm-based designs. in addition, the proposed hidden state in brn is updated by the reused optical flow and refined by the feature refinement module (frm) for further optimization. moreover, by utilizing intermediate flow estimation, the proposed method can inference non-linear motion and restore details better. extensive experiments demonstrate that our optical-flow-reuse-based bidirectional recurrent network (ofr-brn) is superior to state-of-the-art methods in accuracy and efficiency. codes are available on url: https://github.com/hahazh/ofr-brn",AB_0358
"supervised segmentation can be costly, particularly in applications of biomedical image analysis where large scale manual annotations from experts are generally too expensive to be available. semi-supervised segmentation, able to learn from both the labeled and unlabeled images, could be an efficient and effective alternative for such scenarios. in this work, we propose a new formulation based on risk minimization, which makes full use of the unlabeled images. different from most of the existing approaches which solely explicitly guarantee the minimization of prediction risks from the labeled training images, the new formulation also considers the risks on unlabeled images. particularly, this is achieved via an unbiased estimator, based on which we develop a general framework for semi-supervised image segmentation. we validate this framework on three medical image segmentation tasks, namely cardiac segmentation on acdc2017, optic cup and disc segmentation on refuge dataset and 3d whole heart segmentation on mm-whs dataset. results show that the proposed estimator is effective, and the segmentation method achieves superior performance and demonstrates great potential compared to the other state-of-the-art approaches. our code and data will be released via https://zmiclab.github.io/projects.html, once the manuscript is accepted for publication.",AB_0358

AB,NO
"preoperative segmentation of parotid gland tumor regions using deep learning is of great significance for treatment decisions. however, there are still two major limitations: to the best of our knowledge, no networks are designed specifically for parotid gland tumor segmentation tasks; and neither convolutional neural network (cnn) nor transformer can extract both global and local feature solely. to address these issues, we first propose a pyramid convolutional transformer (pct) architecture based on the shrinking pyramid framework and fusion attention transformer cnn (ftc) block for parotid gland tumors segmentation. in this architecture, the shrinking pyramid framework can effectively capture parotid gland tumor image features with dense pixel by integrating multi-scale dependencies of images. and the ftc block is constructed to address complex and variable contour characteristics of parotid gland tumors, which combines transformer with cnn for preferable extracting global and local features of images by dual branch structure. the experimental results suggest that proposed pct achieved intersection-over-union (iou) of 0.8434 and dice similarity coefficient (dice) of 0.9151 on parotid gland tumor segmentation (pgtseg) dataset, and attained new state-of-the-art performance on multiple challenging benchmarks with iou of 0.8521 on monuseg and iou of 0.9080 on isic 2018. meanwhile, common backbones equipped with ftc block outperformed the baseline model. the code and models will be available at: https://github.com/twoverz/pct-pyramid-convolutional-transformer.",AB_0014
"although convolutional neural networks (cnns) have recently shown considerable progress in motion deblur-ring, most existing methods that adopt multi-scale input schemes are still challenging in accurately restoring the heavily-blurred regions in blurry images. several recent methods aim to further improve the deblurring effect using larger and more complex models, but these methods inevitably result in huge computing costs. to address the performance-complexity trade-off, we propose a multi-stage feature-fusion dense network (mffdnet) for motion deblurring. each sub-network of our mffdnet has the similar structure and the same scale of input. meanwhile, we propose a feature-fusion dense connection structure to reuse the extracted features, thereby improving the deblurring effect. moreover, instead of using the multi-scale loss function, we only calculate the loss function at the output of the last stage since the input scale of our sub-network is invariant. experimental results show that mffdnet maintains a relatively small computing cost while outperforming state-of-the-art motion-deblurring methods. the source code is publicly available at: https://github.com/caiguohs/mffdnet_ release.",AB_0014
"aiming at the defects of the sparrow search algorithm (ssa), such as a deficient optimization accuracy and low search efficiency, the sparrow search algorithm based on quantum computations and multi-strategy enhance-ment (qmessa) is proposed. firstly, based on a diversified initial population strategy, an improved circle chaotic mapping theory was proposed, and an initial population with more randomness and diversity was obtained by combining quantum computations with a quantum gate mutation mechanism. secondly, using an enhanced search strategy, an adaptive t-distribution and a new position update formula were constructed to accelerate the convergence and enhance its variability. finally, a dynamic evolution formula was designed for the precision elimination mechanism. based on this, individuals with poor fitness are replaced by new individuals generated using this formula. in addition, a new boundary control strategy was proposed. the convergence of qmessa was systematically proven, and the proposed algorithm was tested on 24 benchmark functions and cec 2017 functions. the experiment results as well as the results of a wilcoxon rank-sum test show that qmessa achieves a better comprehensive performance than ssa and other advanced optimization algorithms. finally, the superi-ority of qmessa was verified for several classical practical application problems. the source code of qmessa is available at https://ww2.mathworks.cn/matlabcentral/fileexchange/120013-project1-0.",AB_0014
"fine-grained nucleus classification is challenging because of the high inter-class similarity and intra-class variability. therefore, a large number of labeled data is required for training effective nucleus classification models. however, it is challenging to label a large-scale nucleus classification dataset comparable to imagenet in natural images, considering that high-quality nucleus labeling requires specific domain knowledge. in addition, the existing publicly available datasets are often inconsistently labeled with divergent labeling criteria. due to this inconsistency, conventional models have to be trained on each dataset separately and work independently to infer their own classification results, limiting their classification performance. to fully utilize all annotated datasets, we formulate the nucleus classification task as a multi-label problem with missing labels to utilize all datasets in a unified framework. specifically, we merge all datasets and combine their labels as multiple labels. thus, each data has one ground-truth label and several missing labels. we devise a base classification module that is trained using all data but sparsely supervised by the ground-truth labels only. we then exploit the correlation among different label sets by a label correlation module. by doing so, we can have two trained basic modules and further cross-train them with both ground-truth labels and pseudo labels for the missing ones. importantly, data without any ground-truth labels can also be involved in our framework, as we can regard them as data with all labels missing and generate the corresponding pseudo labels. we carefully re-organized multiple publicly available nucleus classification datasets, converted them into a uniform format, and tested the proposed framework on them. experimental results show substantial improvement compared to the state-of-the-art methods. the code and data are available at https://w-h-zhang.github.io/projects/dataset_merging/dataset_merging.html.",AB_0014
"elucidating and accurately predicting the druggability and bioactivities of molecules plays a pivotal role in drug design and discovery and remains an open challenge. recently, graph neural networks (gnns) have made remarkable advancements in graph-based molecular property prediction. however, current graph-based deep learning methods neglect the hierarchical information of molecules and the relationships between feature channels. in this study, we propose a well-designed hierarchical informative graph neural network (termed hignn) framework for predicting molecular property by utilizing a corepresentation learning of molecular graphs and chemically synthesizable breaking of retrosynthetically interesting chemical substructure (brics) fragments. furthermore, a plug-and-play feature-wise attention block is first designed in hignn architecture to adaptively recalibrate atomic features after the message passing phase. extensive experiments demonstrate that hignn achieves state-of-the-art predictive performance on many challenging drug discovery associated benchmark data sets. in addition, we devise a molecule-fragment similarity mechanism to comprehensively investigate the interpretability of the hignn model at the subgraph level, indicating that hignn as a powerful deep learning tool can help chemists and pharmacists identify the key components of molecules for designing better molecules with desired properties or functions. the source code is publicly available at https://github.com/idruglab/hignn.",AB_0014
"motivation the rapid development of spatial transcriptomics (st) approaches has provided new insights into understanding tissue architecture and function. however, the gene expressions measured at a spot may contain contributions from multiple cells due to the low-resolution of current st technologies. although many computational methods have been developed to disentangle discrete cell types from spatial mixtures, the community lacks a thorough evaluation of the performance of those deconvolution methods. results here, we present a comprehensive benchmarking of 14 deconvolution methods on four datasets. furthermore, we investigate the robustness of different methods to sequencing depth, spot size and the choice of normalization. moreover, we propose a new ensemble learning-based deconvolution method (endecon) by integrating multiple individual methods for more accurate deconvolution. the major new findings include: (i) cell2loction, rctd and spatialdwls are more accurate than other st deconvolution methods, based on the evaluation of three metrics: rmse, pcc and jsd; (ii) cell2location and spatialdwls are more robust to the variation of sequencing depth than rctd; (iii) the accuracy of the existing methods tends to decrease as the spot size becomes smaller; (iv) most deconvolution methods perform best when they normalize st data using the method described in their original papers; and (v) the integrative method, endecon, could achieve more accurate st deconvolution. our study provides valuable information and guideline for practically applying st deconvolution tools and developing new and more effective methods. availability and implementation the benchmarking pipeline is available at https://github.com/sunxqlab/st-deconvoulution. an r package for endecon is available at https://github.com/sunxqlab/endecon. supplementary information are available at bioinformatics online.",AB_0014
"keypoint-based object detection achieves better performance without positioning calculations and extensive prediction. however, they have heavy backbone, and high-resolution is restored using upsampling that obtain unreliable features. we propose a self-constrained parallelism keypoint-based lightweight object detection network (scpnet), which speeds inference, drops parameters, widens receptive fields, and makes prediction accurate. specifically, the parallel multi-scale fusion module (pmfm) with parallel shuffle blocks (psb) adopts parallel structure to obtain reliable features and reduce depth, adopts repeated multi-scale fusion to avoid too many parallel branches. the self-constrained detection module (scdm) has a two-branch structure, with one branch predicting corners, and employing entad offset to match high-quality corner pairs, and the other branch predicting center keypoints. the distances between the paired corners' geometric centers and the center keypoints are used for self-constrained detection. on ms-coco 2017 and pascal voc, scpnet's results are competitive with the state-of-the-art lightweight object detection. https://github.com/mengdie-wang/scpnet.git.",AB_0014
"wilson disease (wd) is a hereditary disorder of copper metabolism, resulting from mutations within atp7b. early diagnosis is essential for affected individuals. however, there are still patients with clinically suspected wd who do not have detectable pathogenic variants, which makes diagnosis difficult and delays treatment. this study included such patients from the authors' center and screened for the full-length sequence of atp7b by next-generation sequencing. newly identified synonymous and intronic variants were then analyzed with in silico tools. a minigene system was constructed to determine the pathogenicity of these variants in terms of splicing and blood rna extraction, and rt-pcr experiments were performed on several patients to verify the splicing alterations. the phenotypes of the patients were also analyzed. fourteen suspected pathogenic variants, including nine synonymous and five intronic variants, were detected in 12 patients with clinically suspected wd. among them, four synonymous variants (c.1050g>a, c.1122c>g, c.3243g>a, and c.4014t>a) and four intronic variants (c.1543 +40g>a, c.1707+6_1707+16del, c.1870-49a>g, and c.2731-67a>g) resulted in splicing changes in atp7b. after the above analysis, the diagnosis of wd could be confirmed in eight clinically suspected patients with wd who showed a late age of onset. (j mol diagn 2023, 25: 57e67; https:// doi.org/10.1016/j.jmoldx.2022.10.002)",AB_0014
"tropical cyclone intensity estimation (tie) is a fundamental study subject for tropical cyclone development, flood or landslide avoidance, etc. despite considerable efforts, two main challenges remain unresolved in this critical endeavor. the first challenge is that the tie task is frequently conducted as a coarse-grained recognition problem rather than a fine-grained one. the second challenge is that the prediction fails to consider general wind speed information. to conquer these two challenges, we offer a novel model, namely tropical cyclone intensity estimation from a fine-grained perspective with the graph convolution neural network (tfg-net). it is composed of three key components, viz., the backbone, the fine-grained tropical cyclone features extractor (ftfe), and the wind scale transition rule generator (wtrg), which aim at extracting general spatial features, subtle spatial features, and general wind speed information, respectively. to validate the proposed method, extensive experiments on a well-known real-world tropical dataset named gridsat were carried out. following the standard benchmark task setting that the model estimates the wind speed from a given satellite image, the proposed tfg-net reaches 11.12 knots in the rmse metric, which outperforms 33.33%, 2.54% to the traditional method and the state-of-the-art deep learning method, respectively. the code is available on github: https://github.com/xuguangning1218/ti_estimation and its reproductive result is available on code ocean: ",AB_0014
"automatically assessing academic papers has enormous potential to reduce peer-review burden and individual bias. existing studies strive for building sophisticated deep neural networks to identify academic value based on comprehensive data, e.g., academic graphs and full papers. however, these data are not always easy to access. and the content of the paper rather than other features outside the paper should matter in a fair assessment. furthermore, while bert models can maintain general semantics by pre-training on large-scale corpora, they tend to be over-smoothing due to stacked self-attention layers among unfiltered input tokens. therefore, it is nontrivial to figure out distinguishable value of an academic paper from its limited content. in this study, we propose a novel deep neural network, namely dual-view graph convolutions enhanced bert (dgc-bert), for academic paper acceptance estimation. we combine the title and abstract of the paper as input. then, a pre-trained bert model is employed to extract the paper's general representations. apart from hidden representations of the final layer, we highlight the first and last few layers as lexical and semantic views. in particular, we re-examine the dual-view filtered self-attention matrices via constructing two graphs, respectively. after that, two multi-hop graph convolutional networks (gcns) are separately employed to capture pivotal and distant dependencies between the tokens. moreover, the dual-view representations are facilitated by each other with biaffine attention modules. and a re-weighting gate is proposed to further streamline the dual-view representations with the help of the original bert representation. finally, whether the submitted paper could be acceptable is predicted based on the original language model features cooperated with the dual-view dependencies. extensive data analyses and the full paper based mhcnn studies provide insights into the task and structural functions. comparison experiments on two benchmark datasets demonstrate that the proposed dgc-bert significantly outperforms alternative approaches, especially the state-of-the-art models like mhcnn and bert variants. additional analyses reveal significance and explainability of the proposed modules in the dgc-bert. our codes and settings have been released on github (https://github.com/ecnu-text-computing/dgc-bert).",AB_0014

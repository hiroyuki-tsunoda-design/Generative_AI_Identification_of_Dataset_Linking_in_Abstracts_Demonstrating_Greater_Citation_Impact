AB,NO
"fine-grained visual categorization (fgvc) is a challenging task due to similar visual appearances between various species. previous studies always implicitly assume that the training and test data have the same underlying distributions, and that features extracted by modern backbone architectures remain discriminative and generalize well to unseen test data. however, we empirically justify that these conditions are not always true on benchmark datasets. to this end, we combine the merits of invariant risk minimization (irm) and information bottleneck (ib) principle to learn invariant and minimum sufficient (ims) representations for fgvc, such that the overall model can always discover the most succinct and consistent fine-grained features. we apply the matrix-based renyi's..-order entropy to simplify and stabilize the training of ib; we also design a ''soft environment partition scheme to make irm applicable to fgvc task. to the best of our knowledge, we are the first to address the problem of fgvc from a generalization perspective and develop a new informationtheoretic solution accordingly. extensive experiments demonstrate the consistent performance gain offered by our ims. code is available at: https://github.com/sye- hub/ims.",AB_0333
"quantum neural network (qnn) is a neural network model based on the principles of quantum mechanics. the advantages of faster computing speed, higher memory capacity, smaller network size and elimination of catastrophic amnesia make it a new idea to solve the problem of training massive data that is difficult for classical neural networks. however, the quantum circuit of qnn are artificially designed with high circuit complexity and low precision in classification tasks. in this paper, a neural architecture search method eqnas is proposed to improve qnn. first, initializing the quantum population after image quantum encoding. the next step is observing the quantum population and evaluating the fitness. the last is updating the quantum population. quantum rotation gate update, quantum circuit construction and entirety interference crossover are specific operations. the last two steps need to be carried out iteratively until a satisfactory fitness is achieved. after a lot of experiments on the searched quantum neural networks, the feasibility and effectiveness of the algorithm proposed in this paper are proved, and the searched qnn is obviously better than the original algorithm. the classification accuracy on the mnist dataset and the warship dataset not only increased by 5.31% and 4.52%, respectively, but also reduced the parameters by 21.88% and 31.25% respectively. code will be available at https://gitee.com/pcyslist/models/tree/master/research/cv/eqnas, and https://github.com/pcyslist/eqnas.",AB_0333
"deep neural networks often suffer performance degradation when the testing data distribution differs significantly from the training data distribution. to address this problem, most domain generalization (dg) approaches focus on learning domain-invariant features from multiple source domains. however, enforcing model invariance among different domains can also result in information that is not shared across training domains being discarded, even though it may still be relevant to unseen domains. we argue that a generalized model should be discriminative towards comprehensive features across different domains. to avoid unexpected information loss, we propose a two-stage learning scheme, named domain-aware knowledge distillation (dakd). in the first stage, we pre-train a parameter-efficient multi-expert model, where each expert is trained to be responsible for a specific source domain and preserve the domain-specific features. in the second stage, following the traditional knowledge distillation formulation, we train a new student network assisted by the pre-trained experts, where the prediction of the student for a certain domain is regularized by the soft output of the corresponding expert. a comprehensive ablation study and analysis highlight that our distilled model can preserve more source-domain specific features, and obtain higher accuracy on unseen domains compared to its counterpart without distillation. we discuss the relationship between the generalization risk bound theory and our method. the upper bound is reduced by mitigating source-target domain discrepancy and reducing risk on source domains. experiments demonstrate that our method provides state-of-the-art performance on pacs and other more challenging datasets such as office-home and domainnet. the source code is available at https://github.com/zzq321/dakd.git",AB_0333
"inspired by the biological evolution, this paper proposes an evolutionary synthesis mechanism to automatically evolve densenet towards high sparsity and efficiency for medical image classification. unlike traditional automatic design methods, this mechanism generates a sparser offspring in each generation based on its previous trained ancestor. concretely, we use a synaptic model to mimic biological evolution in the asexual reproduction. each generation's knowledge is passed down to its descendant, and an environmental constraint limits the size of the descendant evolutionary densenet, moving the evolution process towards high sparsity. additionally, to address the limitation of ensemble learning that requires multiple base networks to make decisions, we propose an evolution-based ensemble learning mechanism. it utilises the evolutionary synthesis scheme to generate highly sparse descendant networks, which can be used as base networks to perform ensemble learning in inference. this is specially useful in the extreme case when there is only a single network. finally, we propose the meednets (medical image classification via ensemble bio-inspired evolutionary densenets) model which consists of multiple evolutionary densenet-121s synthesised in the evolution process. experimental results show that our bio-inspired evolutionary densenets are able to drop less important structures and compensate for the increasingly sparse architecture. in addition, our proposed meednets model outperforms the state-of-the-art methods on two publicly accessible medical image datasets. all source code of this study is available at https://github.com/hengdezhu/meednets.",AB_0333
"tensor-based multi-view clustering has attracted intensive attention due to the effectiveness of exploiting multi-view data information. however, most existing methods purely aim to explore the consistency of different views while neglecting the inherent difference between views, which may lead to incomplete modeling and affect the final clustering performance. to handle this problem, in this paper, we unify the consistency and specificity to model the multi-view data in a tensor manner. specifically, we learn multiple candidate graphs corresponding to all views through self-expressiveness learning. then these candidate graphs are decomposed into two sets of graphs, i.e., consistent graphs and specific graphs, respectively. after that, these consistent graphs are stacked into a tensor to exploit the high-order structure information while the specific graphs are used to capture the inherent difference in each view, such that a refined consensus affinity graph can be obtained for spectral clustering. the established model is dubbed consider high-order consistency for multi-view clustering (choc-mvc), and its optimal problem can be efficiently solved by the alternating direction method of multipliers (admm). the experimental results demonstrate the effectiveness of our proposed method. the source code is available at https://github.com/haoranli50/choc-mvsc.",AB_0333
"weakly supervised semantic segmentation (wsss) can obtain pseudo-semantic masks through a weaker level of supervised labels, reducing the need for costly pixel-level annotations. however, the general class activation map (cam)-based pseudo-mask acquisition method suffers from sparse coverage, leading to false positive and false negative regions that reduce accuracy. we propose a wsss method based on local superpixel transformation that combines superpixel theory and image local information. our method uses a superpixel local consistency weighted cross-entropy loss to correct erroneous regions and a post-processing method based on the adjacent superpixel affinity matrix (asam) to expand false negatives, suppress false positives, and optimize semantic boundaries. our method achieves 73.5% miou on the pascal voc 2012 validation set, which is 2.5% higher than our baseline eps and 73.9% on the test set, and the asam post-processing method is validated on several state-of-the-art methods. if our paper is accepted, our code will be published at https://github.com/jimmyma99/spl.",AB_0333
"assessing the quality of actions in videos is a challenging vision task, as the relationship between videos and action scores can be difficult to model. consequently, extensive research has been conducted on action quality assessment (aqa) in the literature. traditional aqa methods treat the problem as a regression task to learn the underlying mappings between videos and action scores. however, previous approaches overlook the presence of data uncertainty in aqa datasets. to address aleatoric uncertainty, we have developed a plug-and-play module called distribution auto-encoder (dae). dae encodes videos into distributions and utilizes the reparameterization trick to sample scores, which enables a more accurate mapping between videos and scores. additionally, we use a likelihood loss to learn the uncertainty parameters. we have evaluated our approach on publicly available datasets, and extensive experiments demonstrate that dae achieves state-of-the-art performance with the spearman's correlation metric of 82.58%, 92.32%, and 76.00% on the aqa-7, mtl-aqa, and jigsawss datasets, respectively. furthermore, plug-and-play experiments also demonstrate the extensibility of dae. our code is available at https://github.com/infox-seu/dae-aqa.",AB_0333
"referring expression segmentation (res), which is aimed at localizing and segmenting the target according to the given language expression, has drawn increasing attention. existing methods jointly consider the localization and segmentation steps, which rely on the fused visual and linguistic features for both steps. we argue that the conflict between the purpose of identifying an object and generating a mask limits the res performance. to solve this problem, we propose a parallel position-kernel-segmentation pipeline to better isolate and then interact the localization and segmentation steps. in our pipeline, linguistic information will not directly contaminate the visual feature for segmentation. specifically, the localization step localizes the target object in the image based on the referring expression, and then the visual kernel obtained from the localization step guides the segmentation step. this pipeline also enables us to train res in a weakly-supervised way, where the pixel-level segmentation labels are replaced by click annotations on center and corner points. the position head is fully-supervised and trained with the click annotations as supervision, and the segmentation head is trained with weakly-supervised segmentation losses. to validate our framework on a weakly-supervised setting, we annotated three res benchmark datasets (refcoco, refcoco+ and refcocog) with click annotations. our method is simple but surprisingly effective, outperforming all previous state-of-the-art res methods on fully- and weakly-supervised settings by a large margin. the code and dataset will be released on https://github.com/detectiveli/pks.git.",AB_0333
"video-based human-object interaction recognition is a challenging task since the state of objects as well as their correlations change constantly in the video. existing methods mainly use 3dcnn or use separate components (e.g., gcn + rnn) to model the spatial correlation or the temporal correlation respectively, but ignore modeling spatio-temporal correlations simultaneously and long-term temporal dynamics of objects. in this paper, we propose a novel model, named spatio-temporal interaction graph parsing networks (stigpn), for human-object interaction recognition in videos. stigpn captures both spatial and temporal correlations simultaneously and thus can capture intra-frame and inter-frame dependencies efficiently and effectively. to model long-term temporal dynamics of objects, we introduce spatio-temporal feature enhancement, which can improve the detection of the salient human-object interaction pairs. we explore three types of spatio-temporal graph convolutions to simultaneously capture the spatio-temporal correlations and assess their effectiveness as the basic building block of stigpn. extensive experiments on cad-120, something-else and charades datasets show that our proposed solution leads to competitive results compared with the state-of-the-art methods. code for stigpn is available at: https://github.com/ningwang2049/stigpn2",AB_0333
"printed photographs can be easily warped, wrinkled, and even deteriorated over time. existing methods treat the restoration of scratches as a pure inpainting problem that neglects the underlying corrupted contextual knowledge. however, important underlying contents are hidden behind the scratches, which are essential hints for producing a semantically consistent result. motivated by this insight, we explore how to harmonize the scratch-free features and noisy but essential scratch features to produce a visually consistent restoration. specifically, in this paper, we propose an automatic retouching approach for scratched photographs with the aid of scratch/background context. we explicitly process scratch and background context in two stages. in the first stage, we mainly extract global scratch features, while the mask is introduced in the second stage to filter out and inpaint the scratches. both contexts are carefully reciprocated for a faithful restoration. particularly, we propose a scratch contextual assisted module (scam) to adaptively learn texture within the detected mask. this module utilizes the distance between the scratch mask-out feature and scratch encoder feature for modeling the pixel-wise correspondence, which determines the importance of the encoder feature within the scratch mask. furthermore, to facilitate the evaluation of scratch restoration methods, we create two new scratched photo datasets which have 238 scratch/scratch-free photo pairs to promote the development in the scratch restoration field, namely old scratched photo dataset (ospd) and modern scratched photo dataset (mspd). extensive experimental results on the proposed datasets demonstrate that our model outperforms existing methods. to extend the application, we also perform the proposed method on video samples and obtain visual-pleasing results. the code can be found at https://github.com/cwyyt/contextual-assisted-scratched-photo-restoration.",AB_0333

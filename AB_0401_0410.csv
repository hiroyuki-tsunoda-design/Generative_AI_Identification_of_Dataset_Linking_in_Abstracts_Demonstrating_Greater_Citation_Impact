AB,NO
"fake news with multimedia data is ubiquitous on the internet nowadays, and it is difficult for users to distinguish them. therefore, it is necessary to design automatic multi-modal fake news detectors. however, the existing works make poor utilization of visual information, and do not fully consider the semantic interaction of multi-modal data. in this paper, we propose the multi-modal transformer using two-level visual features (mttv) for fake news detection. first, we model texts and images from news uniformly as sequences that can be processed by transformer, and two-level visual features, i.e. global feature and entity-level feature, are used to improve the utilization of news images. second, we extend the transformer model for natural language processing to multi-modal transformer which can make multi-modal data interact fully and capture the semantic relationships between them. in addition, we propose a scalable classifier to improve the classification balance of fine-grained fake news detection with the problem of class imbalance. extensive experiments on two public datasets demonstrate that our method achieved significant performance improvement compared to the state-of-the-art methods. the source code is available at https://github.com/cqu-wb/mttv.",AB_0041
"in this paper, we study how to denoise medical ultrasound images and improve the performance of instance segmentation using deep learning technology. since medical ultrasound images usually contain a lot of noises, we first propose a novel unsupervised learning approach called dual image (di) for denoising of medical ultrasound images. di consists of three main features. firstly, unlike many existing supervised denoising methods, it does not need clean medical ultrasound images for denoising. instead, it uses computed tomography (ct) images and the noise patches extracted from medical ultrasound images for denoising. secondly, to effectively select noise patches from medical ultrasound images, a patch selection algorithm based on entropy is formulated. thirdly, to minimize structure variation of denoised medical ultrasound images, a new reconstruction block is designed for combining the structural information from the structural enhancement block. after denoising, since medical ultrasound images are usually poor in features, to further improve the instance segmentation performance, we extend solov2 to segmenting on ultrasound image (soui) by proposing the double feature pyramid network (d-fpn) and mask fusion branch to strengthen the communication and fusion of different feature layers. extensive experiments have been performed to study the performance of di and soui using practical medical ultrasound images. we demonstrate that di can greatly improve the quality of medical ultrasound images and minimize structure variation of denoised medical ultrasound images. soui gives 53.7% ap(average precision) on practical medical ultrasound images, and outperforms most the state-of-the-art instance segmentation methods including solov2. code is available at: https://github.com/ztt0821/soui.",AB_0041
"data augmentation has been an essential technique to increase the amount and diversity of datasets, thus improving deep learning models. to pursue further performance, several automated data augmentation approaches have recently been proposed to find data augmentation policies automatically. however, there are still some key issues that deserve further exploration, i.e., a precise policy search space definition, the instructive policy evaluation method, and the low computational cost of policy search. in this paper, we propose a novel method named bo-aug that attempts to solve the above issues. empirical verification on three widely used image classification datasets shows that the proposed method can achieve state-of-the-art or comparable performance compared with advanced automated data augmentation methods, with a relatively low cost. our code is available at https://github.com/zhangcx19/bo-aug.",AB_0041
"the deployment of the sensor nodes (sns) always plays a decisive role in the system performance of wireless sensor networks (wsns). in this work, we propose an optimal deployment method for practical heterogeneous wsns which gives a deep insight into the trade-off between the reliability and deployment cost. specifically, this work aims to provide the optimal deployment of sns to maximize the coverage degree and connection degree, and meanwhile minimize the overall deployment cost. in addition, this work fully considers the heterogeneity of sns (i.e. differentiated sensing range and deployment cost) and three-dimensional (3-d) deployment scenarios. this is a multi-objective optimization problem, non-convex, multimodal and np-hard. to solve it, we develop a novel swarm-based multi-objective optimization algorithm, known as the competitive multi-objective marine predators algorithm (cmompa) whose performance is verified by comprehensive comparative experiments with ten other state-of-the-art multi-objective optimization algorithms. the computational results demonstrate that cmompa is superior to others in terms of convergence and accuracy and shows excellent performance on multimodal multi-objective optimization problems. sufficient simulations are also conducted to evaluate the effectiveness of the cmompa based optimal sns deployment method. the results show that the optimized deployment can balance the trade-off among deployment cost, sensing reliability and network reliability. the source code is available on https://github.com/inet-wzu/cmompa.",AB_0041
"rgb-t salient object detection (sod) combines thermal infrared and rgb images to overcome the light sensitivity of rgb images in low-light conditions. however, the quality of rgb-t images could be unreliable under complex imaging scenarios, and direct fusion of these low-quality images will lead to sub-optimal detection results. in this paper, we propose a novel modal complementary fusion network (mcfnet) to alleviate the contamination effect of low-quality images from both global and local perspectives. specifically, we design a modal reweight module (mrm) to evaluate the global quality of images and adaptively reweight rgb-t features by explicitly modelling interdependencies between rgb and thermal images. furthermore, we propose a spatial complementary fusion module (scfm) to explore the complementary local regions between rgb-t images and selectively fuse multi-modal features. finally, multi-scale features are fused to obtain the salient detection result. experiments on three rgb-t benchmark datasets demonstrate that our mcfnet achieved outstanding performance compared with the latest state-of-the-art methods. we have also achieved competitive results in rgb-d sod tasks, which proves the generalization of our method. the source code is released at https://github.com/dotaball/mcfnet.",AB_0041
"question answering over temporal knowledge graphs is an important topic in question answering, which aims to find an entity or timestamp to answer temporal reasoning questions from temporal knowledge graphs. answering complex questions remains a major challenge for question answering over temporal knowledge graphs because it is associated with complex temporal reasoning. the performance of the existing state-of-the-art model falls short when the question contains constraints (e.g., 'before/after', 'first/lase and 'during') that require complex temporal reasoning based on multiple relevant facts. in this paper, we propose an improving reasoning method called the complex temporal reasoning network, which improves the complex temporal reasoning for temporal reasoning questions. for each question, we capture implicit temporal features and relation representation and then integrate them to generate implicit temporal relation representation. the experimental results on the cronquestions dataset demonstrate that our method significantly outperforms all baselines. in particular, we demonstrate the effectiveness of our method on complex questions. the source code of ctrn will be available at https://github.com/2399240664/ctrn.",AB_0041
"in this paper, a robust infrared and visible image fusion scheme that joins a dual-branch multi-receptive-field neural network and a color vision transfer algorithm is designed to aggregate infrared and visible video sequences. the proposed method enables the fused image to effectively recognize thermal objects, contain rich texture information and ensure visual perception quality. the fusion network is an integrated encoder-decoder modal with a multi-receptive-field attention mechanism that is implemented via hybrid dilated convolution (hdc) and a series of convolution layers to form an unsupervised framework. specifically, the multi-receptive-field attention mechanism aims to extract comprehensive spatial information to enable the encoder to separately focus on the substantial thermal radiation from the infrared modal and the environmental characteristics from the visible modal. in addition, to ensure that the fused image has rich color, high fidelity and steady brightness, a color vision transfer method is proposed to recolor the fused gray results by deriving a map from the visible image serving as a reference. extensive experiments verify the importance and robustness of each step in the subjective and objective evaluation and demonstrate that our work represents a trade-off among color fidelity, fusion performance and computational efficiency. moreover, we will publish our research content, data and code publicly at https://github.com/dzsyunnan/rgb-tir-image-fusion.",AB_0041
"during the outbreak of a specific social event, end-to-end automatic opinion summarization is needed to analyze the surge of text related to the event. however, in the chinese domain, the major existing works either emphasize salient aspects or sentence extraction in a discrete fashion with no consideration of human readability, or focus on short chinese text. to remedy the drawbacks of these methods, in this paper, an event-based opinion summarization model for long chinese text with a parameter fusion mechanism is proposed to address the human readability and imbalance issue of the event-based datasets. in particular, to capture the sentiment information in the source article in an end-to-end manner, a sentiment attention layer and a sentiment cross-entropy loss function are presented. in addition, when facing the issue of imbalance in event-based datasets, a parameter fusion mechanism inspired by the federated learning is proposed, which can further improve the human readability of the output. finally, the efficacy of the proposed model is substantiated via comprehensive experiments performed on the collected event-based datasets, the chinese long text summarization dataset (clts), and the cable news network/daily mail (cnn/dm) dataset using recall-oriented understudy for gisting evaluation (rouge) and sentiment classification accuracy metrics. in addition, the source code is made available at https://github. com/shawnyoung97/opinion-sum.",AB_0041
"center and scale prediction (csp) first introduced the anchor-free method to the field of pedestrian detection. pedestrian detection often occurs in complex scenes subject to occlusion, and it is difficult to extract pedestrian features in a single centre point prediction in csp. to solve this problem, this paper presents a multi-branch detection network (mbdn) based on trigger attention. firstly, a multi-centre point prediction branch feature extraction model (multi-centre) is proposed to solve the problem of csp missed detections in occlusion scenarios. secondly, a novel trigger attention module is designed. the module uses visible parts as triggers to automatically learn the weight relationships of multiple branches, let the network automatically learn the confidence of the centre points of different branches, and automatically strengthen the branch where the visible area on the feature map is located. finally, a channel non-maximum suppression (nms) module is used in the mbdn network to reduce the redundant bounding boxes. then experiments results show that the log-average missing rate (mr-2) of the heavy subset is reduced from 49.63% to 45.51% while maintaining the performance on a reasonable subset. code and models can be accessed at (https://github.com/weidalin/mbdn).",AB_0041
"in recent years, neural architecture search (nas) has achieved unprecedented development because of its ability to automatically achieve high-performance neural networks in various tasks. among these, the evolutionary neural architecture search (enas) has impressed the researchers due to the excellent heuristic exploration capability. however, the evolutionary algorithm-based nas are prone to the loss of population diversity in the search process, causing that the structure of the surviving individuals is exceedingly similar, which will lead to premature convergence and fail to explore the search space comprehensively and effectively. to address this issue, we propose a novel indicator, named architecture entropy, which is used to measure the architecture diversity of population. based on this indicator, an effective sampling strategy is proposed to select the candidate individuals with the potential to maintain the population diversity for environmental selection. in addition, an unified encoding scheme of topological structure and computing operation is designed to efficiently express the search space, and the corresponding population update strategies are suggested to promote the convergence. the experimental results on several image classification benchmark datasets cifar-10 and cifar-100 demonstrate the superiority of our proposed method over the state-of-the-art comparison ones. to further validate the effectiveness of our method in real applications, our proposed nas method is applied in the identification of lumbar spine x-ray images for osteoporosis diagnosis, and can achieve a better performance than the commonly used methods. our source codes are available at https://github.com/ labyrinthineleo/aemonas.",AB_0041

AB,NO
"circular rnas (circrnas) have been found to have the ability to encode proteins through internal ribosome entry sites (iress), which are essential rna regulatory elements for cap-independent translation. identification of ires elements in circrna is crucial for understanding its function. previous studies have presented ires predictors based on machine learning techniques, but they were mainly designed for linear rna ires. in this study, we proposed deepcip (deep learning method for circrna ires prediction), a multimodal deep learning approach that employs both sequence and structural information for circrna ires prediction. our results demonstrate the effectiveness of the sequence and structure models used by deepcip in feature extraction and suggest that integrating sequence and structural information efficiently improves the accuracy of prediction. the comparison studies indicate that deepcip outperforms other comparative methods on the test set and real circrna ires dataset. furthermore, through the integration of an interpretable analysis mechanism, we elucidate the sequence patterns learned by our model, which align with the previous discovery of motifs that facilitate circrna translation. thus, deepcip has the potential to enhance the study of the coding potential of circrnas and contribute to the design of circrna-based drugs. deepcip as a standalone program is freely available at https://g ithub.org/zjupgx/deepcip.",AB_0154
"currently, the primary focus of 3d point-based detectors is to enhance their performance by primarily increasing the recall rate of foreground points at the semantic level. however, this approach is suboptimal. on one hand, ground-truth annotations of 3d bounding boxes are inherently ambiguous due to occlusions, signal distortion, or manual annotation errors, which can obscure genuine semantic information. on the other hand, the saliency of each point varies. in this paper, we propose spsnet based on bayes theorem to explore the mapping relationship between the sampled point and the corresponding bounding box, which we call point stability. this is a plug-and-play module and used as the basis for downsampling instead of relying on semantic information obtained through hard supervision of 3d bounding boxes. we incorporate the proposed method into the most popular point-based detector, ia-ssd, called spsnet-ia. on the challenging kitti validation set, with only changes to the downsampling strategy, it obtains 1.18, 2.78 and 2.96 gains for the metric of ap3d on the easy, moderate and hard levels, respectively. in addition, spsnet-ia outperforms all published point based approaches by a large margin and ranks 1st among single-modal methods. we also design qualitative and quantitative experiments to explain the meaning of stability learned from spsnet. these additional experiments demonstrate that spsnet is not only a performance-enhancing model but also a saliency analysis model. the code is available at https://github.com/alanliangc/spsnet.git.",AB_0154
"the use of drones to observe ships is an effective means of maritime surveillance. however, the object scale from drone-captured images changes dramatically, presenting a significant challenge for ship detection. additionally, the limited computing resources on drones make it difficult to achieve fast detection speed. to address these issues, we propose an efficient deep learning based network, namely the yolov5-odconvnext, for ship detection from drone-captured images. yolov5-odconvnext is a more accurate and faster network designed to improve the efficiency of maritime surveillance. based on yolov5, we implement omni-dimensional convolution (odconv) in the yolov5 backbone to boost the accuracy without increasing the network width and depth. we also replace the original c3 block with a convnext block in yolov5 backbone to accelerate detection speed with only a slight decline in accuracy. we test our model on a self-constructed ship detection dataset containing 3200 images captured by drones or with a drone view. the experimental results show that our model achieves 48.0% ap, exceeding the accuracy of yolov5s by 1.2% ap. the detection speed of our network is 8.3 ms per image on an nvidia rtx3090 gpu, exceeding the detection speed of yolov5s by 13.3%. our code is available at https://github.com/chengshuxiao/yolov5-odconvnext.",AB_0154
"background: to explore the effectiveness of standardized first-trimester ultrasound screening (fts) in detecting fetal structural abnormalities in a non-selective population. methods: a retrospective study was performed on 7523 fetuses (6376 single and 569 twin pregnancies) who underwent fts between 11 and 13(+6) weeks' gestation. all fetuses received anatomy scans using a standardized pro-tocol. results: 147 fetuses (133 single and 7 twin pregnancies) were lost to follow up. of the remaining 7376 fetuses, 119 (1.61%, 119/7376) developed structural malformations, with 64 cases (53.8%, 64/119) identified during the first trimester. the remaining cases were detected during the second trimester (24.4%, 29/119), the third trimester (1.68%, 2/119), and postnatally (20.2%, 24/119). there were 4 cases of suspected ventricular septal defect (vsd) by fts, which were later confirmed to be normal. the sensitivity, specificity, positive predictive value (ppv), and negative predictive value (npv) for fts were 54.2%, 99.9%, 94.1%, and 99.3%, respectively. forty eight fetuses, accounting for 10.6% of the total (452), with thickened nuchal translucency (nt) (above the 95th percentile) showed structural malformations. this was significantly higher than the prevalence of structural abnormalities found in fetuses with normal nt (1.0%, 71/6924) (p < 0.01). conclusions: standardized fts is highly effective in detecting fetal structural malformations early, with impressive specificity, ppv, and npv. increased nt suggests detailed anatomy screening and helps guide treatment. however, while standardized fts is an invaluable tool, it cannot fully replace the sensitivity of second-and third-trimester ultrasound screening. clinical trial registration: the study was registered at https://www.chictr.org.cn (registration number chictr-soc-17010976).",AB_0154
"background: cardiac surgery-associated acute kidney injury (csa-aki) is a major complication that results in short-and long-term mortality among patients. here, we adopted machine learning algorithms to build prediction models with the overarching goal of identi-fying patients who are at a high risk of such unfavorable kidney outcomes. methods: a total of 1686 patients (development cohort) and 422 patients (validation cohort), with 126 pre-and intra-operative variables, were recruited from the first medical centre and the sixth medical centre of chinese pla general hospital in beijing, china, respectively. analyses were performed using six machine learn-ing techniques, namely k-nearest neighbor, logistic regression, decision tree, random forest (rf), support vector machine, and neural network, and the approach score, a previously established risk score for csa-aki. for model tuning, optimal hyperparameter was achieved by using gridsearch with 5-fold cross-validation from the scikit-learn library. model performance was externally assessed via the receiver operating characteristic (roc) and decision curve analysis (dca). explainable machine learning was performed using the python shapley additive explanation (shap) package and seaborn library, which allow the calculation of marginal contributory shap value. results: 637 patients (30.2%) developed csa-aki within seven days after surgery. in the external validation, the rf classifier exhibited the best performance among the six machine learning techniques, as shown by the roc curve and dca, while the traditional approach risk score showed a relatively poor performance. further analysis found no specific causative factor contributing to the development of csa-aki; rather, the development of csa-aki appeared to be a complex process resulting from a complex interplay of multiple risk factors. the shap summary plot illustrated the positive or negative contribution of rf-top 20 variables and extrapolated risk of developing csa-aki at individual levels. the seaborn library showed the effect of each single feature on the model output of the rf prediction. conclusions: efficient machine learning approaches were successfully established to predict patients with a high probability of developing acute kidney injury after cardiac surgery. these findings are expected to help clinicians to optimize treatment strategies and minimize postoperative complications. clinical trial registration: the study protocol was registered at the clinicaltrials registration system (https://www.clinicaltrials.gov/, #nct04966598) on july 26, 2021.",AB_0154
"accurate spatial distribution maps of paddy rice played crucial roles in food security and market stability. decades-spanning landsat images were useful for long-term paddy rice mapping. however, it still remained challenging to achieve consistent paddy rice mapping using the landsat series images due to many factors such as sparse observations, frequent weather contamination, and shortage of training samples. to address these challenges, this study proposed a flexible phenology-assisted supervised paddy rice (pspr) mapping framework on google earth engine (gee). this was achieved by utilizing the automation of the phenological methods, training data generation and purification, and the all-season classification capacity of the machine learning methods. we demonstrated the method by generating high-resolution 30-m paddy rice maps of heilongjiang province of china from 1990 to 2020. the derived rice maps were validated using abundant reference samples, four existing paddy rice products, and available agricultural statistics. the result showed that improved performance was verified in comparison to previous studies and a high linear relationship was observed with an average r2 of 0.993. based on the spatiotemporal analysis, it was discovered that the rice planting in heilongjiang has significantly shifted northward in the last three decades and this northward shift surprisingly appeared earlier than the previous studies, which was to our best knowledge first to be revealed in related studies. the multi-year dataset is useful for rice monitoring, water management, and policy making. all data and codes used in this study can be accessed on github (https://github.com/mkgenesis/pspr-rice-hlj).",AB_0154
"accurately reconstructing a three-dimensional (3d) ocean sound speed field (ssf) is essential for various ocean acoustic applications, but the sparsity and uncertainty of sound speed samples across a vast ocean region make it a challenging task. to tackle this challenge, a large body of reconstruction methods has been developed, including spline interpolation, matrix/tensor-based completion, and deep neural networks (dnns)-based reconstruction. however, a principled analysis of their effectiveness in 3d ssf reconstruction is still lacking. this paper performs a thorough analysis of the reconstruction error and highlights the need for a balanced representation model that integrates expressiveness and conciseness. to meet this requirement, a 3d ssf-tailored tensor dnn is proposed, which uses tensor computations and dnn architectures to achieve remarkable 3d ssf reconstruction. the proposed model not only includes the previous tensor-based ssf representation model as a special case but also has a natural ability to reject noise. the numerical results using the south china sea 3d ssf data demonstrate that the proposed method outperforms state-of-the-art methods. the code is available at https://github.com/oceanstarlab/tensor-neuralnetwork. vc 2023 acoustical society of america. ",AB_0154
"recent decades have witnessed a trend that the echo state network (esn) is widely utilized in field of time series prediction due to its powerful computational abilities. however, most of the existing research on esn is conducted under the assumption that data is free of noise or polluted by the gaussian noise, which lacks robustness or even fails to solve real-world tasks. this work handles this issue by proposing a probabilistic regularized esn (presn) with robustness guaranteed. specifically, we design a novel objective function for minimizing both the mean and variance of modeling error, and then a scheme is derived for getting output weights of the presn. furthermore, generalization performance, robustness, and unbiased estimation abilities of the presn are revealed by theoretical analyses. finally, experiments on a benchmark dataset and two real-world datasets are conducted to verify the performance of the proposed presn. the source code is publicly available at https://github.com/longjin-lab/probabilistic-regularized-echo-state-network.",AB_0154
"a high-quality genome is the basis for studies on functional, evolutionary, and comparative genomics. the majority of attention has been paid to the solution of complex chromosome structures and highly repetitive sequences, along with the emergence of a new 'telomere-to-telomere (t2t) assembly' era. however, the bioinformatic tools for the automatic construction and/or characterization of t2t genome are limited. here, we developed a user-friendly web toolkit, quartet, which currently includes four modules: assemblymapper, gapfiller, teloexplorer, and centrominer. first, assemblymapper is designed to assemble phased contigs into the chromosome-level genome by referring to a closely related genome. then, gapfiller would endeavor to fill all unclosed gaps in a given genome with the aid of additional ultra-long sequences. finally, teloexplorer and centrominer are applied to identify candidate telomere and centromere as well as their localizations on each chromosome. these four modules can be used alone or in combination with each other for t2t genome assembly and characterization. as a case study, by adopting the entire modular functions of quartet, we have achieved the actinidia chinensis genome assembly that is of a quality comparable to the reported genome hongyang v4.0, which was assembled with the addition of manual handling. further evaluation of centrominer by searching centromeres in arabidopsis thaliana and oryza sativa genomes showed that quartet is capable of identifying all the centromeric regions that have been previously detected by experimental methods. collectively, quartet is an efficient toolkit for studies of large-scale t2t genomes and can be accessed at http://www.atcgn.com:8080/quartet/home.html without registration.",AB_0154
"resource- and time-consuming biological experiments are unavoidable in traditional drug discovery, which have directly driven the evolution of various computational algorithms and tools for drug-target interaction (dti) prediction. for improving the prediction reliability, a comprehensive platform is highly expected as some previously reported webservers are small in scale, single-method, or even out of service. in this study, we integrated the multiple-conformation based docking, 2d/3d ligand similarity search and deep learning approaches to construct a comprehensive webserver, namely d3carp, for target prediction and virtual screening. specifically, 9352 conformations with positive control of 1970 targets were used for molecular docking, and approximately 2 million target-ligand pairs were used for 2d/3d ligand similarity search and deep learning. besides, the positive compounds were added as references, and related diseases of therapeutic targets were annotated for further disease-based dti study. the accuracies of the molecular docking and deep learning approaches were 0.44 and 0.89, respectively. and the average accuracy of five ligand similarity searches was 0.94. the strengths of d3carp encompass the support for multiple computational methods, ensemble docking, utilization of positive controls as references, cross-validation of predicted outcomes, diverse disease types, and broad applicability in drug discovery. the d3carp is freely accessible at https://www.d3pharma.com/d3carp/index.php.",AB_0154

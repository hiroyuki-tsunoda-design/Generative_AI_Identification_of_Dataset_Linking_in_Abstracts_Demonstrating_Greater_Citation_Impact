AB,NO
"in this paper, we present a novel end-to-end group collaborative learning network, termed gconet+, which can effectively and efficiently (250 fps) identify co-salient objects in natural scenes. the proposed gconet+ achieves the new state-of-the-art performance for co-salient object detection (cosod) through mining consensus representations based on the following two essential criteria: 1) intra-group compactness to better formulate the consistency among co-salient objects by capturing their inherent shared attributes using our novel group affinity module (gam); 2) inter-group separability to effectively suppress the influence of noisy objects on the output by introducing our new group collaborating module (gcm) conditioning on the inconsistent consensus. to further improve the accuracy, we design a series of simple yet effective components as follows: i) a recurrent auxiliary classification module (racm) promoting model learning at the semantic level; ii) a confidence enhancement module (cem) assisting the model in improving the quality of the final predictions; and iii) a group-based symmetric triplet (gst) loss guiding the model to learn more discriminative features. extensive experiments on three challenging benchmarks, i.e., coca, cosod3k, and cosal2015, demonstrate that our gconet+ outperforms the existing 12 cutting-edge models. code has been released at https://github.com/zhengpeng7/gconet_plus.",AB_0338
"in this work, we present a new multi-view depth estimation method nerfingmvs that utilizes both conventional reconstruction and learning-based priors over the recently proposed neural radiance fields (nerf). unlike existing neural network based optimization method that relies on estimated correspondences, our method directly optimizes over implicit volumes, eliminating the challenging step of matching pixels in indoor scenes. the key to our approach is to utilize the learning-based priors to guide the optimization process of nerf. our system first adapts a monocular depth network over the target scene by finetuning on its mvs reconstruction from colmap. then, we show that the shape-radiance ambiguity of nerf still exists in indoor environments and propose to address the issue by employing the adapted depth priors to monitor the sampling process of volume rendering. finally, a per-pixel confidence map acquired by error computation on the rendered image can be used to further improve the depth quality. we further present nerfingmvs++, where a coarse-to-fine depth priors training strategy is proposed to directly utilize sparse sfm points and the uniform sampling is replaced by gaussian sampling to boost the performance. experiments show that our nerfingmvs and its extension nerfingmvs++ achieve state-of-the-art performances on indoor datasets scannet and nyu depth v2. in addition, we show that the guided optimization scheme does not sacrifice the original synthesis capability of neural radiance fields, improving the rendering quality on both seen and novel views. code is available at https://github.com/weiyithu/nerfingmvs.",AB_0338
"face photo-sketch synthesis has undergone remarkable progress with the rapid development of deep learning techniques. cutting-edge methods directly learn the cross-domain mapping between photos and sketches, which ignores the available reference samples. we argue that the reference samples can provide adequate prior information on texture and content in this task and improve the visual performance of synthetic images. this paper proposes a dual conditional normalization pyramid (dcnp) network with a multi-scale pyramid structure. the core of the dcnp network is a dual conditional normalization (dcn) based architecture, which can obtain prior information on different semantics from reference samples. specifically, dcn contains two conditional normalization branches. the first branch allows for spatially-adaptive normalization of the reference image conditioned on the semantic mask of the input image. the second branch enables adaptive instance normalization of the input image conditioned on the reference image. dcn can emphasize the isolated importance of textural and spatial factors by disintegrating the entire cross-domain mapping into two branches. to avoid information redundancy and improve the final performance, we propose a gated channel attention fusion (gcaf) module to distill and fuse the helpful information of the two branches. qualitative and quantitative experimental results demonstrate the superior performance of the proposed method over the state-of-the-art approaches in structural information preservation and realistic texture generation. the code is public in https://github.com/tony0720/dcnp.",AB_0338
"embedded hardware accelerator with limited resources is increasingly employed in security areas. to accelerate system-on-chip (soc) design, an efficient hw/sw co-design approach and validation platform become extremely important. the electronic system level simulator (esl) based on systemc is the primary solution for fast hardware modeling and verification. however, most existing simulators cannot achieve a better trade-off between accuracy and performance, and none of the specific esl simulators are proposed for cryptographic socs. to this end, this brief proposes a virtual prototype (vp) with integrated cryptographic accelerators for a cryptographic soc based on risc-v to accelerate the functional and performance simulation of the soc. the vp is designed as an extensible and configurable platform dedicated to cryptographic soc using an efficient hw/sw co-design approach. to accurately emulate real hardware, the flexible ahb-tlm interface and core timing model are presented. compared to the rtl simulation, our custom vp performs about 10-450 times faster than the rtl simulation, and the simulation error is only about 4%. our code is available at https://github.com/lx-ic/vp.",AB_0338
"despite the progress made by few-shot segmentation (fss) in low-data regimes, the generalization capability of most previous works could be fragile when countering hard query samples with seen-class objects. this paper proposes a fresh and powerful scheme to tackle such an intractable bias problem, dubbed base and meta (bam). concretely, we apply an auxiliary branch (base learner) to the conventional fss framework (meta learner) to explicitly identify base-class objects, i.e., the regions that do not need to be segmented. then, the coarse results output by these two learners in parallel are adaptively integrated to derive accurate segmentation predictions. considering the sensitivity of meta learner, we further introduce adjustment factors to estimate the scene differences between support and query image pairs from both style and appearance perspectives, so as to facilitate the model ensemble forecasting. the remarkable performance gains on standard benchmarks (pascal-5', coco-20', and fss-1000) manifest the effectiveness, and surprisingly, our versatile scheme sets new state-of-the-arts even with two plain learners. further-more, in light of its unique nature, we also discuss several more practical but challenging extensions, including generalized fss, 3d point cloud fss, class-agnostic fss, cross-domain fss, weak-label fss, and zero-shot segmentation. our source code is available at https://github.com/chunbolang/bam.",AB_0338
"tensor recovery is a fundamental problem in tensor research field. it generally requires to explore intrinsic prior structures underlying tensor data, and formulate them as certain forms of regularization terms for guiding a sound estimate of the restored tensor. recent researches have made significant progress by adopting two insightful tensor priors, i.e., global low-rankness (l) and local smoothness (s), which are always encoded as a sum of two separate regularizers into recovery models. however, unlike the primary theoretical developments on low-rank tensor recovery, these joint l+s models have no theoretical exact-recovery guarantees yet, making the methods lack reliability in real practice. to this crucial issue, in this work, we build a unique regularizer termed as tensor correlated total variation (t-ctv), which essentially encodes both l and s priors of a tensor simultaneously. especially, by equipping t-ctv into the recovery models, we can rigorously prove the exact recovery guarantees for two typical tensor recovery tasks, i.e., tensor completion and tensor robust principal component analysis. to the best of our knowledge, this should be the first exact-recovery results among all related l+s methods for tensor recovery. we further propose admm algorithms with fine convergence to solve the proposed models. significant recovery accuracy improvements are observed in extensive experiments. typically, our method achieves a workable performance when the missing rate is extremely large, e.g., 99.5%, for the color image inpainting task, while all its peers totally fail in such a challenging case. code is released at https://github.com/wanghailin97.",AB_0338
"artificial neural networks are prone to suffer from catastrophic forgetting. networks trained on something new tend to rapidly forget what was learned previously, a common phenomenon within connectionist models. in this work, we propose an effective and efficient continual learning framework using random theory, together with bayes' rule, to equip a single model with the ability to learn streaming data. the core idea of our framework is to preserve the performance of old tasks by guiding output weights to stay in a region of low error while encountering new tasks. in contrast to the existing continual learning approaches, our main contributions concern (1) closed-formed solutions with detailed theoretical analysis; (2) training continual learners by one-pass observation of samples; (3) remarkable advantages in terms of easy implementation, efficient parameters, fast convergence, and strong task-order robustness. comprehensive experiments under popular image classification benchmarks, fashionmnist, cifar-100, and imagenet, demonstrate that our methods predominately outperform the extensive state-of-the-art methods on training speed while maintaining superior accuracy and the number of parameters, in the class incremental learning scenario. code is available at https://github.com/toil2sweet/crnet.",AB_0338
"a resource-adaptive supernet adjusts its subnets for inference to fit the dynamically available resources. in this paper, we propose prioritized subnet sampling to train a resource-adaptive supernet, termed pss-net. we maintain multiple subnet pools, each of which stores the information of substantial subnets with similar resource consumption. considering a resource constraint, subnets conditioned on this resource constraint are sampled from a pre-defined subnet structure space and high-quality ones will be inserted into the corresponding subnet pool. then, the sampling will gradually be prone to sampling subnets from the subnet pools. moreover, the one with a better performance metric is assigned with higher priority to train our pss-net, if sampling is from a subnet pool. at the end of training, our pss-net retains the best subnet in each pool to entitle a fast switch of high-quality subnets for inference when the available resources vary. experiments on imagenet using mobilenet-v1/v2 and resnet-50 show that our pss-net can well outperform state-of-the-art resource-adaptive supernets. our project is publicly available at https://github.com/chenbong/pss-net.",AB_0338
"non-stationarity of eeg signals leads to high variability between subjects, making it challenging to directly use data from other subjects (source domain) for the classifier in the current subject (target domain). in this study, we propose mi-dagsc to address domain adaptation challenges in eeg-based motor imagery (mi) decoding. by combining domain-level information, class-level information, and inter-sample structure information, our model effectively aligns the feature distributions of source and target domains. this work is an extension of our previous domain adaptation work mi-daban (li et al., 2023). based on mi-daban, mi-dagsc designs sample-feature blocks (sfbs) and graph convolution blocks (gcbs) to focus on intra-sample and inter-sample information. the synergistic integration of sfbs and gcbs enable the model to capture comprehensive information and understand the relationship between samples, thus improving representation learning. furthermore, we introduce a triplet loss to enhance the alignment and compactness of feature representations. extensive experiments on real eeg datasets demonstrate the effectiveness of mi-dagsc, confirming that our method makes a valuable contribution to the mi-eeg decoding. moreover, it holds great potential for various applications in brain-computer interface systems and neuroscience research. and the code of the proposed architecture in this study is available under https://github.com/zhangdx21/mi-dagsc.& copy; 2023 elsevier ltd. all rights reserved.",AB_0338
"linguistic metonymy is a common type of figurative language in natural language processing (nlp), where a concept is represented by a closely associated word or phrase, for example business executives suits. as a result, metonymy resolution has become an important nlp task aimed at correctly identifying metonymic expressions within sentences. previous approaches to this task have typically relied on pre-trained language models (plms) using a fine-tuning process. however, this can be timeconsuming and resource-intensive, and may lead to a loss of factual prior knowledge. the emergence of a novel learning paradigm termed prompt learningor prompt-tuninghas recently sparked widespread interest and captured considerable attention, as it has proven to yield remarkable results and surpass previous benchmarks. this approach uses a pre-train -> prompt -> predictparadigm and has been shown to better utilize the internal prior knowledge of a plm, especially in situations with limited supervised resources. inspired by this success, we investigated how prompt learning could improve metonymy resolution. we have developed a series of prompt learning approaches, called promptmr, for metonymy resolution, and applied them to several widely-used metonymy resolution datasets. we also designed additional prompt-tuning augmentation strategies to further enhance the potential of prompt learning. our experiments demonstrated that our method achieved state-of-the-art performance over multiple competitive baselines in both data-sufficient and data-scarce scenarios. the code implementations for promptmr are accessible on github via the url: https://github.com/albert-jin/prompttuning2metonymyresolution. (c) 2023 the author(s). published by elsevier b.v. this is an open access article under the cc by license ().",AB_0338

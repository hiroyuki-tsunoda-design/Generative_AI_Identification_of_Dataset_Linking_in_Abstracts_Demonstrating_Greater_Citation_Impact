AB,NO
"learning from demonstration holds the promise of enabling robots to learn diverse actions from expert experience. in contrast to learning from observation-action pairs, humans learn to imitate in a more flexible and efficient manner: learning behaviors by simply watching. in this article, we propose a watch-and-act imitation learning pipeline that endows a robot with the ability of learning diverse manipulations from visual demonstrations. specifically, we address this problem by intuitively casting it as two subtasks: 1) understanding the demonstration video and 2) learning the demonstrated manipulations. first, a captioning module based on visual change is presented to understand the demonstration by translating the demonstration video into a command sentence. then, to execute the captioning command, a manipulation module that learns the demonstrated manipulations is built upon an instance segmentation model and a manipulation affordance prediction model. we validate the superiority of the two modules over existing methods separately via extensive experiments and demonstrate the whole robotic imitation system developed based on the two modules in diverse scenarios using a real robotic arm. supplementary video is available at https://vsislab.github.io/watch-and-act/.",AB_0186
"aim: to compare the efficacies of exemestane and fulvestrant as first-line mono -therapies for postmenopausal chinese women having advanced oestrogen-receptor positive (er+)/ human epidermal growth factor receptor 2 (her2)-breast cancer (er+/her2-abc) after a previous treatment for >2 years with an adjuvant non-steroidal aromatase inhib-itor.methods: in this randomised, open-label, multi-centre, parallel-controlled phase 2 friend study, 145 postmenopausal er+/her2-abc patients were assigned into fulvestrant (500 mg on days 0, 14 and 28, and then at every 28 +/- 3 days, n = 77) and exemestane (25 mg/day, n = 67) groups. the primary outcome was progression-free survival (pfs), while the secondary outcomes were disease control rate, objective response rate, time to treatment failure, duration of response and overall survival. exploratory end-points included gene mutation-related outcomes and safety.results: fulvestrant was superior to exemestane regarding median pfs times (8.5 versus 5.6 months, p = 0.014, hr = 0.62, 95% confidence intervals: 0.42-0.91), objective response rates (19.5% versus 6.0%, p = 0.017) and time to treatment failure (8.4 versus 5.5 months, p = 0.008). the incidence of adverse or serious adverse events in the two groups was virtually identical. the most frequent mutations in 129 analysed patients were detected in the oestrogen receptor gene 1 (esr1) (18/14.0%), pik3ca (40/31.0%) and tp53 (29/22.5%) genes. fulves-trant produced significant longer pfs times compared to exemestane but only for patients with an esr1-wild type (8.5 versus 5.8 months) (p = 0.035), although there was a similar trend also for the esr1 mutation without statistical significance. all patients with c-myc and brca2 mutations had longer pfs times in the fulvestrant versus the exemestane group (p = 0.049, p = 0.039).conclusion: fulvestrant significantly increased overall pfs for er+/her2-abc patients and was well tolerated.clinicaltrials: nct02646735, https://clinicaltrials.gov/ct2/show/nct02646735.(c) 2023 the authors. published by elsevier ltd. this is an open access article under the cc by license ().",AB_0186
"the emergence of electric vehicles promotes the development of internet of vehicle (iov). however, there are a series of security problems to be solved in the iov. firstly, how to allow vehicle users to find the nearest non-queuing charging pile without detours is a challenge. secondly, applications in the iov are delay-sensitive, while high communication delays caused by security mechanisms would bring serious consequences to vehicles. thirdly, the verifiability and fairness between charging and payment are difficult to be guaranteed. aiming at the efficiency and security problems of the charging service in the iov, this paper proposes a blockchain-based intelligent and fair iov charging service system. according to the multi-factor constraints between vehicles and charging piles, a multi-factor iov branch and bound algorithm is proposed to intelligently recommend charging piles for vehicles and maximize the overall energy saving. we propose the cross-area consensus protocol to achieve low latency in vehicle communication. in addition, we ensure the fairness between charging and payment through a payment channel protocol based on verifiable encrypted signatures. finally, we implement the proposed scheme, and we put the project prototype on an open source platform is available at: https://github.com/chenruonan/blockchain-based-intelligent-and-fair-iov-charging-service-protocol. the experimental results demonstrate the low latency and energy-saving advantages of our proposal. when the payment is executed 250 times, the delay of our proposal is only 1.54% of the normal on-chain payment time.",AB_0186
"this paper aims to solve the trajectory tracking con-trol problem for an autonomous vehicle based on reinforcement learning methods. existing reinforcement learning approaches have found limited successful applications on safety-critical tasks in the real world mainly due to two challenges: 1) sim-to-real transfer; 2) closed-loop stability and safety concern. in this paper, we propose an actor-critic-style framework srl-tr2, in which the rl-based trajectory trackers are trained under the safety constraints and then deployed to a full-size vehicle as the lateral controller. to improve the generalization ability, we adopt a light-weight adapter state and action space alignment (sasa) to establish mapping relations between the simulation and reality. to address the safety concern, we leverage an expert strategy to take over the control when the safety constraints are not satisfied. hence, we conduct safe explorations during the training process and improve the stability of the policy. the experiments show that our agents can achieve one-shot transfer across simulation scenarios and unseen realistic scenarios, finishing the field tests with average running time less than 10 ms/step and average lateral error less than 0.1 m under the speed ranging from 12 km/h to 18 km/h. a video of the field tests is available at https://youtu.be/pjwcn_fv24g.",AB_0186
"named entity recognition is a key task in text mining. in the biomedical field, entity recognition focuses on extracting key information from large-scale biomedical texts for the downstream information extraction task. biomedical literature contains a large amount of long-dependent text, and previous studies use external syntactic parsing tools to capture word dependencies in sentences to achieve nested biomedical entity recognition. however, the addition of external parsing tools often introduces unnecessary noise to the current auxiliary task and cannot improve the performance of entity recognition in an end-to-end way. therefore, we propose a novel automatic dependency parsing approach, namely the adpg model, to fuse syntactic structure information in an end-to-end way to recognize biomedical entities. specifically, the method is based on a multilayer tree-transformer structure to automatically extract the semantic representation and syntactic structure in long-dependent sentences, and then combines a multilayer graph attention neural network (gat) to extract the dependency paths between words in the syntactic structure to improve the performance of biomedical entity recognition. we evaluated our adpg model on three biomedical domain and one news domain datasets, and the experimental results demonstrate that our model achieves state-of-the-art results on these four datasets with certain generalization performance. our model is released on github: https://github.com/yumeng-y/adpg.",AB_0186
"most current approaches in the literature of scene text recognition train the language model via a text dataset far sparser than in natural language processing, resulting in inadequate training. therefore, we propose a simple transformer encoder-decoder model called the multilingual semantic fusion network (msfn) that can leverage prior linguistic knowledge to learn robust language features. first, we label the text dataset with forward, backward sequences, and subwords, which are extracted by tokenization with linguistic information. then we introduce a multilingual model to the decoder corresponding to three different channels of the labeled dataset. the final output is fused by different channels to get more accurate results. in experiments, msfn achieves cutting-edge performance across six benchmark datasets, and extensive ablative studies have proven the effectiveness of the proposed method. code is available at https://github.com/lclee0577/mlvit. (c) 2023 spie and is&t [doi: 10.1117/1.jei.32.2.023015]",AB_0186
"convolutional neural network (cnn)-based detection has shown great potential in accurate infrared (ir) ship detection. typically, ir images exhibit a lack of texture details, whereas the sizes of ir ship targets are extremely multiscale, making it difficult to accurately detect ir ship targets. herein, we propose a novel strengthened asymmetric receptive field block (sarfb) for accurate ir ship detection. the sarfb contains an asymmetric receptive field block (arfb), a spatial pyramid pooling (spp) block, and skip connections. through these components, sarfb is able to fuse local and global features, enriching the expressive ability and receptive field of the network for multiscale ir ship target detection. furthermore, because there is no publicly available ir ship target dataset for detection, we created the single-frame ir ship detection (sfisd) dataset, providing the first public benchmark for testing ir ship target detection performance. in comparative studies, the map_0.5 of yolov5 with sarfb reached 93.3%, outperforming other state-of-the-art methods. finally, we performed experiments on an unmanned surface vehicle (usv) equipped with an ir camera. the results show the superior robustness of our proposed method, especially when target texture information is lacking, and when the ir ship targets are multiscale. the sfisd dataset is available at https://github.com/echoo-sky/sfisd.",AB_0186
"with the development of industrial and sensing technology, sensor-based activity recognition has become a promising technology for informatics applications. however, in a typical activity recognition procedure, sensory data segmentation, usually considered a preprocess with sliding windows, rarely has been investigated and significantly affected the recognition performance. in this article, we propose a novel deep-learning method to jointly segment and recognize activities with wearable sensors. our contributions are three-fold: first, we introduce a multistage temporal convolutional network for sample-level activity prediction to overcome the multiclass windows problem. second, for alleviating oversegmentation errors, our model forms a multitask learning framework with a boundary prediction module to adjust the entire model's gradients. third, we innovatively propose a boundary consistency loss to enforce the consistency of the activity and boundary prediction. our method shows impressive performance on three public datasets, especially achieving 16% improvement over very recently advanced competing methods with class-average f1-score on the hospital dataset. the code of this work will be open source on https://github.com/xspc/segmentation-sensor-based-har.",AB_0186
"touch gesture recognition (tgr) plays a pivotal role in many applications, such as socially assistive robots and embodied telecommunication. however, one obstacle to practicality of existing tgr methods is the individual disparities across subjects. moreover, a deep neural network trained with multiple existing subjects can easily lead to overfitting for a new subject. hence, how to mitigate the discrepancies between the new and existing subjects and establish a generalized network for tgr is a significant task to realize reliable human-robot tactile interaction. in this article, a novel framework for multisource domain adaptation via shared-specific feature projection (mass) is proposed, which incorporates intradomain discriminant, multidomain discriminant, and cross-domain consistency into a deep learning network for cross-subject tgr. specifically, the mass method first extracts the shared features in the common feature space of training subjects, with which a domain-general classifier is built. then, the specific features of each pair of training and testing subjects are mapped and aligned in their common feature space, and multiple domain-specific classifiers are trained with the specific features. finally, the domain-general classifier and domain-specific classifiers are ensembled to predict the label for the touch samples of a new subject. experimental results performed on two datasets show that our proposed mass method achieves remarkable results for cross-subject tgr. the code of mass is available at https://github.com/ai-touch/mass.",AB_0186
"background: pancreatic ductal adenocarcinoma (pdac) is a solid malignancy with adverse outcomes. our aim was to explore promising critical genes related to the development of pdac. methods: microarray datasets were downloaded, and differentially expressed genes (degs) were identified. gene ontology (go) function and kyoto encyclopedia of genes and genomes (kegg) pathway analyses were conducted by the database for anno-tation, visualization and integrated discovery (david, version 6.8, national cancer institute, frederick, md, usa). a protein -protein interaction (ppi) network of degs was built with the search tool for the retrieval of interacting genes (string) (version 11.0, global biodata coalition and elixir, zurich, switzerland, http://string-db.org/), and hub genes were determined using cytoscape (version 3.7.2, uc san francisco & gladstone institute, san diego, ca, usa, http://www.cytoscape.org/). then, expression of hub genes was confirmed by querying gene expression profiling interactive analysis (gepia) and human pro-tein atlas (hpa) (version 22.0, the knut & alice wallenberg foundation, wallenberg, sweden, https://www.proteinatlas.org/) databases. these results were further confirmed by quantitative real time pcr (qrt-pcr) of pdac cell lines. the prognostic significance of hub genes was evaluated through kaplan-meier plotter, and the diagnostic value was assessed using ucsc (uni-versity of california santa cruz) xena. results: two downregulated degs and 196 upregulated degs were identified. these overexpressed genes were primarily en-riched in extracellular exosomes, calcium ion binding, cell adhesion, the phosphatidylinositol 3 kinase (pi3k)/protein kinase b (pkb, also known as akt) signaling pathway and cancer. 10 highly expressed hub genes, namely cyclin-dependent ki -nase 1(cdk1), ribonucleotide reductase regulatory subunit m2 (rrm2), dna topoisomerase ii alpha (top2a), abnormal spindle-like microcephaly-associated protein (aspm), protein regulator of cytokinesis 1 (prc1), zw10 interacting kineto-chore protein (zwint), maternal embryonic leucine zipper kinas (melk), centrosomal protein 55 (cep55), denticleless e3 ubiquitin protein ligase homolog (dtl), and nima related kinase 2 (nek2), were determined, and the increased expression of these screened genes was further confirmed in pdac cells compared with immortalized human pancreatic ductal epithelial cells (hpde6). increased expression of the selected genes had shorter overall survival (os) and relapse-free survival (rfs) in pdac. the analyses of receiver operating characteristic (roc) predicted the area under curve (auc) of hub genes in pdac ranged from 0.970 to 0.990.conclusions: in conclusion, our study suggested that upregulation of cdk1, rrm2, top2a, aspm, prc1, zwint, melk, cep55, dtl, and nek2 is associated with poor os and rfs, and these genes exhibit high diagnostic value in pdac. these genes may be potential independent diagnostic markers. further studies are needed to validate their potential diagnostic and therapeutic values in pdac.",AB_0186

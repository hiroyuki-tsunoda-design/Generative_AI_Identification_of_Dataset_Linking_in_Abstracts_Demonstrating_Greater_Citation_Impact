AB,NO
"automatic segmentation of colorectal polyps can help physicians effectively identify the exact location and size of polyps. current methods are rapidly developing and demonstrating achievements in colonoscopic image segmentation. however, the effectiveness is limited by two aspects. 1) a changeable intestinal environment causes image variability. 2) the convolutional neural network has limitations in extracting long-distance relationships. we propose a coordinate asymmetric multi-scale fusion network (coam-net) to manage the above problems. transformer and cnn are combined to improve automatic polyp segmentation accuracy. the proposed method employs a coordinate asymmetric module (ca-module), a multi-scale fusion decoder (msd), and a multi-scale spatial attention mechanism (msa) to utilize global and local features. ca-module is a component of the cnn feature extractor that makes intensive use of contextual information. by extracting multi-scale features and attention mechanisms, msa effectively enriches cnn spatial features and highlights the importance of relevant features. the designed msd effectively exploits long-distance relationships and local features to build a more accurate decoding structure. we compare our method with twelve other state-of-the-art works on the kvasir-seg and cvc-clinicdb datasets. experiments show that our method performs optimally in most metrics. we also performed generalization experiments on the etis-larib polyp db, cvc-t, and cvc-colondb datasets to validate that coam-net can achieve good results. the model is available at https://github.com/wangyuanyuan0/coam-net.",AB_0329
"audio-visual event (ave) localization aims to detect whether an event exists in each video segment and predict its category. only when the event is audible and visible can it be recognized as an ave. however, sometimes the information from auditory and visual modalities is asymmetrical in a video sequence, leading to incorrect predictions. to address this challenge, we introduce a dynamic interactive learning network designed to dynamically explore the intra- and inter-modal relationships depending on the other modality for better ave localization. specifically, our approach involves a dynamic fusion attention of intra- and inter-modalities module, enabling the auditory and visual modalities to focus more on regions deemed informative by the other modality while focusing less on regions that the other modality considers noise. in addition, we introduce an audio-visual difference loss to reduce the distance between auditory and visual representations. our proposed method has been demonstrated to have superior performance by extensive experimental results on the ave dataset. the source code will be available at https://github.com/hanliang/diln.",AB_0329
"the interactions of users and items in recommender systems can be naturally modeled as user-item bipartite graphs. the iterative propagation of graph neural networks (gnn) can explicitly exploit high-order connectivity from those user-item interactions. apart from these advantages, there are two limitations in gnn-based recommendation systems that might lead to performance degradation: 1) existing gnn methods only depend on the graph topology but ignore the insightful relationship between the connected nodes. the edge representation in gnns cannot effectively express the personalized information of users and items, and can only represent the structural connection information of the graph. 2) the representations of nodes and edges were initialized randomly, these initial representations participate in subsequent node propagation and updating computations in the graph neural network. it directly affects the final representation of the user and item nodes in the network and result in bad recommendation performence. to address these issues, this study proposes a graph attention network with contextual pretraining (gat-cp) for content-based collaborative filtering. it explicitly exploits the user-item graph structure twofold. first, an contextual personalized sentiment analysis task was applied by fine-tuning the bert model to initialize the representations of nodes and edges by investigating the user preference for products based on the reviews of the users. second, the obtained edge representations were used as the propagation constraints to assign different weights to the edges in gat. comparative results show the significant performance gains of gat-cp and the necessity of node and edge initialization with contextual tasks. the code for this paper is available at: https://github.com/yellow4submarine7/gat_ap",AB_0329
"the attribute network not only has a complex topology, but its nodes also contain rich attribute information. attribute network embedding methods extract both network topology and node attribute information to learn low-dimensional embedding of large attribute networks, which are of great importance for network analysis. in this paper, we propose attribute network joint embedding based on global attention (gaje). first, gaje uses the structure information of the attribute network to obtain the structure embedding vectors of nodes. second, we propose a global attention method to obtain the attribute embedding vectors of nodes. this method captures the relationships of different attributes within and between nodes through convolutional neural networks and attention mechanisms, respectively. finally, gaje concatenates the structure embedding vectors and the attribute embedding vectors to obtain the final joint embedding vectors which simultaneously reflects the network structure and attributes information. for link prediction and node classification, we compared gaje with nine well-known network embedding methods in four real datasets. the experimental results show that the algorithm has good attribute network embedding effects. our tensorflow implementation of the gaje is available at https://github.com/andrewsama/gaje-master.",AB_0329
"zero-shot object detection (zsd) is dedicated to the task of precisely localizing and identifying unfamiliar objects that have not been encountered before. in this paper, a contrastive semantic association network is proposed to address the knowledge transfer challenge from seen classes to unseen ones in zsd. it enables efficient information propagation through similarity-based connections, thereby establishing a clearer link between seen and unseen categories. moreover, a visual-semantic contrastive learning technique is developed to mitigate the node convergence issue caused by the graph structure of the proposed network. by emphasizing the visual and semantic distinctiveness across different categories, the proposed model leverages semantic information and graph structure knowledge to enhance the generalization capability of seen and unseen feature projection. extensive experiments demonstrate the superior performance of our model compared to other zero-shot object detection methods, showcasing notable improvement in mean average precision (map) on the ms-coco dataset. the code and models are publicly available at: https://github.com/lihh1023/csa-zsd/tree/master.",AB_0329
"automatic retinal capillary segmentation is a necessary prerequisite for quantitatively analyzing retinal vessels. in recent years, active research has been using deep learning-based methods in this field. however, deep learning methods inevitably lose spatial information of vessels when downsampling, thereby limiting the segmentation performance for fine vessels. additionally, existing methods must pay more attention to the dynamic correlations between feature mappings in deep learning frameworks, resulting in inefficient acquisition of multi-scale decoder features. to address these limitations, we propose a global relationship memory network (grm-net) that considers the relationship between frequency domain and decoder hierarchy. specifically, we first design a frequency relation learning module to preserve fine details of vessels during downsampling. this module decouples encoder features into frequency domain features of different dimensions and employs globally learnable filters to better guide the network's attention towards vessels of different sizes and shapes. secondly, we investigate a hierarchical relation selection module that leverages gate mechanisms to dynamically adjust the collaboration between two adjacent decoder blocks, thereby adaptively aggregating multi-scale decoder features to address the issue of underutilized decoding information. comparative experimental results on two retinal vessel datasets validate the effectiveness of the proposed grm-net segmentation method. compared to other state-of-the-art methods (unet, cs-net, deeplabv3, miniseg, and octa-net), this method achieves more remarkable segmentation results, preserving more details in the tiniest retinal capillaries. code is available at https://github.com/weilijiang/global-relationship-memory-network.",AB_0329
"real-world industrial scenarios pose a challenging task known as few-shot class-incremental learning (fscil), which aims to recognize new classes using a few samples while not forgetting the old classes. despite the recent advance of fscil, most existing methods rely on a single metric for making incremental relation predictions, which is unilateral and lacks stability. in this paper, we remedy this issue from two aspects. specifically, to make convincing relation predictions, we first propose a relation complementation strategy that aggregates different metric models to investigate the comprehensive relation of classifier weights and test features. then, to make the proposed strategy well fit the incremental scenarios, we design a pseudo incremental relation complementation learning scheme that constructs the learning tasks by mimicking the data setting in real incremental sessions. taken together, our proposed method dubbed relation complementation network (rcn) achieves the state-of-the-art performance on miniimagenet, cifar100 and cub200. our code is available at https://github.com/yezilaixi/kt-rcn.git.",AB_0329
"due to the distributed collaboration and privacy protection features, federated learning is a promising technology to perform the model training in virtual twins of digital twin for mobile networks (dtmn). in order to enhance the reliability of the model, it is always expected that the users involved in federated learning have trustworthy behaviors. yet, available trust evaluation schemes for federated learning have the problems of considering simplex evaluation factor and using coarse-grained trust calculation method. in this paper, we propose a trust evaluation scheme for federated learning in dtmn, which takes direct trust evidence and recommended trust information into account. a user behavior model is designed based on multiple attributes to depict users' behavior in a fine-grained manner. furthermore, the trust calculation methods for local trust value and recommended trust value of a user are proposed using the data of user behavior model as trust evidence. several experiments were conducted to verify the effectiveness of the proposed scheme. the results show that the proposed method is able to evaluate the trust levels of users with different behavior patterns accurately. moreover, it performs better in resisting attacks from users that alternately execute good and bad behaviors compared with state-of-the-art scheme. the code for the method proposed in this paper is available at: https://web.xidian.edu.cn/jjguo/en/code.html.",AB_0329
"the application of domain adaptation techniques has emerged as a valuable approach for reducing the cost of data annotation in object recognition domains. despite its usefulness, domain adaptation is often impeded by domain shift issues that can lead to suboptimal performance. to address this challenge, previous works have attempted to align the global distribution across two domains. however, this approach may not be adequate for handling misalignment near classifier boundaries, which can cause a bias towards the source domain. in this paper, we introduce a novel label-smoothing strategy and semantic transport optimization method for unsupervised domain adaptation. our approach leverages a memory bank for dynamic smooth rate learning and employs a semantic alignment optimization that treats it as an optimal transport problem. we also integrate class proportions into the optimization to enhance the discriminative ability of target features. to further improve the performance, we incorporate these two strategies into adversarial-based adaptation methods. we conduct comprehensive experiments on three common benchmarks to evaluate the performance of our method. our results show that our proposed approach achieves competitive performance compared to existing methods. we make our codes publicly available at https://github.com/feifei-cv/dlst.",AB_0329
"expression-level information extraction is a challenging task in natural language processing (nlp), which aims to retrieve crucial semantic information from linguistic documents. however, there is a lack of up-to-date data resources for accelerating expression-level information extraction, particularly in the chinese financial high technology field. to address this gap, we introduce fintech key-phrase: a human-annotated key-phrase dataset for the chinese financial high technology domain. this dataset comprises over 12k paragraphs along with annotated domain-specific key-phrases. we extract the publicly released reports, chinese management's discussion and analysis (cmd&a), from the renowned chinese research data services platform (cnrds) and then filter the reports related to high technology. the high technology key-phrases are annotated following pre-defined philosophy guidelines to ensure annotation quality. in order to better understand the limitations and challenges in the purposed dataset, we conducted comprehensive noise evaluation experiments for the fintech key-phrase, including annotation consistency assessment and absolute annotation quality evaluation. to demonstrate the usefulness of our released fintech key-phrase in retrieving valuable information in the chinese financial high technology field, we evaluate its significance using several superior information retrieval systems as representative baselines and report corresponding performance statistics. additionally, we further applied chatgpt to the text augmentation approach of the fintech key-phrase dataset. extensive comparative experiments demonstrate that the augmented fintech key-phrase dataset significantly improved the coverage and accuracy of extracting key phrases in the finance and high-tech domains. we believe that this dataset can facilitate scientific research and exploration in the chinese financial high technology field. we have made the fintech key-phrase dataset and the experimental code of the adopted baselines accessible on github: https://github.com/albert-jin/fintech-key-phrase. to encourage newcomers to participate in the financial high-tech domain information retrieval research, we have developed a series of tools, including an open website(1) and corresponding real-time information retrieval apis.(2)",AB_0329

AB,NO
"to improve deep-learning performance in low-resource settings, many researchers have redesigned model architectures or applied additional data (e.g., external resources, unlabeled samples). however, there have been relatively few discussions on how to make good use of small amounts of labeled samples, although it is potentially beneficial and should be done before applying additional data or redesigning models. in this study, we assume a low-resource setting in which only a few labeled samples (i.e., 30-100 per class) are available, and we discuss how to exploit them without additional data or model redesigns. we explore possible approaches in the following three aspects: training-validation splitting, early stopping, and weight initialization. extensive experiments are conducted on six public sentence classification datasets. performance on various evaluation metrics (e.g., accuracy, loss, and calibration error) significantly varied depending on the approaches that were combined in the three aspects. based on the results, we propose an integrated method, which is to initialize the model with a weight averaging method and use a non-validation stop method to train all samples. this simple integrated method consistently outperforms the competitive methods; e.g., the average accuracy of six datasets of this method was 1.8% higher than those of conventional validation-based methods. in addition, the integrated method further improves the performance when adapted to several state-of-the-art models that use additional data or redesign the network architecture (e.g., self-training and enhanced structural models). our results highlight the importance of the training strategy and suggest that the integrated method can be the first step in the low-resource setting. this study provides empirical knowledge that will be helpful when dealing with low-resource data in future efforts. our code is publicly available at https://github.com/dmcb-gist/exploit_all_samples.",AB_0125
"background: commercial smartphone apps designed to promote emotional well-being are becoming increasingly popular, but few apps have been empirically validated.objective: this study examined the feasibility and effectiveness of a self-guided app designed to reduce daily stress via positive messaging and tailored short inspirational talks (ie, peps).methods: a total of 166 participants (n=112, 67.5% female; mean age 38.48, sd 6.73 years) were recruited through social media advertising and randomized into an intervention (hey lemonade app plus twice daily mood monitoring using the multidimensional mood questionnaire [mdmq]) or active control (twice daily mood monitoring [mdmq]) group. primary (coping self-efficacy [cse]; 3 subscales) and secondary outcomes (vitality, satisfaction with life, perceived stress, positive and negative affect, and hassles and uplifts) were measured at the baseline (week 1) and end point (week 4). the app evaluation questions were assessed at week 2. all interactions and measurements were collected on the internet and through the apps.results: in total, of 166 participants, 125 (75.3%) completed the trial. there were no differences in dropout rates between the groups (62/81, 76% intervention; 63/85, 74% control). there were significant group-by-time interactions for vitality and hassles but no significant effect for cse total (p=.05). for the intervention group, the change from baseline to week 4 was significant for vitality (p=.002) and hassles (p=.004), cse total (p=.008), and cse emotional subscale (p=.02). for the control group, any changes over 4 weeks were not significant for any outcome. there was a significant group-by-time interaction for mdmq calmness (p=.04). by week 4, calmness was significantly higher in the intervention group (p=.046). of those in the intervention group at week 2 (n=68), 39 (57%) participants recommended the app and 41 (60%) participants wanted to continue using it. pep talks and customizable voice options were the most popular features.conclusions: participants who had access to the smartphone app on an as-needed basis over the 4-week trial showed significant improvements in emotional well-being indicators. more broadly, this suggests that simple accessible solutions may generate meaningful well-being outcomes. whether these changes are sustained and can be generalized to other population groups is yet to be determined. trial registration: australian and new zealand clinical trials registry (anzctr) 12622001005741; https://www.anzctr.org.au/trial/registration/trialreview.aspx?id=384304&isreview=true",AB_0125
"supervised deep learning depends on massive accurately annotated examples, which is usually impractical in many real-world scenarios. a typical alternative is learning from multiple noisy annotators. numerous earlier works assume that all labels are noisy, while it is usually the case that a few trusted samples with clean labels are available. this raises the following important question: how can we effectively use a small amount of trusted data to facilitate robust classifier learning from multiple annotators? this paper proposes a data-efficient approach, called trustable co-label learning (tcl), to learn deep classifiers from multiple noisy annotators when a small set of trusted data is available. this approach follows the coupled-view learning manner, which jointly learns the data classifier and the label aggregator. it effectively uses trusted data as a guide to generate trustable soft labels (termed co-labels). a co-label learning can then be performed by alternately reannotating the pseudo labels and refining the classifiers. in addition, we further improve tcl for a special complete data case, where each instance is labeled by all annotators and the label aggregator is represented by multilayer neural networks to enhance model capacity. extensive experiments on synthetic and real datasets clearly demonstrate the effectiveness and robustness of the proposed approach. source code is available at https://github.com/shikunli/tcl.",AB_0125
"cross domain recommendation (cdr) is one popular research topic in recommender systems. this article focuses on a popular scenario for cdr where different domains share the same set of users but no overlapping items. the majority of recent methods have explored the shared-user representation to transfer knowledge across domains. however, the idea of shared-user representation resorts to learning the overlapped features of user preferences and suppresses the domain-specific features. other works try to capture the domainspecific features by an mlp mapping but require heuristic human knowledge of choosing samples to train the mapping. in this article, we attempt to learn both features of user preferences in a more principled way. we assume that each user's preferences in one domain can be expressed by the other one, and these preferences can be mutually converted to each other with the so-called equivalent transformation. based on this assumption, we propose an equivalent transformation learner (etl), which models the joint distribution of user behaviors across domains. the equivalent transformation in etl relaxes the idea of shared-user representation and allows the learned preferences in different domains to preserve the domain-specific features as well as the overlapped features. extensive experiments on three public benchmarks demonstrate the effectiveness of etl compared with recent state-of-the-art methods. codes and data are available online: https://github.com/xuchensjtu/etl-master.",AB_0125
"surprising performance has been achieved in style transfer since deep learning was introduced to it. however, the existing state-of-the-art (sota) algorithms either suffer from quality issues or high computational complexity. the quality issues include shape retention and the adequacy of style migration, and the computational complexity is reflected in the network complexity and additional updates when the style changes. to deal with the above problems, we propose a novel low computational complexity arbitrary style transfer algorithm (lccstyle) that mainly consists of a transformation feature module (tfm) and learning transformation module (ltm). the tfm is responsible for transforming the content feature map into the stylized feature map without impact on the integrity of content information, which contributes to good shape retention and full style migration. in addition, to avoid additional updates when the style changes, we propose a new training mechanism for arbitrary style transfer to directly generate the parameters of the tfm by a hyper-network. however, the widely used hyper-networks are composed of fully connected layers, which cause a large number of parameters. hence, we designed a hyper-network (ltm) consisting of one-dimensional convolution to adapt to the characteristics of the gram matrix of the style feature map, contributing to a small model size and having no impact on quality. quantitative comparison and user study show that lccstyle achieves high performance both on the adequacy of style migration and shape retention. furthermore, compared with the sotas, the size of the proposed model is reduced by a large margin of nearly 51.4%$\sim$99.6%. when the input is 512x512 pixels, the processing speeds in the cases of unchanged style and constantly changing style are increased by at least 135% and 227%, respectively. on an nvidia titan rtx gpu, lccstyle reaches 60fps for 720p video and takes only 1 s to process 8 k images. https://github.com/huangyujie94/lccstyle.",AB_0125
"image-mixing augmentations (e.g., mixup and cutmix), which typically involve mix ing two images, have become the de-facto training techniques for image classification. despite their huge success in image classification, the number of images to be mix ed has not been elucidated in the literature: only the naive k-image expansion has been shown to lead to performance degradation. this study derives a new k-image mixing augmentation based on the stick-breaking process under dirichlet prior distribution. we demonstrate the superiority of our k-image expansion augmentation over conventional two-image mixing augmentation methods through extensive experiments and analyses: 1) more robust and generalized classifiers; 2) a more desirable loss landscape shape; 3) better adversarial robustness. moreover, we show that our probabilistic model can measure the sample-wise uncertainty and boost the efficiency for network architecture search by achieving a 7-fold reduction in the search time. code will be available at https://github.com/yjyoo3312/dcutmix-pytorch.git.",AB_0125
"the emergence of empty-dish recycling robots has alleviated problems, such as labor shortages, caused by an aging population. the detection and grasping of dishes play a crucial role in empty-dish recycling robots. however, due to the limited resources of edge devices, traditional object detection models require more space to store parameters and much computational overhead, limiting the development of empty-dish recycling robots. therefore, this article proposes an ultralightweight dish detection model yolo-gs for an empty-dish recycling robot. we use the modified cspdarknet as the backbone structure and design an ultralightweight neck structure for efficient feature fusion. meanwhile, we design a lightweight head structure for object classification and bounding box coordinate regression by combining ghost shuffle convolution (gsconv2d) and the anchor-free method. for the empty-dish recycling robot to grasp the dishes, we design a dish grasp point extraction algorithm using image processing. finally, tensorrt is used to optimize and accelerate the model for efficient and intelligent detection of dishes on the nvidia jetson xavier nx. the experimental results show that yolo-gs achieves 99.380% mean average precision (map) with a parameter amount of 0.606 m. the inference speed of the tensorrt-optimized yolo-gs algorithm reaches 31.371 fps, which meets the needs of real-time dish detection by the empty-dish recycling robot. the image of the empty-dish recycling robot demo is available at https://www.youtube.com/watch?v=pcbo1nzm3qu & t=22s.",AB_0125
"cancer is one of the most challenging diseases because of its complexity, variability, and diversity of causes. it has been one of the major research topics over the past decades, yet it is still poorly understood. to this end, multifaceted therapeutic frameworks are indispensable. anticancer peptides (acps) are the most promising treatment option, but their large-scale identification and synthesis require reliable prediction methods, which is still a problem. in this paper, we present an intuitive classification strategy that differs from the traditional black-box method and is based on the well-known statistical theory of sparse-representation classification (src). specifically, we create over-complete dictionary matrices by embedding the composition of the k-spaced amino acid pairs (cksaap). unlike the traditional src frameworks, we use an efficient matching pursuit solver instead of the computationally expensive basis pursuit solver in this strategy. furthermore, the kernel principal component analysis (kpca) is employed to cope with non-linearity and dimension reduction of the feature space whereas the synthetic minority oversampling technique (smote) is used to balance the dictionary. the proposed method is evaluated on two benchmark datasets for well-known statistical parameters and is found to outperform the existing methods. the results show the highest sensitivity with the most balanced accuracy, which might be beneficial in understanding structural and chemical aspects and developing new acps. the google-colab implementation of the proposed method is available on the github page (https://github.com/ehtisham-fazal/acp-kernel-src).",AB_0125
"background: even modest reductions in blood pressure (bp) can have an important impact on population-level morbidity and mortality from cardiovascular disease. there are 2 promising approaches: the saltswitch smartphone app, which enables users to scan the bar code of a packaged food using their smartphone camera and receive an immediate, interpretive traffic light nutrition label on-screen alongside a list of healthier, lower-salt options in the same food category; and reduced-sodium salts (rsss), which are an alternative to regular table salt that are lower in sodium and higher in potassium but have a similar mouthfeel, taste, and flavor. objective: our aim was to determine whether a 12-week intervention with a sodium-reduction package comprising the saltswitch smartphone app and an rss could reduce urinary sodium excretion in adults with high bp.conclusions: in this randomized controlled trial of a salt-reduction package, we found no evidence that dietary sodium intake was reduced in adults with high bp. these negative findings may be owing to lower-than-anticipated engagement with the trial intervention package. however, implementation and covid-19-related challenges meant that the trial was underpowered, and it is possible that a real effect may have been missed.trial registration: australian new zealand clinical trials registry actrn12619000352101; https://www.anzctr.org.au/trial/registration/trialreview.aspx?id=377044 and universal trial u1111-1225-4471",AB_0125
"deep learning has demonstrated its power in image rectification by leveraging the representation capacity of deep neural networks via supervised training based on a large-scale synthetic dataset. however, the model may overfit the synthetic images and generalize not well on real-world fisheye images due to the limited universality of a specific distortion model and the lack of explicitly modeling the distortion and rectification process. in this paper, we propose a novel self-supervised image rectification (sir) method based on an important insight that the rectified results of distorted images of a same scene from different lenses should be the same. specifically, we devise a new network architecture with a shared encoder and several prediction heads, each of which predicts the distortion parameter of a specific distortion model. we further leverage a differentiable warping module to generate the rectified images and re-distorted images from the distortion parameters and exploit the intra- and inter-model consistency between them during training, thereby leading to a self-supervised learning scheme without the need for ground-truth distortion parameters or normal images. experiments on synthetic dataset and real-world fisheye images demonstrate that our method achieves comparable or even better performance than the supervised baseline method and representative state-of-the-art (sota) methods. the proposed self-supervised method also provides a possible way to improve the universality of distortion models while keeping their self-consistency. code and datasets will be available at https://github.com/loong8888/sir.",AB_0125

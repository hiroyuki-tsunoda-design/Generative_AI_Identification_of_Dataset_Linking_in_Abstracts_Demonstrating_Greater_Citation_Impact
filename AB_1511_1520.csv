AB,NO
"fingerprinting has become a mainstream method for indoor positioning. with the popularization of smart devices, the construction of indoor positioning databases is no longer limited to fingerprints collected in a single carrier; instead, it includes those collected by various platforms, such as internet of things (iot) devices, smartphones, and robots. to adapt to this new trend, it is key to answer the question: how do fuse fingerprints collected using various carriers to generate a database for localization? this article has three contributions. first, it reveals the necessity of involving the location uncertainty of localization feature (lf) measurements. this topic has yet to be considered in the existing research works because they only have fingerprints collected from a single platform. second, considering such location uncertainty, this article proposes an improved database training and location estimation method. third, this article presents an approach combining sparse professional fingerprints and dense consumer fingerprints to create a database that is key to the ubiquitous positioning of smart devices. in field tests, the proposed method improved positioning accuracy by over 35% and brought other benefits. the source code of this research is available at https://github.com/zhenqizhen/location-uncertainty-fp.git.",AB_0152
"the low accuracy of satellite cloud fraction (cf) data over the arctic seriously restricts the accurate assessment of the regional and global radiative energy balance under a changing climate. previous studies have reported that no individual satellite cf product could satisfy the needs of accuracy and spatiotemporal coverage simultaneously for long-term applications over the arctic. merging multiple cf products with complementary properties can provide an effective way to produce a spatiotemporally complete cf data record with higher accuracy. this study proposed a spatiotemporal statistical data fusion framework based on cumulative distribution function (cdf) matching and the bayesian maximum entropy (bme) method to produce a synthetic 1 degrees x 1 degrees cf dataset in the arctic during 2000-2020. the cdf matching was employed to remove the systematic biases among multiple passive sensor datasets through the constraint of using cf from an active sensor. the bme method was employed to combine adjusted satellite cf products to produce a spatiotemporally complete and accurate cf product. the advantages of the presented fusing framework are that it not only uses the spatiotemporal autocorrelations but also explicitly incorporates the uncertainties of passive sensor products benchmarked with reference data, i.e., active sensor product and ground-based observations. the inconsistencies of arctic cf between passive sensor products and the reference data were reduced by about 10%-20% after fusing, with particularly noticeable improvements in the vicinity of greenland. compared with ground-based observations, r-2 increased by about 0.20-0.48, and the root mean square error (rmse) and bias reductions averaged about 6.09% and 4.04% for land regions, respectively; these metrics for ocean regions were about 0.05-0.31, 2.85 %, and 3.15 %, respectively. compared with active sensor data, r-2 increased by nearly 0.16, and rmse and bias declined by about 3.77% and 4.31 %, respectively, in land; meanwhile, improvements in ocean regions were about 0.3 for r-2, 4.46% for rmse, and 3.92% for bias. the results of the comparison with era5 and the meteorological research institute - atmospheric general circulation model version 3.2s (mri-agcm3-2-s) climate model suggest an obvious improvement in the consistency between the satellite-observed cf and the reanalysis and model data after fusion. this serves as a promising indication that the fused cf results hold the potential to deliver reliable satellite observations for modeling and reanalysis data. moreover, the fused product effectively supplements the temporal gaps of advanced very high resolution radiometer (avhrr)-based products caused by satellite faults and the data missing from modis-based products prior to the launch of aqua, and it extends the temporal range better than the active product; it addresses the spatial insufficiency of the active sensor data and the avhrr-based products acquired at latitudes greater than 82.5 degrees n. a continuous monthly 1 degrees cf product covering the entire arctic during 2000-2020 was generated and is freely available to the public at https://doi.org/10.5281/zenodo.7624605 (liu and he, 2022). this is of great importance for reducing the uncertainty in the estimation of surface radiation parameters and thus helps researchers to better understand the earth's energy imbalance.",AB_0152
"as one of the most successful cancer therapeutic targets, estrogen receptor -a (er/esr1) has been extensively studied over the past few decades. sequencing technological advances have enabled genome-wide analysis of er action. however, comparison of individual studies is limited by different experimental designs, and few meta-analyses are available. here, we established the estrogene database through unified processing of data from 246 experiments including 136 transcriptomic, cistromic, and epigenetic datasets focusing on estradiol (e2)-triggered er activation across 19 breast cancer cell lines. a user-friendly browser (https://estrogene.org/) was generated for multiomic data visualization involving gene inquiry under user-defined experimental conditions and statistical thresholds. notably, annotation of metadata associated with public datasets revealed a considerable lack of experimental details. comparison of independent rna-seq or er chip-seq data with the same design showed large variability and only strong effects could be consistently detected. temporal estrogen response metasignatures were defined, and the association of e2 response rate with temporal transcriptional factors, chromatin accessibility, and heterogeneity of er expression was evaluated. unexpectedly, harmonizing 146 e2-induced transcriptomic datasets uncovered a subset of genes harboring bidirectional e2 regulation, which was linked to unique transcriptional factors and highly associated with immune surveillance in the clinical setting. furthermore, the context dependent e2 response programs were characterized in mcf7 and t47d cell lines, the two most frequently used models in the estrogene database. collectively, the estrogene database provides an informative and practical resource to the cancer research community to uniformly evaluate key reproducible features of er regulomes and unravels modes of er signaling.",AB_0152
"effective passage retrieval is crucial for conversation question answering (qa) but challenging due to the ambiguity of questions. current methods rely on the dual-encoder architecture to embed contextualized vectors of questions in conversations. however, this architecture is limited in the embedding bottleneck and the dot-product operation. to alleviate these limitations, we propose generative retrieval for conversational qa (gcoqa). gcoqa assigns distinctive identifiers for passages and retrieves passages by generating their identifiers token-by-token via the encoder-decoder architecture. in this generative way, gcoqa eliminates the need for a vector-style index and could attend to crucial tokens of the conversation context at every decoding step. we conduct experiments on three public datasets over a corpus containing about twenty million passages. the results show gcoqa achieves relative improvements of +13.6% in passage retrieval and +42.9% in document retrieval. gcoqa is also efficient in terms of memory usage and inference speed, which only consumes 1/10 of the memory and takes in less than 33% of the time. the code and data are released at https://github.com/liyongqi67/gcoqa.",AB_0152
"the increasing concerns of public health and safety lead to a practical need to detect smoking behaviors (or smokers) in public places. previous smoker detection methods often focus on cigarette detection, which overlook the interaction between the smoker and the cigarette. in light of this, this paper presents a single-image smoker detection framework via human-object interaction with lite transformer network (holt-net). specifically, a one-stage human-object interaction module is devised to identify the interaction between the smoker and the cigarette. to incorporate the global information for better feature representation, a simple yet powerful lite transformer module is leveraged, where the multi-head self-attention blocks are exploited. beyond that, a post-refinement module is integrated for taking advantage of an additional fine-grained cigarette detector to enhance the interaction detection accuracy. it is noteworthy that we present a new benchmark dataset named scau-smoker detection (scau-sd), which, to the best of our knowledge, is the first benchmark dataset for the specific task of smoker detection in single images with human-object interaction annotations. extensive experimental results demonstrate the effectiveness of our holt-net framework. the code is publicly available at https://github.com/jackkoling/holt-net.",AB_0152
"colorectal cancer is a prevalent disease in modern times, with most cases being caused by polyps. therefore, the segmentation of polyps has garnered significant attention in the field of medical image segmentation. in recent years, the variant network derived from the u-net network has demonstrated a good segmentation effect on polyp segmentation challenges. in this paper, a polyp segmentation model, called cfha-net, is proposed, that combines a cross-scale feature fusion strategy and a hybrid attention mechanism. inspired by feature learning, the encoder unit incorporates a cross-scale context fusion (ccf) module that performs cross-layer feature fusion and enhances the feature information of different scales. the skip connection is optimized by proposed triple hybrid attention (tha) module that aggregates spatial and channel attention features from three directions to improve the long-range dependence between features and help identify subsequent polyp lesion boundaries. additionally, a dense-receptive feature fusion (dff) module, which combines dense connections and multi-receptive field fusion modules, is added at the bottleneck layer to capture more comprehensive context information. furthermore, a hybrid pooling (hp) module and a hybrid upsampling (hu) module are proposed to help the segmentation network acquire more contextual features. a series of experiments have been conducted on three typical datasets for polyp segmentation (cvc-clinicdb, kvasirseg, endotect) to evaluate the effectiveness and generalization of the proposed cfha-net. the experimental results demonstrate the validity and generalization of the proposed method, with many performance metrics surpassing those of related advanced segmentation networks. therefore, proposed cfha-net could present a promising solution to the challenges of polyp segmentation in medical image analysis. the source code of proposed cfha-net is available at https://github.com/cxzhai/cfha-net.git.",AB_0152
"the use of artificial intelligence has led to an increase in road extraction projects from satellite images through deep learning. however, multi-spectral images (msi) have been largely overlooked in road extraction algorithms due to their lower resolution compared to panchromatic or fused images. additionally, deep learning faces the challenge of image content reasoning from distant contexts in data rule mining. to address these issues, we propose a new method for road extraction called the msi-guided segmentation network, which utilizes all the data from the gf2 satellite to achieve optimal results. this study highlights the advantages of using msi with low-resolution for obtaining deeper semantic information in a faster manner, while high-resolution fused images are better suited for extracting precise characteristics. the proposed method includes two sections: (1) a local symmetry feature fusion to enhance the network's local context-awareness for shallow details, and (2) a global asymmetric semantic fusion to improve the network's capability to comprehend the whole scene for deep semantic information. moreover, to evaluate the robustness and generalization of this method, we have provided a gf2 full-band china road dataset. the codes and datasets will be made public on https://github.com/ dudujia160918/msnet.",AB_0152
"rapid and accurate agricultural parcel mapping from high-resolution remote sensing imagery is fundamental to precision agriculture for smallholder farming systems. however, due to the narrow and small-size parcels, and the significant spatio-spectral variability, the existing two-stage segmentation methods cannot extract individual parcels automatically. in this article, the end-to-end vectorization of smallholder agricultural parcel boundaries (e2evap) framework is proposed for extracting the vertices of each parcel boundary individually in smallholder farming regions, where the semantic-contour interaction and topological loss through hierarchical instance representation (called channel to instance) are designed for aggregating the foreground features and jointly establishing the topological relationship between instances to alleviate the topological overlap between parcel objects. vertex shift correction based on the deep attention corner snake module guided by the parcel boundaries is also proposed to adaptively correct the boundary vertex location shift of large-scale irregular parcels. the comprehensive experimental results obtained on the iflytek public agricultural parcel dataset confirm that e2evap shows a superior performance (with a mask map of 0.335 and a boundary map of 0.201), compared with the pixel-based (such as mask r-cnn, htc, and solov2) and contour-based (such as deepsnake and e2ec) benchmark methods. we believe that e2evap has the potential to be widely used for accurate vectorization mapping of agricultural parcels in smallholder farming areas such as south africa and southern china. the code of e2evap is at https://github.com/yangpanhzau/e2evap.",AB_0152
"as one of the necessary cash crops in china and many other countries, wolfberry is parasitized by multiple pests, and its yield is highly susceptible to being affected. on the other hand, agricultural pest backgrounds are complex. when identifying them, single-modal models cannot utilize diverse data types across modalities, resulting in low identification accuracy and data utilization. traditional unimodal identification models can no longer meet the needs of multimodal data development in agriculture. to overcome these challenges, the itfwpi cross-modal feature fusion model is proposed, which consists of cotn and odls for parallel processing of images and text, respectively. we incorporate the transformer structure (cot), which focuses on contextual feature extraction, into cotn to make full use of the rich static and dynamic linear fusion contexts between adjacent keys and improve the 4-stage network of cotn using pyramid squeezed attention (psa) to improve the extraction of multi-scale feature structure information and effectively promote the interaction of in-depth features with multi-scale spatial information. the odls network constructed by introducing 1d convolutional and bidirectional lstm stacking has been shown to have more robust text feature acquisition than other advanced convolutional neural network-long short-term memory (cnn-lstm) models from experimental results, with a 30% reduction in maccs compared to the optimal model. the results showed that itf-wpi performed well in accuracy, f1 score, model size, and maccs with 97.98%, 93.19%, 52.20 mb, and 7.828 g compared to the classical state-of-the-art (sota) model, lightweight sota model and advanced transformer neural network synthesis, respectively. the model has critical practical applications for promoting the development of crossmodal models in agriculture and research on wolfberry pest control and improving wolfberry yields. the code and dataset for this study will be posted on github (https://github.com/wemindful/cross-modal-pest-identifying) as soon as the study is released, and new data will be updated in the future.",AB_0152
"objective: this randomized double-blinded clinical study is to investigate the clinical efficacy of per-paravertebral disk ozone injection combined with steroids in the treatment of patients with chronic discogenic low back pain (cdlbp). methods: group a (n = 60) received a per-paravertebral injection of a steroid mixture of 10 ml with pure oxygen 20 ml, while group b (n = 60) received a per-paravertebral injection of a steroid mixture of 10 ml combined with ozone 20 ml (30 mu g/ml). injections were administered once a week for 3 weeks, with a follow-up of 6 months. clinical outcomes were assessed at week 1, month 3, and month 6 with the help of visual analog scale (vas) scores and macnab efficacy evaluation. results: the vas score of both group a (1.65 vs. 6.87, p = 0.000) and group b (1.25 vs. 6.85, p = 0.000) at week 1 was significantly reduced compared to baseline. the effect was sustained at the 3- and 6-month follow-up periods (p < 0.05). group b had significantly lower vas scores at month 3 (1.53 vs. 3.82, p = 0.000) and month 6 (2.80 vs. 5.05, p = 0.000) compared to group a, respectively. based on macnab criteria, 95 and 96.7% of patients in groups a and b had good rates excellent plus good at week 1, respectively. good rates were significantly higher in group b at month 3 (91.7 vs. 78.3%, p = 0.041) and month 6 (85.0 vs. 68.3%, p = 0.031) compared to group a, respectively. no serious adverse events were noted in both groups. conclusion: per-paravertebral injection of steroid and ozone combination resulted in better relief of cdlbp compared to pure oxygen plus steroid. clinical trial registration: https://www.chictr.org.cn/showproj.html?proj=121571, chictr2100044434.",AB_0152

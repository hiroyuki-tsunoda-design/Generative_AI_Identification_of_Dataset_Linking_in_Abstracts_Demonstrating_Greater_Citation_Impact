AB,NO
"most existing methods adopt the quadrilateral or rotated rectangle representation to detect multi-oriented objects. yet, the same oriented object may correspond to several different representations, due to different vertex ordering, or angular periodicity and edge exchangeability. to ensure the uniqueness of the representation, some engineered rules are usually added. this makes these methods suffer from discontinuity problem, resulting in degraded performance for objects around some orientation. in this article, we propose to encode the multi-oriented object with double horizontal rectangles (dhrec) to solve the discontinuity problem. specifically, for an oriented object, we arrange the horizontal and vertical coordinates of its four vertices in left-right and top-down order, respectively. the first (resp. second) horizontal box is given by two diagonal points with smallest (resp. second) and third (resp. largest) coordinates in both horizontal and vertical dimensions. we then regress three factors given by area ratios between different regions, helping to guide the oriented object decoding from the predicted dhrec. inherited from the uniqueness of horizontal rectangle representation, the proposed method is free of discontinuity issue, and can accurately detect objects of arbitrary orientation. extensive experimental results show that the proposed method significantly improves the existing baseline representation, and outperforms state-of-the-art methods. the code is available at: https://github.com/lightbillow/dhrec.",AB_0365
"face recognition systems have been widely applied in security-related areas of our daily life. however, they are vulnerable to face spoofing attacks. specifically, an attacker can fool a face recognition system into making false decisions, by presenting spoof face information (such as printed photos, replayed videos, etc.), rather than live face, to the face recognition system. therefore, face anti-spoofing (fas) is critical for the security operation of a face recognition system.deep learning-based fas approaches show the best performance among existing fas approaches. the basic idea of deep learning-based fas approaches is to learn statistical representations capable of distin-guishing spoof faces from live ones, and then leverage the learned representations for live and spoof face classifications. therefore, the learned representations play a key role in the performance of fas. however, most existing approaches learn representations from representation-entangled spaces, in which critical and irrelevant representations for live and spoof face classifications are entangled with each other, thereby bringing a negative influence on the performance of a fas system.to address the issue, we introduced a twin autoencoder disentanglement (tad) framework. our tad framework utilizes adversarial learning and a reconstruction strategy to disentangle both critical and irrelevant representations into two mutually independent representation spaces. in addition, to further suppress irrelevant representations that may remain in the critical representation space, we design a multi-branch supervision architecture (msa) and embed it into tad. msa achieves the goal via imposing depth supervision and pattern supervision to the critical representation space. i.e., learning spatial rep-resentation (face depth information) and texture representation (face spoof pattern information).experimental results on four typical public datasets, oulu-npu, siw, replay-attack, and casia-mfsd, demonstrate that our proposed tad approach successfully disentangles critical and irrelevant represen-tations, and the two disentangled representations are more interpretable than state-of-the-art fas meth-ods. the codes are available at https://github.com/tad-fas/tad.& copy; 2023 elsevier b.v. all rights reserved.",AB_0365
"identifying interactions between long non-coding rnas (lncrnas) and micrornas (mirnas) reveals the mechanisms of biological processes, thereby contributing to disease diagnosis and treatment. recently, graph neural networks (gnns) have achieved remarkable progress in this task due to their consideration of both node attributes and graph topology. nevertheless, existing gnn-based methods use only one type of node attribute, and the possible bias of a single view leads them to learn suboptimal node representations. moreover, the underlying mechanisms of action between lncrnas and mirnas are complex. ignoring the importance of neighboring nodes to the target node and the influence of different order neighborhood information makes them fail to learn satisfactory topological information. to this end, we propose a novel multi-view graph neural network with cascaded attention (mgcat) for lncrna-mirna interaction (lmi) prediction, where cascaded attention is a key ingredient consisting of view-level, node-level, and layer-level attentions. specifically, we first construct a multi-attributed lmi graph to fully characterize lncrnas and mirnas, where nodes have multiple node attributes (i.e., multi-view features). next, view-level attention dynamically integrates multi-view features to capture the inherent attribute information of nodes. then, node-level attention iteratively aggregates the neighborhood information of each node. finally, layer-level attention adaptively combines integrated features and different order neighborhood information to obtain informative node representations. extensive experiments on four benchmark datasets show that mgcat consistently outperforms recent state-of-the-art methods. further case studies demonstrate the potential ability of mgcat to identify novel lmis. code and datasets are publicly available at https://github.com/ai4slab/mgcat. & copy; 2023 elsevier b.v. all rights reserved.",AB_0365
"a challenging problem in robotics is how to control multiple robots cooperatively and safely in real-world applications. yet, developing multi-robot control methods from the perspective of safe multi-agent reinforcement learning (marl) has merely been studied. to fill this gap, in this study, we investigate safe marl for multi-robot control on cooperative tasks, in which each individual robot has to not only meet its own safety constraints while maximising their reward, but also consider those of others to guarantee safe team behaviours. firstly, we formulate the safe marl problem as a constrained markov game and employ policy optimisation to solve it theoretically. the proposed algorithm guarantees monotonic improvement in reward and satisfaction of safety constraints at every iteration. secondly, as approximations to the theoretical solution, we propose two safe multi -agent policy gradient methods: multi-agent constrained policy optimisation (macpo) and mappo-lagrangian. thirdly, we develop the first three safe marl benchmarks-safe multi -agent mujoco (safe mamujoco), safe multi-agent robosuite (safe marobosuite) and safe multi-agent isaac gym (safe maig) to expand the toolkit of marl and robot control research communities. finally, experimental results on the three safe marl benchmarks indicate that our methods can achieve state-of-the-art performance in the balance between improving reward and satisfying safety constraints compared with strong baselines. demos and code are available at the link (https://sites .google .com /view /aij -safe -marl/).2crown copyright (c) 2023 published by elsevier b.v. all rights reserved.",AB_0365
"weight and activation binarization can efficiently compress deep neural networks and accelerate model inference, but they cause severe accuracy degradation. existing optimization methods for binary neural networks (bnns) focus on fitting fullprecision networks to reduce quantization errors and suffer from a tradeoff between accuracy and efficiency. in contrast, considering information loss and the mismatch between model capacity and input information quantity caused by network binarization, we propose information restriction and information recovery network (ir(2)net) to stimulate the potential of bnns and achieve improved network accuracy by restricting the input information and recovering feature information. the proposed approach includes (1) information restriction, which evaluates the feature information extracted from the input by a bnn, discards some of the information it cannot focus on, and reduces the amount of the input information to match the model capacity; and (2) information recovery: due to the information loss incurred during forward propagation, the extracted feature information of the network is not sufficient for supporting accurate classification. shallow feature maps with richer information are selected, and these feature maps are fused with the final feature maps to recover the extracted feature information and further enhance the model capacity to match the amount of input information. in addition, the computational cost is reduced by streamlining the information recovery method to strike a better tradeoff between accuracy and efficiency. experimental results demonstrate that our approach still achieves comparable accuracy even with a similar to 10x floating-point operations (flops) reduction for resnet- 18. the models and code are available at https://github.com/ pingxue-hfut/ir2net.",AB_0365
"how to generate an image from a text description is an imaginative and challenging task. this study proposes a conditional generative adversarial network (gan) of transformer architecture for text-to-image tasks called ctgan by employing the gan generator based on transformer architecture. we also propose a filtering module suitable for non-end-to-end multi-stage models. this module can screen out the good images generated in the previous stage and allows only the good images to participate in the generation of the later stage. this method significantly improves the quality of the generated images. furthermore, we designed a generator and discriminator based on symmetry. in the generator, we propose a shift self-attention technology to establish information communication between grids, reduce boundary loss, and improve image quality. we established two modes of local and global discriminations based on the grid, which can balance the performance of the generator and discriminator, improve the training stability, and accelerate the model convergence. we conducted several experiments on the widely used conditional datasets (cub and coco) and unconditional datasets (celeba and lsun church). the experimental results show that the proposed ct-gan is superior to the most advanced convolution model in generating diversity and semantic consistency. codes are available at: https://github.com/jwtcode/ct-gan.",AB_0365
"micro-expression analysis by computer vision techniques has attracted much attention as it can reveal the human emotions automatically. among the analysis tasks, the temporal spotting is the most challenging task for achieving expression-aware frames from long video sequences. compared to the well studied recognition task, more researches need to be devoted to the spotting task for further improving the per-formance and benefiting the subsequent tasks. so, in this paper, we propose a convolutional transformer based deep model for micro-expression spotting in long video sequences. a 3d convolutional subnetwork is firstly employed to extract the visual features from the temporal frames in a fixed-size sliding win-dow of original video sequence. then a multi-scale local transformer module is designed based on the visual features to model the correlation between frames in a local window. by leveraging the correlation information, the description of face movement becomes more representative for various-duration micro-expressions. finally, the multi-head classifier and the corresponding estimator are jointly combined to predict the temporal position for spotting micro-expressions. the proposed method is evaluated on two publicly-available datasets, namely cas(me)2 and samm-lv, and achieves the promising performance of 0.2770 f1-score on samm-lv and 0.1373 f1-score on cas(me)2. the code is publicly available on github ( https://github.com/xiazhaoqiang/mult-microexpressionspot ).(c) 2023 elsevier b.v. all rights reserved.",AB_0365
"multi-view stereo reconstruction aims to construct 3d scenes from multiple 2d images. in recent years, learning-based multi-view stereo methods have achieved significant results in depth estimation for multi-view stereo reconstruction. however, the current popular multi-stage processing method cannot solve the low-efficiency problem satisfactorily owing to the use of 3d convolution and still involves significant amounts of calculation. therefore, to further balance the efficiency and generalization performance, this study proposed a multi-scale iterative probability estimation with refinement, which is a highly efficient method for multi-view stereo reconstruction. it comprises three main modules: 1) a high-precision probability estimator, dilated-lstm that encodes the pixel probability distribution of depth in the hidden state, 2) an efficient interactive multi-scale update module that fully integrates multi-scale information and improves parallelism by interacting information between adjacent scales, and 3) a pi-error refinement module that converts the depth error between views into a grayscale error map and refines the edges of objects in the depth map. simultaneously, we introduced a large amount of high-frequency information to ensure the accuracy of the refined edges. among the most efficient methods (e.g., runtime and memory), the proposed method achieved the best generalization on the tanks & temples benchmarks. additionally, the performance of the miper-mvs was highly competitive in dtu benchmark. our code is available at https://github.com/zhz120/miper-mvs.(c) 2023 elsevier ltd. all rights reserved.",AB_0365
"intelligent diagnostic methods based on deep learning have proven to be effective in equipment management and maintenance. however, in practical industrial applications in which data is scarce and equipment, load, and operating conditions are variable, the performance of well-trained laboratory models degrades significantly. to this end, this study proposes a domain adaptation meta-learning network with feature-oriented discard-supplement module (fd-daml) for few-shot cross-domain rotating machinery fault diagnosis. this method addresses the diagnosis issues of severe domain distribution discrepancy, label space mismatch, and scarcity of labeled samples in the target domain within a unified framework. specifically, the proposed method attempts a training mode that alternates the execution of the source and target domains meta-learning, and combines it with domain adversarial training. such a training mode not only contributes to the accumulation of domain-invariant meta-knowledge from the source domain for the model, but also effectively learns the discriminative model for the target domain and achieves good generalization over it. moreover, a plug-and-play feature-oriented discard-supplement module is designed to perform discard and supplement operations on extracted features against the context, to improve the generalization of the model. extensive comparative experiments on public datasets, experimental datasets, and actual wind turbine datasets validate the effectiveness of the proposed fd-daml and the feasibility of engineering diagnostics. the code will be published at https://github.com/zhangyu-ysu/fd-daml.(c) 2023 elsevier b.v. all rights reserved.",AB_0365
"batch normalization (bn) is widely used in modern deep neural networks, which has been shown to represent the domain-related knowledge, and thus is ineffective for cross-domain tasks like unsuper-vised domain adaptation (uda). existing bn variant methods aggregate source and target domain knowl-edge in the same channel in normalization module. however, the misalignment between the features of corresponding channels across domains often leads to a sub-optimal transferability. in this paper, we exploit the cross-domain relation and propose a novel normalization method, reciprocal normal-ization (rn). specifically, rn first presents a reciprocal compensation (rc) module to acquire the com-pensatory for each channel in both domains based on the cross-domain channel-wise correlation. then rn develops a reciprocal aggregation (ra) module to adaptively aggregate the feature with its cross-domain compensatory components. as an alternative to bn, rn is more suitable for uda problems and can be easily integrated into popular domain adaptation methods. experiments show that the proposed rn outperforms existing normalization counterparts by a large margin and helps state-of-the-art adapta-tion approaches achieve better results. the source code is available on https://github.com/openning07/ reciprocal- normalization- for-da . (c) 2023 published by elsevier ltd.",AB_0365

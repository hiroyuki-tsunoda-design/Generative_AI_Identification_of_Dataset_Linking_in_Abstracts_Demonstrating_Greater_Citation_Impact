AB,NO
"in china, the demand for a more precise perception of the national land surface has become most urgent given the pace of development and urbanization. constructing a very-high-resolution (vhr) land-cover dataset for china with national coverage, however, is a nontrivial task. thus, this has become an active area of research that is impeded by the challenges of image acquisition, manual annotation, and computational complexity. to fill this gap, the first 1 m resolution national-scale land-cover map of china, sinolc-1, was established using a deep-learning-based framework and open-access data, including global land-cover (glc) products, openstreetmap (osm), and google earth imagery. reliable training labels were generated by combining three 10 m glc products and osm data. these training labels and 1 m resolution images derived from google earth were used to train the proposed framework. this framework resolved the label noise stemming from a resolution mismatch between images and labels by combining a resolution-preserving backbone, a weakly supervised module, and a self-supervised loss function, to refine the vhr land-cover results automatically without any manual annotation requirement. based on large-storage and computing servers, processing the 73.25 tb dataset to obtain the sinolc-1 covering the entirety of china, similar to 9 600 000 km(2), took about 10 months. the sinolc-1 product was validated using a visually interpreted validation set including over 100 000 random samples and a statistical validation set collected from the official land survey report provided by the chinese government. the validation results showed that sinolc-1 achieved an overall accuracy of 73.61 % and a kappa coefficient of 0.6595. validations for every provincial region further indicated the accuracy of this dataset across the whole of china. furthermore, the statistical validation results indicated that sinolc-1 conformed to the official survey reports with an overall misestimation rate of 6.4 %. in addition, sinolc-1 was compared with five other widely used glc products. these results indicated that sinolc-1 had the highest spatial resolution and the finest landscape details. in conclusion, as the first 1 m resolution national-scale land-cover map of china, sinolc-1 delivered accuracy and provided primal support for related research and applications throughout china. the sinolc-1 land-cover product is freely accessible at https://doi.org/10.5281/zenodo.7707461 (li et al., 2023).",AB_0136
"kruger, wirtz, van boven, and altermatt (2004) described the effort heuristic as the tendency to evaluate the quality and the monetary value of an object as higher if the production of that object was perceived as involving more effort. we attempted two preregistered replications (total n = 1405; u.s. american participants from mturk and prolific) of their experiments 1 and 2. our first replication using an mturk sample found support for the original's findings regarding experiment 2, yet failed to find support for the original's findings in experiment 1. our second revised attempt of experiment 1 on prolific was mixed, with more nuanced findings, showing support for an effort heuristic effect for liking/quality and no support for an effort heuristic on monetary value. we discuss possible reasons for this discrepancy, theoretical implications and future research directions for the psychology of value and the effort heuristic. all materials, data, and code were made available on https://osf.io/qxf5c/.",AB_0136
"in this study, we systematically studied the energy distribution of bioactive conformations of small molecular ligands in their conformational ensembles using ani-2x, a machine learning potential, in conjunction with one of our recently developed geometry optimization algorithms, known as a conjugate gradient with backtracking line search (cg-bs). we first evaluated the combination of these methods (ani-2x/cg-bs) using two molecule sets. for the 231-molecule set, ab initio calculations were performed at both the omega b97x/6-31g(d) and b3lyp-d3bj/dzvp levels for accuracy comparison, while for the 8,992-molecule set, ab initio calculations were carried out at the b3lyp-d3bj/dzvp level. for each molecule in the two molecular sets, up to 10 conformations were generated, which diminish the influence of individual outliers on the performance evaluation. encouraged by the performance of ani-2x/cg-bs in these evaluations, we calculated the energy distributions using ani-2x/cg-bs for more than 27,000 ligands in the protein data bank (pdb). each ligand has at least one conformation bound to a biological molecule, and this ligand conformation is labeled as a bound conformation. besides the bound conformations, up to 200 conformations were generated using openeye's omega2 software (https://docs.eyesopen.com/applications/ omega/) for each conformation. we performed a statistical analysis of how the bound conformation energies are distributed in the ensembles for 17,197 pdb ligands that have their bound conformation energies within the energy ranges of the omega2-generated conformation ensembles. we found that half of the ligands have their relative conformation energy lower than 2.91 kcal/mol for the bound conformations in comparison with the global conformations, and about 90% of the bound conformations are within 10 kcal/mol above the global conformation energies. this information is useful to guide the construction of libraries for shape-based virtual screening and to improve the docking algorithm to efficiently sample bound conformations.",AB_0136
"drug-target affinity (dta) prediction as an emerging and effective method is widely applied to explore the strength of drug-target interactions in drug development research. by predicting these interactions, researchers can assess the potential efficacy and safety of candidate drugs at an early stage, narrowing down the search space for therapeutic targets and accelerating the discovery and development of new drugs. however, existing dta prediction models mainly use graphical representations of drug molecules, which lack information on interactions between individual substructures, thus affecting prediction accuracy and model interpretability. therefore, transformer and diffusion on drug graphs in dta prediction (tdgraphdta) are introduced to predict drug-target interactions using multi-scale information interaction and graph optimization. an interactive module is integrated into feature extraction of drug and target features at different granularity levels. a diffusion model-based graph optimization module is proposed to improve the representation of molecular graph structures and enhance the interpretability of graph representations while obtaining optimal feature representations. in addition, tdgraphdta improves the accuracy and reliability of predictions by capturing relationships and contextual information between molecular substructures. the performance of the proposed tdgraphdta in dta prediction was verified on three publicly available benchmark datasets (davis, metz, and kiba). compared with state-of-the-art baseline models, it achieved better results in terms of consistency index, r-squared, etc. furthermore, compared with some existing methods, the proposed tdgraphdta is demonstrated to have better structure capturing capabilities by visualizing the feature capturing capabilities of the model using grad-aam toxicity labels in the toxcast dataset. the corresponding source codes are available at https://github.com/lamouryz/tdgraph.",AB_0136
"medical image segmentation is a critical task used to accurately extract regions of interest and pathological areas from medical images. in recent years, significant progress has been made in the field of medical image segmentation using deep learning and neural networks. however, existing methods still have limitations in terms of fusing local features and global contextual information due to the complex variations and irregular shapes of medical images. to address this issue, this paper proposes a medical image segmentation architecture called lgi net, which improves the internal computation to achieve sufficient interaction between local perceptual capabilities and global contextual information within the network. furthermore, the network incorporates an eca module to effectively capture the interplay between channels and improve inter-layer information exchange capabilities. we conducted extensive experiments on three public medical image datasets: kvasir, isic, and x-ray to validate the effectiveness of the proposed method. ablation studies demonstrated the effectiveness of our lgaf, and comparative experiments confirmed the superiority of our proposed lgi net in terms of accuracy and parameter efficiency. this study provides an innovative approach in the field of medical image segmentation, offering valuable insights for further improvements in accuracy and performance. the code and models will be available at https://github.com/liulinjie0310/lgi-net.",AB_0136
"backgroundthis study aimed to construct a risk prediction model to estimate the odds of osteoporosis (op) in elderly patients with type 2 diabetes mellitus (t2dm) and evaluate its prediction efficiency.methodsthis study included 21,070 elderly patients with t2dm who were hospitalized at six tertiary hospitals in southwest china between 2012 and 2022. univariate logistic regression analysis was used to screen for potential influencing factors of op and least absolute shrinkage. further, selection operator regression (lasso) and multivariate logistic regression analyses were performed to select variables for developing a novel predictive model. the area under the receiver operating characteristic curve (auroc), calibration curve, decision curve analysis (dca), and clinical impact curve (cic) were used to evaluate the performance and clinical utility of the model.resultsthe incidence of op in elderly patients with t2dm was 7.01% (1,476/21,070). age, sex, hypertension, coronary heart disease, cerebral infarction, hyperlipidemia, and surgical history were the influencing factors. the seven-variable model displayed an auroc of 0.713 (95% confidence interval [ci]:0.697-0.730) in the training set, 0.716 (95% ci: 0.691-0.740) in the internal validation set, and 0.694 (95% ci: 0.653-0.735) in the external validation set. the optimal decision probability cut-off value was 0.075. the calibration curve (bootstrap = 1,000) showed good calibration. in addition, the dca and cic demonstrated good clinical practicality. an operating interface on a webpage (https://juntaotan.shinyapps.io/osteoporosis/) was developed to provide convenient access for users.conclusionsthis study constructed a highly accurate model to predict op in elderly patients with t2dm. this model incorporates demographic characteristics and clinical risk factors and may be easily used to facilitate individualized prediction.",AB_0136
"the latent space of pre-trained generative adversarial networks (gans) is rich in semantic information, which often becomes highly entangled. it is crucial to identify semantic directions within this latent space, as these directions correlate with image attributes and are vital for image editing tasks. existing methods for semantic discovery usually involve labor-intensive procedures such as manual labeling and training attribute classifiers, which limits their practicality. in response to this issue, the paper proposes the optimal transport-based unsupervised semantic disentanglement (otusd) algorithm. this novel method efficiently uncovers semantic directions in the latent space of gans by utilizing the concepts of manifold learning and optimal transport (ot) theory. otusd applies singular value decomposition (svd) to the ot matrix that links latent codes to generated images. this process yields singular vectors that correspond to semantically meaningful directions. unlike traditional methods, otusd bypasses the need for time-consuming labeling and training processes, thus enhancing efficiency and revealing a wider array of semantically meaningful directions. experimental results demonstrate the effectiveness of otusd in discovering semantic directions from several state-of-the-art gan models, including stylegan, stylegan2, and biggan. this performance emphasizes the potential applicability of otusd to image editing and other related tasks, and illuminates its value in harnessing the manifold learning and ot mapping capabilities inherent in gans for semantic disentanglement. the implementation code is available at https://github.com/luckalex/otusd.",AB_0136
"there is a growing body of evidence suggesting that micrornas (mirnas), small biological molecules, play a crucial role in the diagnosis, treatment, and prognostic assessment of diseases. however, it is often inefficient to verify the association between mirnas and diseases (mda) through traditional experimental methods. based on this situation, researchers have proposed various computational-based methods, but the existing methods often have many drawbacks in terms of predictive effectiveness and accuracy. therefore, in order to improve the prediction performance of computational methods, we propose a transformer-based prediction model (mdformer) for multi-source feature information. specifically, first, we consider multiple features of mirnas and diseases from the molecular biology perspective and utilize them in a fusion. then high-quality node feature embeddings were generated using a feature encoder based on the transformer architecture and meta-path instances. finally, a deep neural network was built for mda prediction. to evaluate the performance of our model, we performed multiple 5-fold cross-validations as well as comparison experiments on hmdd v3.2 and hmdd v2.0 databases, and the experimental results of the average roc area under the curve (auc) were higher than the comparative methods for both databases at 0.9506 and 0.9369. we conducted case studies on five highly lethal cancers (breast, lung, colorectal, gastric, and hepatocellular cancers), and the first 30 predictions for these five diseases achieved 97.3% accuracy. in conclusion, mdformer is a reliable and scientifically sound tool that can be used to accurately predict mda. in addition, the source code is available at https://github.com/linda908/ mdformer.",AB_0136
"accurate and automatic segmentation of medical images is a key step in clinical diagnosis and analysis. currently, the successful application of transformers' model in the field of computer vision, researchers have begun to gradually explore the application of transformers in medical segmentation of images, especially in combination with convolutional neural networks with coding-decoding structure, which have achieved remarkable results in the field of medical segmentation. however, most studies have combined transformers with cnns at a single scale or processed only the highest-level semantic feature information, ignoring the rich location information in the lower-level semantic feature information. at the same time, for problems such as blurred structural boundaries and heterogeneous textures in images, most existing methods usually simply connect contour information to capture the boundaries of the target. however, these methods cannot capture the precise outline of the target and ignore the potential relationship between the boundary and the region. in this paper, we propose the tgdaunet, which consists of a dual-branch backbone network of cnns and transformers and a parallel attention mechanism, to achieve accurate segmentation of lesions in medical images. firstly, high-level semantic feature information of the cnn backbone branches is fused at multiple scales, and the high-level and low-level feature information complement each other's location and spatial information. we further use the polarised self-attentive (psa) module to reduce the impact of redundant information caused by multiple scales, to better couple with the feature information extracted from the transformers backbone branch, and to establish global contextual long-range dependencies at multiple scales. in addition, we have designed the reverse graph-reasoned fusion (rgf) module and the feature aggregation (fa) module to jointly guide the global context. the fa module aggregates high-level semantic feature information to generate an original global predictive segmentation map. the rgf module captures nonsignificant features of the boundaries in the original or secondary global prediction segmentation graph through a reverse attention mechanism, establishing a graph reasoning module to explore the potential semantic relationships between boundaries and regions, further refining the target boundaries. finally, to validate the effectiveness of our proposed method, we compare our proposed method with the current popular methods in the cvc-clinicdb, kvasir-seg, etis, cvc-colondb, cvc-300,datasets as well as the skin cancer segmentation datasets isic-2016 and isic-2017. the large number of experimental results show that our method outperforms the currently popular methods. source code is released at https://github.com/sd-spf/tgdaunet.",AB_0136
"introductionwith regard to the esthetics and comfort of orthodontic treatment, the requirement for removable clear aligners (cas) is increasing. unlike conventional fixed orthodontic appliances, cas were made of thermoplastic film by thermoforming on the personalized dental models. the construction of orthodontic thermoplastic is a critical factor for orthodontic tooth movement (otm). polyethylene terephthalate glycol-modified (petg) and thermoplastic polyurethane (tpu) are the most commonly orthodontic thermoplastics; however, the evidence of the differences between different orthodontic thermoplastic are limited to vitro environment and the evidence in vivo environment is not available. therefore, this trial aims to provide reliable evidence for orthodontists' personalized treatment plans whether the two most commonly used orthodontic thermoplastics of petg and tpu have differences in the efficiency of otm.methods and analysisthis randomized controlled clinical study will recruit 44 orthodontic patients for orthodontic treatment. all the subjects will be randomized into two groups (petg and tpu, n = 22 for each group). in the first stage (m0 to m1), clear aligners will be made of two orthodontic thermoplastics and move the maxillary first or second premolars 2 mm. in the second stage, patients will take the standard orthodontic treatments. the primary outcome will be the efficiency of clear aligners made of different materials on the digital models. the secondary outcome will be the efficiency of clear aligners made of different materials on the cone-beam computed tomography (cbct). the efficiency will be calculated through the superimposition of the digital models and cbct.discussionthe results from this trial will serve as evidence for orthodontists and manufacturers and clarify whether the difference in orthodontic thermoplastics significantly impacts the efficiency of otm.trial registration numberchictr2300070980. registered on 27 april 2023.https://www.chictr.org.cn/showproj.html?proj=186253trial registration numberchictr2300070980. registered on 27 april 2023.https://www.chictr.org.cn/showproj.html?proj=186253",AB_0136

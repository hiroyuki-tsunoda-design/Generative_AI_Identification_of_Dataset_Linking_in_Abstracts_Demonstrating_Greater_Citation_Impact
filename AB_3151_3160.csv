AB,NO
"introduction: adverse drug reactions (adr) are directly related to public health and become the focus of public and media attention. at present, a large number of adr events have been reported on the internet, but the mining and utilization of such information resources is insufficient. named entity recognition (ner) is the basic work of many natural language processing (nlp) tasks, which aims to identify entities with specific meanings from natural language texts. methods: in order to identify entities from adr event data resources more effectively, so as to provide valuable health knowledge for people, this paper introduces albert in the input presentation layer on the basis of the classic bilstm-crf model, and proposes a method of adr named entity recognition based on the albert-bilstm-crf model. the textual information about adr on the website '' chinese medical information query platform '' (https://www.dayi.org. cn) was collected by the crawler and used as research data, and the bio method was used to label three types of entities: drug name (drn), drug component (com), and adverse drug reactions (adr) to build a corpus. then, the words were mapped to the word vector by using the albert module to obtain the character level semantic information, the context coding was performed by the bilstm module, and the label decoding was using the crf module to predict the real label. results: based on the constructed corpus, experimental comparisons were made with two classical models, namely, bilstm-crf and bert-bilstm-crf. the experimental results show that the f1 of our method is 91.19% on the whole, which is 1.5% and 1.37% higher than the other two models respectively, and the performance of recognition of three types of entities is significantly improved, which proves the superiority of this method. discussion: the method proposed can be used effectively in ner from adr information on the internet, which provides a basis for the extraction of drugrelated entity relationships and the construction of knowledge graph, thus playing a role in practical health systems such as intelligent diagnosis, risk reasoning and automatic question answering.",AB_0316
"although computational methods for driver gene identification have progressed rapidly, it is far from the goal of obtaining widely recognized driver genes for all cancer types. the driver gene lists predicted by these methods often lack consistency and stability across different studies or datasets. in addition to analytical performance, some tools may require further improvement regarding operability and system compatibility. here, we developed a user-friendly r package (drivergenepathway) integrating mutsigcv and statistical methods to identify cancer driver genes and pathways. the theoretical basis of the mutsigcv program is elaborated and integrated into drivergenepathway, such as mutation categories discovery based on in-formation entropy. five methods of hypothesis testing, including the beta-binomial test, fisher combined p- value test, likelihood ratio test, convolution test, and projection test, are used to identify the minimal core driver genes. moreover, de novo methods, which can effectively overcome mutational heterogeneity, are introduced to identify driver pathways. herein, we describe the computational structure and statistical fundamentals of the drivergenepathway pipeline and demonstrate its performance using eight types of cancer from tcga. drivergenepathway correctly confirms many expected driver genes with high overlap with the cancer gene census list and driver pathways associated with cancer development. the drivergenepathway r package is freely available on github: https://github.com/bioinformatics-xu/ drivergenepathway.& copy; 2023 the author(s). published by elsevier b.v. on behalf of research network of computational and structural biotechnology. this is an open access article under the cc by-nc-nd license ().",AB_0316
"social recommendation leverages social information to alleviate data sparsity and cold-start issues of collaborative filtering (cf) methods. most existing works model user interests following the assumption of social homophily based on social-relation data. the explicit modeling of social influence, which also largely affects user behaviors, has not been well explored. considering user behaviors may be driven by social factors in today's information services (e.g., purchasing products shared by close friends on social e-commerce applications), these methods will be suboptimal. in this work, we propose a method modeling both social homophily-aware user interests and social influence as two essential effects on user behaviors for social recommendation, named as disgcn (short for disentangled modeling of social homophily and influence with graph convolutional network). specifically, we devise a disentangled embedding layer to encode these two effects. furthermore, two tailored graph convolutional layers are developed to disentangle them refinedly, leveraging the high-order embedding propagation in social-network graph from two aspects. technically, first, the operation of attentive embedding propagation is adopted for capturing personalized social homophily-aware interests, and second, the item-gate-based embedding propagation is proposed for capturing item-specific social influence. in addition, to ensure the disentanglement of social influence, we propose a contrastive learning framework that endows corresponding embeddings with explicit semantics. extensive experiments on two real-world datasets demonstrate the effectiveness of our proposed model. further studies also verify the rationality and necessity of our designs. we have released the datasets and codes at this link: https://github.com/tsinghua-fib-lab/disgcn.",AB_0316
"modeling time-evolving preferences of users with their sequential item interactions, has attracted increasing attention in many online applications. hence, sequential recommender systems have been developed to learn the dynamic user interests from the historical interactions for suggesting items. however, the interaction pattern encoding functions in most existing sequential recommender systems have focused on single type of user-item interactions. in many real-life online platforms, user-item interactive behaviors are often multi-typed (e.g., click, add-to-favorite, purchase) with complex cross-type behavior inter-dependencies. learning from informative representations of users and items based on their multi-typed interaction data, is of great importance to accurately characterize the time-evolving user preference. in this work, we tackle the dynamic user-item relation learning with the awareness of multi-behavior interactive patterns. towards this end, we propose a new temporal graph transformer (tgt) recommendation framework to jointly capture dynamic short-term and long-range user-item interactive patterns, by exploring the evolving correlations across different types of behaviors. the new tgtmethod endows the sequential recommendation architecture to distill dedicated knowledge for type-specific behavior relational context and the implicit behavior dependencies. experiments on the real-world datasets indicate that our method tgtconsistently outperforms various state-of-the-art recommendation methods. our model implementation codes are available at https://github.com/akaxlh/tgt.",AB_0316
"undersampling is one of the most popular techniques for dealing with class-imbalance problems. various undersampling methods have emerged over the past few decades. each of them exhibits the superiority in some scenarios. however, selecting representative majority-class samples such that the structures of the selected groups are maintained according to the underlying imbalanced distribution remains a challenge. for this purpose, this paper proposes spatial distribution-based undersampling (sdus) for imbalanced learning. sdus uses a supervised constructive process to learn majority-class local patterns in terms of sphere neighborhoods (spn). two sample selection strategies, specifically, a top-down strategy and a bottom-up strategy, are proposed for maintaining the distribution pattern of original data in selecting majority-class sample subsets from different perspectives. sdus introduces an ensemble technique that improves learning performance by utilizing the diversity caused by the randomness of the local-pattern learning process. numerical experiments on 38 typical datasets from keel repository and 13 state-of-the-art comparison methods demonstrate the effectiveness of sdus in maintaining the underlying distribution characteristics for imbalanced undersampling. the implementation of the proposed sdus in programming language python is available at https://github.com/ytyancp/sdus.",AB_0316
"zero-shot learning (zsl) methods mainly associate global or region features to semantic vectors within a single image, for transferring semantic knowledge from the seen classes to unseen ones. however, the interactive region learning among a group of images from different categories, which can enhance the discrimination of region features and thus lead to a desirable knowledge transfer between seen and unseen classes, is seldom considered. to remedy the above challenge, we propose a group-wise interactive region learning (girl) model to guarantee a comprehensive and explicit region interaction. specifically, girl consists of an attentive region interaction (ari) module and a holistic semantic embedding (hse) module. ari utilizes the semantic commonalities and differences of group regions to produce refined region features. hse holistically maps these region features to the semantic space for a more stable semantic transfer. we also present a semantic consistency loss and a relation alignment loss that can distill the refined/original region features and introduce unseen class semantic vectors for training, respectively. extensive experiments demonstrate the effectiveness of girl over other methods, achieving 68.9%, 42.9%, 75.5%, and 47.8% the generalized zsl (gzsl) h scores on cub, sun, awa2, and apy. the code is publicly available at https://github .com /tingml /girl.",AB_0316
"background cell clustering is a prerequisite for identifying differentially expressed genes (degs) in single- cell rna sequencing (scrna-seq) data. obtaining a perfect clustering result is of central importance for subsequent analyses, but not easy. additionally, the increase in cell throughput due to the advancement of scrna-seq protocols exacerbates many computational issues, especially regarding method runtime. to address these difficulties, a new, accurate, and fast method for detecting degs in scrna-seq data is needed. results here, we propose single-cell minimum enclosing ball (scmeb), a novel and fast method for detecting singlecell degs without prior cell clustering results. the proposed method utilizes a small part of known non-degs (stably expressed genes) to build a minimum enclosing ball and defines the degs based on the distance of a mapped gene to the center of the hypersphere in a feature space. conclusions we compared scmeb to two different approaches that could be used to identify degs without cell clustering. the investigation of 11 real datasets revealed that scmeb outperformed rival methods in terms of cell clustering, predicting genes with biological functions, and identifying marker genes. moreover, scmeb was much faster than the other methods, making it particularly effective for finding degs in high-throughput scrna-seq data. we have developed a package scmeb for the proposed method, which could be available at https://github.com/focuspaka/ scmeb.",AB_0316
"single-cell rna sequencing (scrna-seq) provides insights into gene expression heterogeneities in diverse cell types underlying homeostasis, development and pathological states. however, the loss of spatial information hinders its applications in deciphering spatially related features, such as cell-cell interactions in a spatial context. here, we present stellaris (https://spatial.rhesusbase.com), a web server aimed to rapidly assign spatial information to scrna-seq data based on their transcriptomic similarity with public spatial transcriptomics (st) data. stellaris is founded on 101 manually curated st datasets comprising 823 sections across different organs, developmental stages and pathological states from humans and mice. stellaris accepts raw count matrix and cell type annotation of scrna-seq data as the input, and maps single cells to spatial locations in the tissue architecture of properly matched st section. spatially resolved information for intercellular communications, such as spatial distance and ligand-receptor interactions (lris), are further characterized between annotated cell types. moreover, we also expanded the application of stellaris in spatial annotation of multiple regulatory levels with single-cell multiomics data, using the transcriptome as a bridge. stellaris was applied to several case studies to showcase its utility of adding value to the ever-growing scrna-seq data from a spatial perspective.",AB_0316
"with the development of multi-beam light detection and ranging (lidar) sensors, fast and accurate lidar-based localization has become a crucial issue in robotics and autonomous driving. however, balancing accu-racy and efficiency remains challenging in existing methods. in this paper, we propose a super-fast lidar global localization approach that can achieve state-of-the-art (sota) accuracy with superior efficiency. our method leverages template descriptors to capture structural environments and approximates the vehicle's position via map candidate points. additionally, we create an offline map database to evenly simulate vehicle orientations. we design a loss function to improve localization accuracy. we extensively evaluated the proposed method in public kitti outdoor sequences and self-collected indoor datasets. the experimental results show that our approach can run at close to 100 frames per second (fps) on a single-thread cpu, which is much faster than current sota methods. our average absolute translation errors (ates) are 0.20m (indoor) and 0.44m (outdoor), and the average localization success rates are 93% (indoor) and 90% (outdoor). the average localization success rates can exceed 97% in large outdoor scenarios with fine-tuned parameters. the source code will be available in https://github.com/shipc-ai.",AB_0316
"the crispr-cas system is a highly adaptive and rna-guided immune system found in bacteria and archaea, which has applications as a genome editing tool and is a valuable system for studying the co-evolutionary dynamics of bacteriophage interactions. here introduces crisprimmunity, a new web server designed for acr prediction, identification of novel class 2 crispr-cas loci, and dissection of key crispr-associated molecular events. crisprimmunity is built on a suite of crispr-oriented databases providing a comprehensive co-evolutionary perspective of the crispr-cas and anti-crispr systems. the platform achieved a high prediction accuracy of 0.997 for acr prediction when tested on a dataset of 99 experimentally validated acrs and 676 non-acrs, outperforming other existing prediction tools. some of the newly identified class 2 crispr-cas loci using crisprimmunity have been experimentally validated for cleavage activity in vitro. crisprimmunity offers the catalogues of pre-identified crispr systems to browse and query, the collected resources or databases to download, a well-designed graphical interface, a detailed tutorial, multi-faceted information, and exportable results in machine-readable formats, making it easy to use and facilitating future experimental design and further data mining. the platform is available at http://www.microbiome-bigdata.com/crisprimmunity. moreover, the source code for batch analysis are published on github (https://github.com/hit-immunologylab/crisprimmunity). [graphics] .",AB_0316
